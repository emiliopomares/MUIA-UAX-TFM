{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4429191f",
   "metadata": {},
   "source": [
    "## CNN VXL-Net - TFM Emilio Pomares Porras MUIA Alfonso X el Sabio, 2023-2024\n",
    "\n",
    "### Sistema de visión artificial para manipulación robótica a tasas interactivas con arquitecturas basadas en UNet: VXL-Net\n",
    "\n",
    "#### Artificial vision system for robotic manipulation at interactive framerates with U-Net based architectures: VXL-Net\n",
    "\n",
    "# ETAPA DE SELECCIÓN DE MODELO - MODEL SELECTION STAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6a4d1ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.10.14 (main, May  6 2024, 19:42:50) [GCC 11.2.0]\n"
     ]
    }
   ],
   "source": [
    "# Python >= 3.10 is required\n",
    "\n",
    "import sys\n",
    "print(sys.version)\n",
    "\n",
    "assert (int(str(sys.version).split(\".\")[0])*100 + int(str(sys.version).split(\".\")[1]))>=310, \"Please upgrade to pytorch ^3.10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a955832f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports y variables globales\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "\n",
    "import struct\n",
    "\n",
    "import scipy\n",
    "from scipy import ndimage\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FixedLocator\n",
    "\n",
    "import time\n",
    "\n",
    "import wandb\n",
    "\n",
    "import random\n",
    "\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "81468ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 256\n",
    "N_CHANNELS = 6\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d8594bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Device detection\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else (\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "device = \"cpu\"\n",
    "print(f\"Chosen device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e534e5c",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df596ef",
   "metadata": {},
   "source": [
    "In this section we will include all auxiliary functions needed to load the data from disk and prepare the minibatches on the fly to be fed into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5e3709d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_3d(data, aspect='equal', double_axis=True, ax=None):\n",
    "    \"\"\"\n",
    "    Plots a 3D grid of scalar-valued voxels.\n",
    "\n",
    "    Parameters:\n",
    "    data (numpy.array): data (len(data.shape) should be 3)\n",
    "    aspect (str): Aspect ratio for the plot (default is 'equal')\n",
    "    double_axis (bool): Whether to scale the tick labels by a factor of 2\n",
    "    ax (matplotlib.axes._subplots.Axes3DSubplot, optional): The axis to plot on. \n",
    "                                                           If None, a new figure and axis are created.\n",
    "    \"\"\"\n",
    "\n",
    "    def explode(data):\n",
    "        size = np.array(data.shape) * 2\n",
    "        data_e = np.zeros(size - 1, dtype=data.dtype)\n",
    "        data_e[::2, ::2, ::2] = data\n",
    "        return data_e\n",
    "\n",
    "    def explode_2(data):\n",
    "        size = np.array(data.shape) * 2\n",
    "        size[3] = data.shape[3]\n",
    "        data_e = np.zeros((size[0] - 1, size[1] - 1, size[2] - 1, data.shape[3]), dtype=data.dtype)\n",
    "        data_e[::2, ::2, ::2, :] = data\n",
    "        return data_e\n",
    "\n",
    "    filled = data\n",
    "    colors = np.zeros(filled.shape + (4,))\n",
    "    colors[..., 3] = filled  # Use tensor values for the alpha channel\n",
    "    colors[..., :3] = plt.cm.viridis(filled)[..., :3]  # Assign colors using the viridis colormap\n",
    "\n",
    "    # Upscale the above voxel image, leaving gaps\n",
    "    filled_2 = explode(filled)\n",
    "    colors_2 = explode_2(colors)\n",
    "\n",
    "    # Shrink the gaps\n",
    "    x, y, z = np.indices(np.array(filled_2.shape) + 1).astype(float) // 2\n",
    "    x[0::2, :, :] += 0.05\n",
    "    y[:, 0::2, :] += 0.05\n",
    "    z[:, :, 0::2] += 0.05\n",
    "    x[1::2, :, :] += 0.95\n",
    "    y[:, 1::2, :] += 0.95\n",
    "    z[:, :, 1::2] += 0.95\n",
    "\n",
    "    # Create a new figure and axis only if ax is None\n",
    "    if ax is None:\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "    ax.voxels(x, y, z, filled_2, facecolors=colors_2)\n",
    "    ax.set_aspect(aspect)\n",
    "\n",
    "    if double_axis:\n",
    "        # Scale the tick labels by a factor of 2\n",
    "        xticks = ax.get_xticks()\n",
    "        yticks = ax.get_yticks()\n",
    "        zticks = ax.get_zticks()\n",
    "    \n",
    "        # Set the tick positions (using FixedLocator)\n",
    "        ax.xaxis.set_major_locator(FixedLocator(xticks))\n",
    "        ax.yaxis.set_major_locator(FixedLocator(yticks))\n",
    "        ax.zaxis.set_major_locator(FixedLocator(zticks))\n",
    "    \n",
    "        # Now set the tick labels\n",
    "        ax.set_xticklabels(np.round(xticks * 2, 2))\n",
    "        ax.set_yticklabels(np.round(yticks * 2, 2))\n",
    "        ax.set_zticklabels(np.round(zticks * 2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5b808f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_kernel(sigma, size=3):\n",
    "    \"\"\"\n",
    "    Generates a Gaussian kernel of a given size and standard deviation.\n",
    "\n",
    "    Parameters:\n",
    "    sigma (float): Standard deviation of the Gaussian distribution.\n",
    "    size (int): Size of the kernel. Default is 3.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: Gaussian kernel.\n",
    "    \"\"\"\n",
    "    kernel_range = np.linspace(-(size - 1) / 2, (size - 1) / 2, size)\n",
    "    x, y, z = np.meshgrid(kernel_range, kernel_range, kernel_range)\n",
    "    kernel = np.exp(-(x ** 2 + y ** 2 + z ** 2) / (2 * sigma ** 2))\n",
    "    kernel /= np.sum(kernel)\n",
    "    #print(np.min(kernel))\n",
    "    return kernel\n",
    "\n",
    "def apply_gaussian_smoothing(array, sigma):\n",
    "    \"\"\"\n",
    "    Applies Gaussian smoothing to a 3D array.\n",
    "\n",
    "    Parameters:\n",
    "    array (numpy.ndarray): Input array of shape (W, H, D).\n",
    "    sigma (float): Standard deviation of the Gaussian kernel.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: Smoothed array.\n",
    "    \"\"\"\n",
    "    kernel = gaussian_kernel(sigma)\n",
    "    return ndimage.convolve(array, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9e4d0619",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_padded_size(data, N):\n",
    "    \"\"\"\n",
    "    Calculates padding sizes for F.pad so that each dimension is a multiple of N\n",
    "    \"\"\"\n",
    "    n_dim = len(data.shape)\n",
    "    dims = []\n",
    "    for dim in range(n_dim):\n",
    "        l = data.shape[dim]\n",
    "        needed = ((N-(l-(l//N)*N))%N)\n",
    "        needed_low = needed//2\n",
    "        needed_high = needed-needed_low\n",
    "        dims.append(needed_low)\n",
    "        dims.append(needed_high)\n",
    "    return tuple(dims[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "31f92bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_layer_output_shapes(model: nn.Module, input_tensor: torch.Tensor):\n",
    "    \"\"\"Prints out output shape for all layers in the network\"\"\"\n",
    "    def register_hook(module):\n",
    "        def hook(module, input, output):\n",
    "            class_name = module.__class__.__name__\n",
    "            layer_output_shape = output.shape\n",
    "            print(f\"{class_name}: {layer_output_shape}\")\n",
    "        return hook\n",
    "\n",
    "    # Register hooks for each layer in the model\n",
    "    hooks = []\n",
    "    for layer in model.children():\n",
    "        hooks.append(layer.register_forward_hook(register_hook(layer)))\n",
    "\n",
    "    # Forward pass to trigger the hooks\n",
    "    model(input_tensor)\n",
    "\n",
    "    # Remove the hooks after the forward pass\n",
    "    for hook in hooks:\n",
    "        hook.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d65ab974",
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug(condition, msg, level=0, name=\"\"):\n",
    "    \"\"\"\n",
    "    Conditionally outputs text, with\n",
    "    informative formatting\n",
    "    \n",
    "    Parameters:\n",
    "    condition (bool): A condition that will evaluate to True or False\n",
    "    msg (str): The string to conditionally print\n",
    "    level (int): The formatting tabulation level\n",
    "    name (str): An optional informative label\n",
    "    \"\"\"\n",
    "    if condition:\n",
    "        prefix = \"\"\n",
    "        for i in range(level):\n",
    "            prefix += \"   \"\n",
    "        print(f\"{prefix} ({name}) {msg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a933c0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    \"\"\"\n",
    "    Counts the total number of parameters in a PyTorch model\n",
    "\n",
    "    Parameters:\n",
    "    model (nn.Module): PyTorch model\n",
    "\n",
    "    Returns:\n",
    "    total_params (int): Total number of parameters\n",
    "    total_size (int): Total size of all parameters in bytes\n",
    "    \"\"\"\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    total_size = sum(p.numel() * p.element_size() for p in model.parameters())\n",
    "    \n",
    "    return total_params, total_size, f\"{total_params//(1000000)}M\", f\"{total_size//(1024*1024)}MB\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "167bda40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_frozen_layers(model: nn.Module):\n",
    "    \"\"\"\n",
    "    Lists layers and prints their trainability status\n",
    "    \"\"\"\n",
    "    layers_status = []\n",
    "    for name, param in model.named_parameters():\n",
    "        layer_name = name.split('.')[0]  # Get the layer name\n",
    "        is_frozen = not param.requires_grad\n",
    "        layers_status.append((name, is_frozen))\n",
    "    \n",
    "    for layer, is_frozen in layers_status:\n",
    "        status = \"Frozen\" if is_frozen else \"Trainable\"\n",
    "        print(f\"Layer: {layer}, Status: {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402422a9",
   "metadata": {},
   "source": [
    "## Data inspection and pre-processing\n",
    "Let's inspect some data first and assemble datapoints for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a9d56e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's load a few datapoints, consisting of and L and R 1280x720 images plus binary occupancy grid\n",
    "\n",
    "DATASET_PATH = \"../reduced-dataset/train\"\n",
    "\n",
    "import struct\n",
    "\n",
    "def load_target_datapoint(file_path, dataset_path=\"\"):\n",
    "    # Define the format string for reading the binary data\n",
    "    format_string = \"<3f4f\"  # 3 floats (position), 4 floats (quaternion)\n",
    "    # Calculate the size of the bytes for occupation data\n",
    "    occupation_size = 37 * 25 * 18\n",
    "    format_string += str(occupation_size) + \"s\"  # Occupation data\n",
    "\n",
    "    with open(os.path.join(dataset_path, file_path), \"rb\") as file:\n",
    "        # Read the binary data\n",
    "        data = file.read(struct.calcsize(format_string))\n",
    "        # Unpack the binary data according to the format string\n",
    "        unpacked_data = struct.unpack(format_string, data)\n",
    "\n",
    "        # Extract position, rotation, and occupation data\n",
    "        position = unpacked_data[:3]\n",
    "        rotation = unpacked_data[3:7]\n",
    "        # Convert occupation data to array of numbers\n",
    "        occupation = struct.unpack(str(occupation_size) + \"B\", unpacked_data[7])\n",
    "\n",
    "        return position, rotation, occupation\n",
    "    \n",
    "def load_stereo_image(index=0, \n",
    "                      dataset_path=\"./\", \n",
    "                      model_size=(IMG_SIZE, IMG_SIZE), \n",
    "                      l_path=None, \n",
    "                      r_path=None,\n",
    "                      plot=False,\n",
    "                      roffset=(0,0)\n",
    "                     ):\n",
    "    dx = -110 + roffset[0]\n",
    "    dy = -6 + roffset[1]\n",
    "    l_file = l_path if l_path is not None else os.path.join(dataset_path, f\"{index}L.png\")\n",
    "    r_file = r_path if r_path is not None else os.path.join(dataset_path, f\"{index}R.png\")\n",
    "    l_img = cv2.cvtColor(cv2.imread(l_file), cv2.COLOR_BGR2RGB)\n",
    "    l_img = cv2.warpAffine(l_img, np.float32([[1, 0, dx], [0, 1, dy]]), (l_img.shape[1], l_img.shape[0]))\n",
    "    r_img = cv2.cvtColor(cv2.imread(r_file), cv2.COLOR_BGR2RGB)\n",
    "    l_img = cv2.resize(l_img[0:714, 0:1170], model_size, interpolation=cv2.INTER_AREA)\n",
    "    r_img = cv2.resize(r_img[0:714, 0:1170], model_size, interpolation=cv2.INTER_AREA)\n",
    "    blended_image = cv2.addWeighted(l_img, 0.5, r_img, 0.5, 0)\n",
    "    \n",
    "    if plot:\n",
    "        # Plot the blended image\n",
    "        plt.title(f\"sample {index} ({model_size[0]}x{model_size[0]} 3+3 channel, aspect corrected)\")\n",
    "        plt.imshow(blended_image, aspect=1/1.4)\n",
    "        \n",
    "    return torch.tensor(l_img/255.0), torch.tensor(r_img/255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ad77e429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A few permutation helper functions\n",
    "\n",
    "def permute_target_tensor(t):\n",
    "    return torch.flip(t, dims=[2]).permute(2, 0, 1)\n",
    "\n",
    "def unpermute_target_tensor(t):\n",
    "    return torch.flip(t.permute(1, 2, 0), dims=[2])\n",
    "\n",
    "def crop_output(t):\n",
    "    return t[6:6+37, 12:12+25, 15:15+18]\n",
    "\n",
    "def crop_output_batch(t):\n",
    "    return t[:, 6:6+37, 12:12+25, 15:15+18]\n",
    "\n",
    "def expand_output(t):\n",
    "    return F.pad(t, get_padded_size(np.zeros(t.shape), 48))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3186ae78",
   "metadata": {},
   "source": [
    "We can now check that in the permutation output, the 0th axis matches the vertical axis running from top to bottom, and the 1st axis runs horizontally from left to right, as in the input 2d image. The 2nd axis could have been inverted so that boths configurations are more easy to match visually, but this won't make a difference when it comes to training the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3587869b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43eb90c6",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "In this section we will prepare the DataLoader pipeline so we can efficiently feed data to the model during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "266333fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model_input(l, r, permute=True):\n",
    "    \"\"\"Creates a tensor input datapoint to be fed into the model\n",
    "    from l and r images\n",
    "    Parameters:\n",
    "    - l: left image\n",
    "    - r: right image\n",
    "    - permute (bool): apply permutation\n",
    "    Returns:\n",
    "    torch.tensor\n",
    "    \"\"\"\n",
    "    if permute:\n",
    "        assert l.shape == (IMG_SIZE, IMG_SIZE, N_CHANNELS//2)\n",
    "        assert r.shape == (IMG_SIZE, IMG_SIZE, N_CHANNELS//2)\n",
    "        lr = torch.cat([l, r], dim=2).permute(2,0,1).float()\n",
    "    else:\n",
    "        assert l.shape == (N_CHANNELS//2, IMG_SIZE, IMG_SIZE)\n",
    "        assert r.shape == (N_CHANNELS//2, IMG_SIZE, IMG_SIZE)\n",
    "        lr = torch.cat([l, r], dim=0).float()\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6b8ece0f-1228-4868-8969-9b662a219dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quaternion_to_euler(q):\n",
    "    w, x, y, z = q\n",
    "    \n",
    "    roll = torch.atan2(torch.tensor(2 * (x * y + w * z)), torch.tensor(w**2 + x**2 - y**2 - z**2))\n",
    "    pitch = torch.asin(torch.clamp(torch.tensor(2 * (x * z - w * y)), -1.0, 1.0))\n",
    "    yaw = torch.atan2(torch.tensor(2 * (y * z + w * x)), torch.tensor(w**2 - x**2 - y**2 + z**2))\n",
    "    \n",
    "    return torch.tensor([roll+np.pi if roll<0 else roll-np.pi, pitch, yaw])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "36063a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataLoader(Dataset):\n",
    "    \"\"\"Class to load data from files in disk and convert\n",
    "    them to tensors on the fly\"\"\"\n",
    "    def __init__(self, data_dir, transform=None, additional_param=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.l_img_list = []\n",
    "        self.r_img_list = []\n",
    "        self.return_mode = \"occupancy\"\n",
    "        self.gt_list = []\n",
    "        self.return_pose = False\n",
    "        self.additional_param = additional_param\n",
    "        max_index = 0\n",
    "        min_index = 99999999\n",
    "        for file in sorted(os.listdir(data_dir), reverse=True):\n",
    "            if file.endswith(\"L.png\"):\n",
    "                index = int(file.replace(\"L.png\", \"\"))\n",
    "                if index>max_index:\n",
    "                    max_index = index\n",
    "                if index<min_index:\n",
    "                    min_index = index\n",
    "                self.l_img_list.append(os.path.join(data_dir, file))\n",
    "            elif file.endswith(\"R.png\"):\n",
    "                self.r_img_list.append(os.path.join(data_dir, file))\n",
    "            elif file.endswith(\"T.bin\"):\n",
    "                self.gt_list.append(os.path.join(data_dir, file))   \n",
    "        print(f\"Min index: {min_index},   Max index: {max_index},  N Items: {len(self.l_img_list)}\")\n",
    "        \n",
    "    def set_return_mode(self, mode, mean=None, std=None):\n",
    "        self.return_mode = mode\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.gt_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        roffset = self.additional_param[\"roffset\"] if \"roffset\" in self.additional_param else (0,0)\n",
    "        mean = self.additional_param[\"normal_mean\"] if \"normal_mean\" in self.additional_param else 0.0\n",
    "        std = self.additional_param[\"normal_std\"] if \"normal_std\" in self.additional_param else 1.0\n",
    "        l, r = load_stereo_image(l_path=self.l_img_list[idx], r_path=self.r_img_list[idx], roffset=roffset);\n",
    "        t, q, o = load_target_datapoint(self.gt_list[idx])\n",
    "\n",
    "        # Apply transformations if specified\n",
    "        if self.transform:\n",
    "            l = self.transform(l)\n",
    "            r = self.transform(r)\n",
    "\n",
    "        #img = np.zeros((l.shape[0], 2*l.shape[1]))\n",
    "        #img[:,:l.shape[1]] = l\n",
    "        #img[:,l.shape[1]:] = r\n",
    "\n",
    "        l = (l.permute(2, 0, 1) - mean)/std\n",
    "        r = (r.permute(2, 0, 1) - mean)/std\n",
    "\n",
    "        if \"augmentations\" in self.additional_param and self.additional_param[\"augmentations\"] is not None:\n",
    "\n",
    "            augment_contrast=self.additional_param[\"augmentations\"]['contrast'] if ('contrast' in self.additional_param[\"augmentations\"]) else 0\n",
    "            augment_saturation=self.additional_param[\"augmentations\"]['saturation'] if ('saturation' in self.additional_param[\"augmentations\"]) else 0\n",
    "            augment_brightness=self.additional_param[\"augmentations\"]['brightness'] if ('brightness' in self.additional_param[\"augmentations\"]) else 0\n",
    "            augment_hue=self.additional_param[\"augmentations\"]['hue'] if ('hue' in self.additional_param[\"augmentations\"]) else 0\n",
    "            augment_noise=self.additional_param[\"augmentations\"]['noise'] if ('noise' in self.additional_param[\"augmentations\"]) else 0\n",
    "    \n",
    "            # Augment each image separately, as l and r cameras are independent\n",
    "    \n",
    "            l = transforms.functional.adjust_brightness(l, 1 + (random.random() - 0.5) * 2 * augment_brightness)\n",
    "            l = transforms.functional.adjust_contrast(l, 1 + (random.random() - 0.5) * 2 * augment_contrast)\n",
    "            l = transforms.functional.adjust_saturation(l, 1 + (random.random() - 0.5) * 2 * augment_saturation)\n",
    "            l = transforms.functional.adjust_hue(l, (random.random() - 0.5) * 2 * augment_hue)\n",
    "            noise = np.random.normal(0, augment_noise, l.shape).astype(np.float32)\n",
    "            l = l + noise\n",
    "            l = torch.clip(l, 0, 1)\n",
    "    \n",
    "            r = transforms.functional.adjust_brightness(r, 1 + (random.random() - 0.5) * 2 * augment_brightness)\n",
    "            r = transforms.functional.adjust_contrast(r, 1 + (random.random() - 0.5) * 2 * augment_contrast)\n",
    "            r = transforms.functional.adjust_saturation(r, 1 + (random.random() - 0.5) * 2 * augment_saturation)\n",
    "            r = transforms.functional.adjust_hue(r, (random.random() - 0.5) * 2 * augment_hue)\n",
    "            noise = np.random.normal(0, augment_noise, r.shape).astype(np.float32)\n",
    "            r = r + noise\n",
    "            r = torch.clip(r, 0, 1)\n",
    "\n",
    "        X = make_model_input(l, r, permute=False)\n",
    "\n",
    "        if self.return_mode == \"position\":\n",
    "            y = np.zeros(3, dtype=np.float32)\n",
    "            y[0:3] = ((torch.tensor(t)).float())# - self.mean[0:3]) / self.std[0:3]# <1 range\n",
    "            #y[3:7] = ((torch.tensor(q)).float() - self.mean[3:7]) / self.std[3:7]# <1 range\n",
    "            #euler_angles = quaternion_to_euler(q)\n",
    "            #y[3:7] = torch.zeros(4)\n",
    "            #y[0:3] = ((torch.tensor(t)).float()) # <1 range\n",
    "            #y[3:7] = ((torch.tensor(q)).float()) # <1 range\n",
    "            return X,y\n",
    "\n",
    "        if self.return_mode == \"rotation\":\n",
    "            y = np.zeros(3, dtype=np.float32)\n",
    "            #y[0:3] = ((torch.tensor(t)).float())# - self.mean[0:3]) / self.std[0:3]# <1 range\n",
    "            #y[3:7] = ((torch.tensor(q)).float() - self.mean[3:7]) / self.std[3:7]# <1 range\n",
    "            euler_angles = quaternion_to_euler(q)\n",
    "            y[0:3] = euler_angles.clone().detach()\n",
    "            #y[0:3] = ((torch.tensor(t)).float()) # <1 range\n",
    "            #y[3:7] = ((torch.tensor(q)).float()) # <1 range\n",
    "            return X,y\n",
    "            \n",
    "        occupation = torch.tensor(np.array(o, dtype='float32').reshape(37,25,18))\n",
    "        occupation = expand_output(occupation)\n",
    "        y = permute_target_tensor(occupation)\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1d7335",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8a82a520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min index: 13171,   Max index: 13870,  N Items: 25\n",
      "Min index: 32639,   Max index: 32643,  N Items: 5\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DATASET_PATH = \"../reduced-dataset/train\"\n",
    "TEST_DATASET_PATH = \"../reduced-dataset/test\"\n",
    "\n",
    "aug_params = {\n",
    "    'contrast': 0.2,\n",
    "    'brightness': 0.2,\n",
    "    'saturation': 0.2,\n",
    "    'hue': 0.2,\n",
    "    'noise': 0.02\n",
    "}\n",
    "\n",
    "train_dataloader = CustomDataLoader(TRAIN_DATASET_PATH, additional_param={\"augmentations\": None, \"roffset\":(0,0)})\n",
    "train_loader = DataLoader(train_dataloader, batch_size=BATCH_SIZE)\n",
    "\n",
    "test_dataloader = CustomDataLoader(TEST_DATASET_PATH, additional_param={\"augmentations\":None, \"roffset\":(0,0)})\n",
    "test_loader = DataLoader(test_dataloader, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1a437b",
   "metadata": {},
   "source": [
    "## Dataset normalization\n",
    "For increased stability, generalization and rapid convergence, let us calculate the mean and standard deviation of the dataset. This mean and std will be single scalars that will be subtracted and divided from the datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f3c40987",
   "metadata": {},
   "outputs": [],
   "source": [
    "#debug_loader = DataLoader(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "049bd893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total imgs: 25\n",
      "Dataset mean: 0.7929257154464722\n",
      "Dataset std: 0.18029381334781647\n"
     ]
    }
   ],
   "source": [
    "mean_x = 0\n",
    "std_x = 0\n",
    "total_imgs = 0\n",
    "for batch in train_loader:\n",
    "    x = batch[0]\n",
    "    mean_x += x.mean() * x.shape[0]\n",
    "    std_x += x.std() * x.shape[0]\n",
    "    total_imgs += x.shape[0]\n",
    "    print(f\"total imgs: {total_imgs}\")\n",
    "dataset_mean = mean_x/total_imgs\n",
    "print(f\"Dataset mean: {dataset_mean}\")\n",
    "dataset_std = std_x/total_imgs\n",
    "print(f\"Dataset std: {dataset_std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb5e5ab-9021-4b04-878b-a5c51e7dff46",
   "metadata": {},
   "source": [
    "Almacenemos estos valores en dataset_mean y dataset_std, y apliquémos estos valores a la carga de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "cae9b666-fee9-4447-9ce9-7b296e213e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min index: 13171,   Max index: 13870,  N Items: 25\n",
      "Min index: 32639,   Max index: 32643,  N Items: 5\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = CustomDataLoader(TRAIN_DATASET_PATH, additional_param={\"augmentations\": None, \n",
    "                                                                          \"normal_mean\": dataset_mean,\n",
    "                                                                          \"normal_std\": dataset_std,\n",
    "                                                                          \"roffset\":(0,0)})\n",
    "train_loader = DataLoader(train_dataloader, batch_size=BATCH_SIZE)\n",
    "\n",
    "test_dataloader = CustomDataLoader(TEST_DATASET_PATH, additional_param={\"augmentations\":None, \n",
    "                                                                        \"normal_mean\": dataset_mean,\n",
    "                                                                        \"normal_std\": dataset_std,\n",
    "                                                                        \"roffset\":(0,0)})\n",
    "test_loader = DataLoader(test_dataloader, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "54645b39-b808-4ad5-b77b-84ca1d2746b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.9073e-08)\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# We make sure loaded train data statistics are what we expect\n",
    "for batch in train_loader:\n",
    "    x = batch[0]\n",
    "    print(torch.mean(x))\n",
    "    print(torch.std(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "bd9533ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "\n",
    "# Try to load\n",
    "try:\n",
    "    pos_weights = torch.load('pos_weights.pt')\n",
    "except:\n",
    "    # if error, calculate and save\n",
    "    dataloader.set_return_mode(\"occupancy\")\n",
    "    pos_weights = torch.ones((48, 48, 48))\n",
    "    total = 0\n",
    "    max_batch = 5000*32\n",
    "    for batch in dataloader:\n",
    "        y = batch[1]\n",
    "        #print(y.shape)\n",
    "        pos_weights += torch.sum(y, dim=0)\n",
    "        total += y.shape[0]\n",
    "        #print(max_batch)\n",
    "        if (max_batch%5000)==0:\n",
    "            print(\".\", end=\"\")\n",
    "        max_batch-=1\n",
    "        if max_batch == 0:\n",
    "            break\n",
    "    pos_weights = (pos_weights/total) + 1\n",
    "weights = torch.clamp(1.0 / (pos_weights - 1 + 0.01), max=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98237c7e",
   "metadata": {},
   "source": [
    "#Calculemos la media y desviación estándar del vector de pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4ef848fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.4469205e+02  7.3269678e+02  4.9531940e+02  1.2743019e-01\n",
      "  1.2756923e-01 -6.9544047e-01  6.9537848e-01]\n",
      "[1.5945981e+01 1.9488235e+01 8.6593685e+00 9.9771069e-03 1.0023176e-02\n",
      " 7.2440053e-03 7.2297286e-03]\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing\n",
    "\n",
    "try:\n",
    "    with open('./pose_mean.pkl', 'rb') as file:\n",
    "        pose_mean = pickle.load(file)\n",
    "    with open('./pose_std.pkl', 'rb') as file:\n",
    "        pose_std = pickle.load(file)\n",
    "except:\n",
    "    pose_data = []\n",
    "    dataloader.set_return_mode(\"position\")\n",
    "    pos_weights = torch.ones((48, 48, 48))\n",
    "    total = 0\n",
    "    max_batch = 1000\n",
    "    for batch in dataloader:\n",
    "        y = batch[1]\n",
    "        pose_data.append(y)\n",
    "        if (max_batch%5000)==0:\n",
    "            print(\".\", end=\"\")\n",
    "        max_batch-=1\n",
    "        if max_batch == 0:\n",
    "            break\n",
    "    # We'd better write these down as they are expensive to calculate\n",
    "    pose_mean = np.mean(np.array(pose_data), axis=0)\n",
    "    pose_std = np.std(np.array(pose_data), axis=0)\n",
    "print(pose_mean)\n",
    "print(pose_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb763d5e",
   "metadata": {},
   "source": [
    "## Model\n",
    "This section will define the model that will be used for the training plus the training function and loss function(s). We will implement the VOXELNet arquitecture here as described in the master's thesis report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8b0bf306",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_inflate(input_tensor):\n",
    "    \"\"\"\n",
    "    Inflates towards the 2nd axis by\n",
    "    producing multiple copies of the\n",
    "    0th-1st axis slice\n",
    "    \"\"\"\n",
    "    # Get the shape of the input tensor\n",
    "    batch_size, C, _, N = input_tensor.shape\n",
    "\n",
    "    # Reshape the input tensor to add a singleton dimension at the end\n",
    "    inflated_tensor = input_tensor.unsqueeze(-1)\n",
    "\n",
    "    # Repeat the singleton dimension N times along the last axis\n",
    "    inflated_tensor = inflated_tensor.expand(-1, -1, -1, -1, N)\n",
    "\n",
    "    return inflated_tensor\n",
    "\n",
    "\n",
    "class DoubleConv2D(nn.Module):\n",
    "    \"\"\"\n",
    "    Double Convolution 2D\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv2D, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, 1, 1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ELU(inplace=True) ## ERA ReLU\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, 1, 1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)     \n",
    "        x = self.bn1(x)     \n",
    "        x = self.relu(x)       \n",
    "        x = self.conv2(x)      \n",
    "        x = self.bn2(x)     \n",
    "        x = self.relu(x)       \n",
    "        return x\n",
    "\n",
    "        \n",
    "class DoubleConv3D(nn.Module):\n",
    "    \"\"\"\n",
    "    Double Convolution 3D\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv3D, self).__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.ELU(inplace=True), # era ReLU\n",
    "            nn.Conv3d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "class VoxelNet_v1(nn.Module):\n",
    "    \"\"\"\n",
    "    VoxelNet, U-Net inspired network which will\n",
    "    map a 6 channel, stereo RGB image into a\n",
    "    3d 64x64x64 occupation probability map\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, steps=5):\n",
    "        super(VoxelNet_v1, self).__init__()\n",
    "\n",
    "        self.encoder = nn.ModuleList()\n",
    "        self.decoder = nn.ModuleList()\n",
    "        self.residual_connections = nn.ModuleList()\n",
    "        self.steps = steps\n",
    "        self.relu = nn.ReLU()\n",
    "        self.elu = nn.ELU()\n",
    "        self.mode = \"occupancy\"\n",
    "        self.pool1d = nn.AvgPool1d(kernel_size=2)\n",
    "\n",
    "        features = [2 ** (i+4) for i in range(steps)]\n",
    "\n",
    "        # Encoder\n",
    "        for feature in features:\n",
    "            self.encoder.append(\n",
    "                    DoubleConv2D(in_channels, feature),\n",
    "            )\n",
    "            in_channels = feature\n",
    "\n",
    "        out_ch = in_channels\n",
    "        \n",
    "        # Decoder\n",
    "        for i in range(1,self.steps-2):\n",
    "            # Let's try the last layer trick\n",
    "            self.decoder.append(\n",
    "                nn.Sequential(\n",
    "                    nn.ConvTranspose3d(out_ch*2, out_ch, kernel_size=2 if i<self.steps-3 else 3, stride=2 if i<self.steps-3 else 3),\n",
    "                    DoubleConv3D(out_ch, out_ch//2)\n",
    "                )\n",
    "            )\n",
    "            out_ch = out_ch//2\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.final_conv_1 = nn.Conv3d(64, 32, kernel_size=1)\n",
    "        self.final_conv_2 = nn.Conv3d(32, 16, kernel_size=1)\n",
    "        self.final_conv_3 = nn.Conv3d(16, 4, kernel_size=1)\n",
    "        self.final_conv_4 = nn.Conv3d(4, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(x.shape)\n",
    "        was_training = self.training\n",
    "        encoder_outputs = []\n",
    "\n",
    "        \n",
    "        # Encoder\n",
    "        n = 0\n",
    "        for module in self.encoder:\n",
    "            n+=1\n",
    "            x = module(x)\n",
    "            x = self.pool(x)\n",
    "            print(f\"encoder {n}: {x.shape}\")\n",
    "            encoder_outputs.append(x)\n",
    "        \n",
    "        x = copy_inflate(x)#x.unsqueeze(-1)\n",
    "        print(\"LATENTS HERE\")\n",
    "        print(x.shape)\n",
    "        \n",
    "        # Decoder\n",
    "        for i in range(1,self.steps-2):\n",
    "            residual_connection = encoder_outputs[-i]\n",
    "            print(f\"res conn shape: {residual_connection.shape}\")\n",
    "            inflated_connection = copy_inflate(residual_connection)\n",
    "            print(f\"inflated conn shape: {inflated_connection.shape}\")\n",
    "            x = torch.cat([x, inflated_connection], dim=1)\n",
    "            x = self.decoder[i-1](x)\n",
    "            print(f\"dencoder {i}: {x.shape}\")\n",
    "\n",
    "        print(f\"before final conv1 {x.shape}\")\n",
    "        x = self.final_conv_1(x)\n",
    "        x = self.elu(x) # relu\n",
    "        print(f\"before final conv2 {x.shape}\")\n",
    "        x = self.final_conv_2(x)\n",
    "        x = self.elu(x) # relu\n",
    "        print(f\"before final conv3 {x.shape}\")\n",
    "        x = self.final_conv_3(x)\n",
    "        x = self.elu(x) # relu\n",
    "        print(f\"before final conv4 {x.shape}\")\n",
    "        x = self.final_conv_4(x).squeeze(dim=1)\n",
    "\n",
    "        return x\n",
    "\n",
    "class VoxelNet_v4(nn.Module):\n",
    "    \"\"\"\n",
    "    VoxelNet, U-Net inspired network which will\n",
    "    map a 6 channel, stereo RGB image into a\n",
    "    3d 64x64x64 occupation probability map\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, steps=5):\n",
    "        super(VoxelNet_v4, self).__init__()\n",
    "\n",
    "        self.encoder = nn.ModuleList()\n",
    "        self.decoder = nn.ModuleList()\n",
    "        self.residual_connections = nn.ModuleList()\n",
    "        self.steps = steps\n",
    "        self.relu = nn.ReLU()\n",
    "        self.elu = nn.ELU()\n",
    "        self.mode = \"occupancy\"\n",
    "        self.pool1d = nn.AvgPool1d(kernel_size=2)\n",
    "\n",
    "        features = [2 ** (i+4) for i in range(steps)]\n",
    "\n",
    "        # Encoder\n",
    "        for feature in features:\n",
    "            self.encoder.append(\n",
    "                    DoubleConv2D(in_channels, feature),\n",
    "            )\n",
    "            in_channels = feature\n",
    "\n",
    "        out_ch = in_channels\n",
    "        \n",
    "        # Decoder\n",
    "        for i in range(1,6):\n",
    "            # Let's try the last layer trick\n",
    "            self.decoder.append(\n",
    "                nn.Sequential(\n",
    "                    nn.ConvTranspose3d(out_ch*2, out_ch, kernel_size=2 if i<5 else 3, stride=2 if i<5 else 3),\n",
    "                    DoubleConv3D(out_ch, out_ch//2)\n",
    "                )\n",
    "            )\n",
    "            out_ch = out_ch//2\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.final_conv_1 = nn.Conv3d(64, 32, kernel_size=1)\n",
    "        self.final_conv_2 = nn.Conv3d(32, 16, kernel_size=1)\n",
    "        self.final_conv_3 = nn.Conv3d(16, 4, kernel_size=1)\n",
    "        self.final_conv_4 = nn.Conv3d(4, out_channels, kernel_size=1)\n",
    "\n",
    "        self.pose_dense_1 = nn.Linear(2 ** (self.steps+4-1), 256)\n",
    "        self.pose_dense_2 = nn.Linear(256, 64)\n",
    "        self.pose_dense_3 = nn.Linear(64, 16)\n",
    "        self.pose_dense_4 = nn.Linear(16, 7)\n",
    "\n",
    "    def set_mode(self, mode):\n",
    "        freeze_pose = True\n",
    "        if mode=='occupancy':\n",
    "            freeze_pose = True\n",
    "        elif mode=='pose' or mode=='position' or mode=='rotation':\n",
    "            freeze_pose = False\n",
    "        else:\n",
    "            raise ValueException(\"Unknown mode\")\n",
    "        self.mode = mode\n",
    "        # Freeze layer1 and layer2\n",
    "        for param in self.encoder.parameters():\n",
    "            param.requires_grad = freeze_pose\n",
    "        for param in self.decoder.parameters():\n",
    "            param.requires_grad = freeze_pose\n",
    "        for param in self.residual_connections.parameters():\n",
    "            param.requires_grad = freeze_pose\n",
    "        for param in self.final_conv_1.parameters():\n",
    "            param.requires_grad = freeze_pose\n",
    "        for param in self.final_conv_2.parameters():\n",
    "            param.requires_grad = freeze_pose\n",
    "        for param in self.final_conv_3.parameters():\n",
    "            param.requires_grad = freeze_pose\n",
    "        for param in self.final_conv_4.parameters():\n",
    "            param.requires_grad = freeze_pose\n",
    "        for param in self.pose_dense_1.parameters():\n",
    "            param.requires_grad = not freeze_pose\n",
    "        for param in self.pose_dense_2.parameters():\n",
    "            param.requires_grad = not freeze_pose\n",
    "        for param in self.pose_dense_3.parameters():\n",
    "            param.requires_grad = not freeze_pose\n",
    "        for param in self.pose_dense_4.parameters():\n",
    "            param.requires_grad = not freeze_pose\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        was_training = self.training\n",
    "        encoder_outputs = []\n",
    "\n",
    "        if(self.mode == \"pose\"):\n",
    "            # Do not update BatchNormalization Statistics\n",
    "            self.eval()\n",
    "            with torch.no_grad():\n",
    "                # Encoder\n",
    "                for module in self.encoder:\n",
    "                    x = module(x)\n",
    "                    x = self.pool(x)\n",
    "                    encoder_outputs.append(x)\n",
    "        else:\n",
    "            # Encoder\n",
    "            for module in self.encoder:\n",
    "                x = module(x)\n",
    "                x = self.pool(x)\n",
    "                encoder_outputs.append(x)\n",
    "        \n",
    "        if self.mode == \"pose\":\n",
    "            if was_training:\n",
    "                self.train()\n",
    "            #print(f\"{encoder_outputs[-2].shape}\")\n",
    "            s = torch.flatten(encoder_outputs[-2], start_dim=1)\n",
    "            #print(f\"s shape {s.shape}  max {torch.max(s)}   min {torch.min(s)}\")\n",
    "            #x_pose = self.pool1d(s)# + x[:,:,0,0] * 5e7 #x[:,:,0,0]*1e8\n",
    "            x_pose1 = torch.flatten(encoder_outputs[-2], start_dim=1)\n",
    "            x_pose2 = torch.flatten(encoder_outputs[-3], start_dim=1)\n",
    "            x_pose = x[:,:,0,0] #x[:,:,0,0]*1e8\n",
    "            concatenated = torch.cat((x_pose1, x_pose2, x_pose), dim=1)\n",
    "            return concatenated\n",
    "            #x_pose = x[:,:,0,0] * 5e7\n",
    "            #print(f\"x shape {x_pose.shape}  max {torch.max(x_pose)}   min {torch.min(x_pose)} first values {x_pose[:,0:10]}\")\n",
    "            x_pose = self.pose_dense_1(x_pose)\n",
    "            x_pose = self.elu(x_pose)\n",
    "            #print(f\"1 {x_pose}\")\n",
    "            #if self.pose_dense_1.weight.grad is not None:\n",
    "            #    print(self.pose_dense_1.weight.grad.detach().cpu().numpy())\n",
    "            #else:\n",
    "            #    print(f\"pose_dense_1 grad is None\")\n",
    "            x_pose = self.pose_dense_2(x_pose)\n",
    "            x_pose = self.elu(x_pose)\n",
    "            #print(f\"2 {x_pose}\")\n",
    "            x_pose = self.pose_dense_3(x_pose)\n",
    "            x_pose = self.elu(x_pose)\n",
    "            print(f\"weights 3: {self.pose_dense_3.weight.detach().cpu().numpy()}\")\n",
    "            #print(f\"3 {x_pose}\")\n",
    "            x_pose = self.pose_dense_4(x_pose)\n",
    "            #print(f\"4 {x_pose}\")\n",
    "            if self.pose_dense_4.weight.grad is not None:\n",
    "                print(f\"grad: {self.pose_dense_4.weight.grad.detach().cpu().numpy()}\")\n",
    "            else:\n",
    "                print(f\"pose_dense_4 grad is None\")\n",
    "            print(f\"weights 4: {self.pose_dense_4.weight.detach().cpu().numpy()}\")\n",
    "            return x_pose\n",
    "        x = x.unsqueeze(-1)\n",
    "        \n",
    "        # Decoder\n",
    "        for i in range(1,6):\n",
    "            residual_connection = encoder_outputs[-i]\n",
    "            inflated_connection = copy_inflate(residual_connection)\n",
    "            x = torch.cat([x, inflated_connection], dim=1)\n",
    "            x = self.decoder[i-1](x)\n",
    "        \n",
    "        x = self.final_conv_1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.final_conv_2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.final_conv_3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.final_conv_4(x).squeeze(dim=1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a85f9edf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(278688377, 1114753508, '278M', '1063MB')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = VoxelNet_v1(in_channels=6, out_channels=1, steps=8).to(device)\n",
    "\n",
    "# Let's check the number of parameters and memory occupied by the model\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a069be28-9310-4f21-aae4-3172b6cc13c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VoxelNet_v1(\n",
       "  (encoder): ModuleList(\n",
       "    (0): DoubleConv2D(\n",
       "      (conv1): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ELU(alpha=1.0, inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): DoubleConv2D(\n",
       "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ELU(alpha=1.0, inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): DoubleConv2D(\n",
       "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ELU(alpha=1.0, inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): DoubleConv2D(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ELU(alpha=1.0, inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): DoubleConv2D(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ELU(alpha=1.0, inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): DoubleConv2D(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ELU(alpha=1.0, inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (6): DoubleConv2D(\n",
       "      (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ELU(alpha=1.0, inplace=True)\n",
       "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (7): DoubleConv2D(\n",
       "      (conv1): Conv2d(1024, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ELU(alpha=1.0, inplace=True)\n",
       "      (conv2): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (decoder): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): ConvTranspose3d(4096, 2048, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "      (1): DoubleConv3D(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv3d(2048, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ELU(alpha=1.0, inplace=True)\n",
       "          (3): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (4): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): ConvTranspose3d(2048, 1024, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "      (1): DoubleConv3D(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv3d(1024, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ELU(alpha=1.0, inplace=True)\n",
       "          (3): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (4): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): ConvTranspose3d(1024, 512, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "      (1): DoubleConv3D(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ELU(alpha=1.0, inplace=True)\n",
       "          (3): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (4): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): ConvTranspose3d(512, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "      (1): DoubleConv3D(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ELU(alpha=1.0, inplace=True)\n",
       "          (3): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (4): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): ConvTranspose3d(256, 128, kernel_size=(3, 3, 3), stride=(3, 3, 3))\n",
       "      (1): DoubleConv3D(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ELU(alpha=1.0, inplace=True)\n",
       "          (3): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (4): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (residual_connections): ModuleList()\n",
       "  (relu): ReLU()\n",
       "  (elu): ELU(alpha=1.0)\n",
       "  (pool1d): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (final_conv_1): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "  (final_conv_2): Conv3d(32, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "  (final_conv_3): Conv3d(16, 4, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "  (final_conv_4): Conv3d(4, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       ")"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3a490603",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'l' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[105], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Let's make one datapoint go through the network to make sure it all tensor shapes\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# are coherent\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m in_data \u001b[38;5;241m=\u001b[39m make_model_input(\u001b[43ml\u001b[49m, r)\u001b[38;5;241m.\u001b[39munsqueeze(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m model\u001b[38;5;241m.\u001b[39mforward(in_data)\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m48\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'l' is not defined"
     ]
    }
   ],
   "source": [
    "# Let's make one datapoint go through the network to make sure it all tensor shapes\n",
    "# are coherent\n",
    "in_data = make_model_input(l, r).unsqueeze(dim=0).to(device)\n",
    "\n",
    "assert model.forward(in_data).shape == (1, 48, 48, 48)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66604320",
   "metadata": {},
   "source": [
    "## Training\n",
    "This section will include a training function and the appropriate loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "79065f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_weight = 0.75\n",
    "def weighted_cross_entropy_with_logits(logits, labels):\n",
    "    #log_weight = 1 + (pos_weight - 1) * labels\n",
    "    log_weight = pos_weight * labels\n",
    "    loss = (1 - labels) * logits + log_weight * (torch.log1p(torch.exp(-torch.abs(logits))) + F.relu(-logits))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c267374e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC\n",
    "\n",
    "class Metric(ABC):\n",
    "    \"\"\"Abstract metric class, to be inherited from\"\"\"\n",
    "    def __init__(self, name):\n",
    "        self.channels = {}\n",
    "        self.name = name\n",
    "\n",
    "    def initialize(self):\n",
    "        pass\n",
    "\n",
    "    def reset(self):\n",
    "        self.channels = {}\n",
    "\n",
    "    def print(self):\n",
    "        if len(self.channels.keys())==0:\n",
    "            print(\"<Empty>\")\n",
    "            return\n",
    "        for channel in self.channels:\n",
    "            print(f\"[{self.name} - {channel}] {self.channels[channel]}\")\n",
    "\n",
    "    def calculate(self, channel, preds, gt, log_to_wandb=None):\n",
    "        pass\n",
    "\n",
    "    def append_result(self, channel, value):\n",
    "        if channel not in self.channels:\n",
    "            self.channels[channel] = []\n",
    "        self.channels[channel].append(value)\n",
    "\n",
    "    def average(self, channel):\n",
    "        if channel in self.channels:\n",
    "            total = 0\n",
    "            for val in self.channels[channel]:\n",
    "                total += val\n",
    "            self.channels[channel] = [total / len(self.channels[channel])]\n",
    "\n",
    "    def log_latest(self, channel, log_to_wandb=None):\n",
    "        if channel in self.channels and len(self.channels[channel])>0:\n",
    "            print(f\"[{self.name} - {channel}] {self.channels[channel][-1]}\")\n",
    "            if log_to_wandb is not None:\n",
    "                print(f\"Adding in dict for wandb: '{channel}_{self.name}': {self.channels[channel][-1]}\")\n",
    "                log_to_wandb[f'{channel}_{self.name}'] = self.channels[channel][-1]\n",
    "\n",
    "class MisclassificationRate(Metric):\n",
    "    \"\"\"Calculates the misclassification rate\"\"\"\n",
    "    def __init__(self, threshold=0.5):\n",
    "        super().__init__('misclassification_rate')\n",
    "        self.threshold = threshold\n",
    "        \n",
    "    def calculate(self, channel, preds, gt, log_to_wandb=None):\n",
    "        with torch.no_grad():\n",
    "            misclassified = 0\n",
    "            target_class = gt > 0.5\n",
    "            occ = torch.sigmoid(preds)\n",
    "            occ = (occ-torch.min(occ)) / (torch.max(occ)-torch.min(occ))\n",
    "            pred_class = occ > self.threshold\n",
    "            misclassified = (target_class != pred_class).sum().item()\n",
    "            self.append_result(channel, misclassified)\n",
    "\n",
    "class MeanSquaredError(Metric):\n",
    "    \"\"\"Calculates the mean squared error\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__('mean_squared_error')\n",
    "        \n",
    "    def calculate(self, channel, preds, gt, log_to_wandb=None):\n",
    "        with torch.no_grad():\n",
    "            error = (1/preds.shape[0]) * torch.mean((preds-gt)**2)\n",
    "            self.append_result(channel, error.item())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "dd1e34e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mscr = MisclassificationRate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "bbe75cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function definition\n",
    "\n",
    "def train_model(model, \n",
    "                dloader, \n",
    "                optimizer,\n",
    "                config, \n",
    "                val_every_n_minibatches=1, \n",
    "                metrics_every_n_minibatches=64,\n",
    "                start_at=0, \n",
    "                initial_epoch=0,\n",
    "                autosave_every=30, \n",
    "                num_epochs=10, \n",
    "                device=device, \n",
    "                debug=False, \n",
    "                name=\"untitled\",\n",
    "                metrics=[],\n",
    "                criterion=None,\n",
    "                suffix=\"\",\n",
    "                validation=None, \n",
    "                log_to_wandb=False, \n",
    "                show_grad_norm=False):\n",
    "    \"\"\"\n",
    "    Trains a torch model\n",
    "    \"\"\"\n",
    "    print(f\" initial lr: {config['initial_learning_rate']}, weight_decay: {config['weight_decay']}\")\n",
    "\n",
    "    if criterion == None:\n",
    "        raise ValueException(\"Criterion must be specified\")\n",
    "    last_lr = config['initial_learning_rate']\n",
    "\n",
    "    # Agregamos scheduler de tipo ReduceLROnPlateau\n",
    "    scheduler = ReduceLROnPlateau(optimizer, \n",
    "                                  mode='min', \n",
    "                                  factor=config['lrfactor'], \n",
    "                                  min_lr=config['min_lr'], \n",
    "                                  patience=config['patience'])\n",
    "\n",
    "    dataset_length = None\n",
    "    epoch_loss = -1\n",
    "    total_batch_count = 0\n",
    "    start_time = time.time()\n",
    "    train_start_time = start_time\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        gather_dict = {}\n",
    "        \n",
    "        model.train()  # Set the model to training mode\n",
    "        running_loss = 0.0 # runnin loss is accumulated loss per epoch, we need then to divide per n_minibatches\n",
    "        val_loss = 0.0\n",
    "        batch_step = 0\n",
    "        batch_counter=0\n",
    "        train_samples = 0\n",
    "        \n",
    "        for batch in tqdm(dloader, desc=\"Epoch\", unit=\"minibatches\"): # Takes a minibatch of data\n",
    "            inputs, targets = batch[0].to(device), batch[1].to(device)\n",
    "            train_samples += inputs.shape[0]\n",
    "            optimizer.zero_grad()  # Clears gradients\n",
    "\n",
    "            outputs = model(inputs) # outputs are predictions\n",
    "            \n",
    "            loss = criterion(outputs, targets) # Calculates loss\n",
    "            loss.backward()  # Backpropagation\n",
    "            print(loss)\n",
    "            optimizer.step()  # Updates models parameters\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for metric in metrics:\n",
    "                    metric.calculate('train', outputs, targets)\n",
    "            \n",
    "            batch_step += 1\n",
    "\n",
    "            \n",
    "        epoch_loss = running_loss / batch_step\n",
    "        \n",
    "        # Epoch completed\n",
    "        for metric in metrics:\n",
    "            metric.average('train')\n",
    "            metric.log_latest('train', log_to_wandb=gather_dict)\n",
    "            metric.reset()\n",
    "\n",
    "        # Step the scheduler with the epoch_loss\n",
    "        scheduler.step(loss.item()) # Actualiza scheduler de LR\n",
    "        for param_group in optimizer.param_groups: # Lee lr actual\n",
    "            last_lr = param_group['lr']\n",
    "            \n",
    "        # Calculate validation loss\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_batches = 0\n",
    "            running_val_loss = 0\n",
    "            running_val_mis = 0\n",
    "            for batch in validation:\n",
    "\n",
    "                val_input, val_targets = batch[0].to(device), batch[1].to(device)\n",
    "                val_batches += 1\n",
    "                val_pred = model(val_input)\n",
    "\n",
    "                val_loss = criterion(val_pred, val_targets) # Calculates loss\n",
    "                \n",
    "                running_val_loss += val_loss.item()\n",
    "\n",
    "                for metric in metrics:\n",
    "                    metric.calculate('validation', val_pred, val_targets)\n",
    "\n",
    "            val_loss = running_val_loss / val_batches\n",
    "\n",
    "            for metric in metrics:\n",
    "                metric.average('validation')\n",
    "                metric.log_latest('validation', log_to_wandb=gather_dict)\n",
    "                metric.reset()\n",
    "                    \n",
    "            if val_batches > 0:\n",
    "                val_loss = running_val_loss / val_batches\n",
    "                print(f\"\\nVal loss: {val_loss},  val batches: {val_batches}\")\n",
    "                \n",
    "            model.train() # Back to train mode\n",
    "\n",
    "        gather_dict['train_loss'] = epoch_loss\n",
    "        gather_dict['val_loss'] = epoch_loss\n",
    "        gather_dict['lr'] = last_lr\n",
    "        if log_to_wandb:\n",
    "            print(f\"Logging to wandb: {gather_dict}\")\n",
    "            wandb.log(gather_dict)\n",
    "            \n",
    "        for param_group in optimizer.param_groups: # Lee lr actual\n",
    "            last_lr = param_group['lr']\n",
    "            \n",
    "        print(f\"\\n\\n   Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss}, lr: {last_lr}\")\n",
    "\n",
    "    torch.save(model.state_dict(), f\"./model_checkpoint_finish_{config['model']+suffix}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "080f3dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'initial_learning_rate': 0.006,\n",
    "    'weight_decay': 0.00001,\n",
    "    'lrfactor': 1/1.01,\n",
    "    'model': 'VoxelNet_v1_test_4',\n",
    "    'description': 'With augmentation',\n",
    "    'experiment': 1003,\n",
    "    'min_lr': 1e-8,\n",
    "    'patience': 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "0c89ff28",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=config['initial_learning_rate'], weight_decay=config['weight_decay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0a17d8df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:gpmke4m5) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▇▆▅▄▄▃▂▂▁▁</td></tr><tr><td>train_misclassification_rate</td><td>█▂▅▅▇▃▂▂▁▁▁</td></tr><tr><td>val_loss</td><td>█▇▆▅▄▄▃▂▂▁▁</td></tr><tr><td>validation_misclassification_rate</td><td>▃▅█▃▁▃▄▃▃▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr</td><td>0.0006</td></tr><tr><td>train_loss</td><td>0.54633</td></tr><tr><td>train_misclassification_rate</td><td>439592.0</td></tr><tr><td>val_loss</td><td>0.54633</td></tr><tr><td>validation_misclassification_rate</td><td>78845.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lilac-feather-69</strong> at: <a href='https://wandb.ai/quantum_spin_glass/MUIA%20UAX%202023%202024/runs/gpmke4m5' target=\"_blank\">https://wandb.ai/quantum_spin_glass/MUIA%20UAX%202023%202024/runs/gpmke4m5</a><br/> View project at: <a href='https://wandb.ai/quantum_spin_glass/MUIA%20UAX%202023%202024' target=\"_blank\">https://wandb.ai/quantum_spin_glass/MUIA%20UAX%202023%202024</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240908_160458-gpmke4m5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:gpmke4m5). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acd9e0fe827c4dfab95b57a0adb99897",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112956566669002, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.9 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/media/emilio/2TBDrive/MUIA-UAX-TFM/notebooks/wandb/run-20240908_161437-nc0g7mmv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/quantum_spin_glass/MUIA%20UAX%202023%202024/runs/nc0g7mmv' target=\"_blank\">dazzling-wave-70</a></strong> to <a href='https://wandb.ai/quantum_spin_glass/MUIA%20UAX%202023%202024' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/quantum_spin_glass/MUIA%20UAX%202023%202024' target=\"_blank\">https://wandb.ai/quantum_spin_glass/MUIA%20UAX%202023%202024</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/quantum_spin_glass/MUIA%20UAX%202023%202024/runs/nc0g7mmv' target=\"_blank\">https://wandb.ai/quantum_spin_glass/MUIA%20UAX%202023%202024/runs/nc0g7mmv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# start a new wandb run to track this script\n",
    "run = wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"MUIA UAX 2023 2024\",\n",
    "\n",
    "    # track hyperparameters and run metadata\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "0d352299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min index: 13171,   Max index: 13870,  N Items: 25\n",
      "Min index: 32639,   Max index: 32643,  N Items: 5\n"
     ]
    }
   ],
   "source": [
    "# First, debug training: try to overfit a few samples\n",
    "# If the model is not capable of doing this, that's a clear\n",
    "# sign that something is off\n",
    "\n",
    "train_dataloader = CustomDataLoader(TRAIN_DATASET_PATH, additional_param={\"augmentations\": aug_params, \n",
    "                                                                          \"normal_mean\": dataset_mean,\n",
    "                                                                          \"normal_std\": dataset_std,\n",
    "                                                                          \"roffset\":(0,0)})\n",
    "train_loader = DataLoader(train_dataloader, batch_size=BATCH_SIZE)\n",
    "\n",
    "test_dataloader = CustomDataLoader(TEST_DATASET_PATH, additional_param={\"augmentations\":aug_params, \n",
    "                                                                        \"normal_mean\": dataset_mean,\n",
    "                                                                        \"normal_std\": dataset_std,\n",
    "                                                                        \"roffset\":(0,0)})\n",
    "test_loader = DataLoader(test_dataloader, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "06cc26dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume training\n",
    "\n",
    "def find_latest_checkpoint(model_name, directory):\n",
    "    latest_timestamp = float('-inf')  # Initialize with negative infinity\n",
    "    latest_file = None\n",
    "\n",
    "    # Traverse the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".pth\") and filename.startswith(f\"model_checkpoint_running_m{model_name}_\"):\n",
    "            parts = filename.split(\"_\")\n",
    "            timestamp_str = parts[-1].replace(\"s.pth\", \"\")\n",
    "            try:\n",
    "                timestamp = float(timestamp_str)\n",
    "                if timestamp > latest_timestamp:\n",
    "                    latest_timestamp = timestamp\n",
    "                    latest_file = os.path.join(directory, filename)\n",
    "            except ValueError:\n",
    "                pass  # Ignore filenames that can't be parsed as floats\n",
    "\n",
    "    return latest_file, latest_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "3119ef4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_checkpoint, initial_time = find_latest_checkpoint(config['model'], \"../checkpoints\")\n",
    "initial_epoch = 0\n",
    "if latest_checkpoint is not None:\n",
    "    # Load the weights from the checkpoint file\n",
    "    print(f\"Restoring checkpoint {latest_checkpoint}\")\n",
    "    checkpoint = torch.load(latest_checkpoint)\n",
    "\n",
    "    # Load the model's state_dict from the checkpoint\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    # Read latest epoch\n",
    "    initial_epoch = checkpoint['epoch']\n",
    "    \n",
    "    # Load the optimizer's state_dict from the checkpoint\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "else:\n",
    "    initial_time = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa6f9ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " initial lr: 0.006, weight_decay: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                     | 0/1 [00:00<?, ?minibatches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 6, 256, 256])\n",
      "encoder 1: torch.Size([25, 16, 128, 128])\n",
      "encoder 2: torch.Size([25, 32, 64, 64])\n",
      "encoder 3: torch.Size([25, 64, 32, 32])\n",
      "encoder 4: torch.Size([25, 128, 16, 16])\n",
      "encoder 5: torch.Size([25, 256, 8, 8])\n",
      "encoder 6: torch.Size([25, 512, 4, 4])\n",
      "encoder 7: torch.Size([25, 1024, 2, 2])\n",
      "encoder 8: torch.Size([25, 2048, 1, 1])\n",
      "LATENTS HERE\n",
      "torch.Size([25, 2048, 1, 1, 1])\n",
      "res conn shape: torch.Size([25, 2048, 1, 1])\n",
      "inflated conn shape: torch.Size([25, 2048, 1, 1, 1])\n",
      "dencoder 1: torch.Size([25, 1024, 2, 2, 2])\n",
      "res conn shape: torch.Size([25, 1024, 2, 2])\n",
      "inflated conn shape: torch.Size([25, 1024, 2, 2, 2])\n",
      "dencoder 2: torch.Size([25, 512, 4, 4, 4])\n",
      "res conn shape: torch.Size([25, 512, 4, 4])\n",
      "inflated conn shape: torch.Size([25, 512, 4, 4, 4])\n",
      "dencoder 3: torch.Size([25, 256, 8, 8, 8])\n",
      "res conn shape: torch.Size([25, 256, 8, 8])\n",
      "inflated conn shape: torch.Size([25, 256, 8, 8, 8])\n",
      "dencoder 4: torch.Size([25, 128, 16, 16, 16])\n",
      "res conn shape: torch.Size([25, 128, 16, 16])\n",
      "inflated conn shape: torch.Size([25, 128, 16, 16, 16])\n",
      "dencoder 5: torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv1 torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv2 torch.Size([25, 32, 48, 48, 48])\n",
      "before final conv3 torch.Size([25, 16, 48, 48, 48])\n",
      "before final conv4 torch.Size([25, 4, 48, 48, 48])\n",
      "tensor(0.5380, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|█████████████████████████████| 1/1 [00:41<00:00, 41.05s/minibatches]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[misclassification_rate - train] 371594.0\n",
      "Adding in dict for wandb: 'train_misclassification_rate': 371594.0\n",
      "torch.Size([5, 6, 256, 256])\n",
      "encoder 1: torch.Size([5, 16, 128, 128])\n",
      "encoder 2: torch.Size([5, 32, 64, 64])\n",
      "encoder 3: torch.Size([5, 64, 32, 32])\n",
      "encoder 4: torch.Size([5, 128, 16, 16])\n",
      "encoder 5: torch.Size([5, 256, 8, 8])\n",
      "encoder 6: torch.Size([5, 512, 4, 4])\n",
      "encoder 7: torch.Size([5, 1024, 2, 2])\n",
      "encoder 8: torch.Size([5, 2048, 1, 1])\n",
      "LATENTS HERE\n",
      "torch.Size([5, 2048, 1, 1, 1])\n",
      "res conn shape: torch.Size([5, 2048, 1, 1])\n",
      "inflated conn shape: torch.Size([5, 2048, 1, 1, 1])\n",
      "dencoder 1: torch.Size([5, 1024, 2, 2, 2])\n",
      "res conn shape: torch.Size([5, 1024, 2, 2])\n",
      "inflated conn shape: torch.Size([5, 1024, 2, 2, 2])\n",
      "dencoder 2: torch.Size([5, 512, 4, 4, 4])\n",
      "res conn shape: torch.Size([5, 512, 4, 4])\n",
      "inflated conn shape: torch.Size([5, 512, 4, 4, 4])\n",
      "dencoder 3: torch.Size([5, 256, 8, 8, 8])\n",
      "res conn shape: torch.Size([5, 256, 8, 8])\n",
      "inflated conn shape: torch.Size([5, 256, 8, 8, 8])\n",
      "dencoder 4: torch.Size([5, 128, 16, 16, 16])\n",
      "res conn shape: torch.Size([5, 128, 16, 16])\n",
      "inflated conn shape: torch.Size([5, 128, 16, 16, 16])\n",
      "dencoder 5: torch.Size([5, 64, 48, 48, 48])\n",
      "before final conv1 torch.Size([5, 64, 48, 48, 48])\n",
      "before final conv2 torch.Size([5, 32, 48, 48, 48])\n",
      "before final conv3 torch.Size([5, 16, 48, 48, 48])\n",
      "before final conv4 torch.Size([5, 4, 48, 48, 48])\n",
      "[misclassification_rate - validation] 66665.0\n",
      "Adding in dict for wandb: 'validation_misclassification_rate': 66665.0\n",
      "\n",
      "Val loss: 0.15568380057811737,  val batches: 1\n",
      "Logging to wandb: {'train_misclassification_rate': 371594.0, 'validation_misclassification_rate': 66665.0, 'train_loss': 0.5379799008369446, 'val_loss': 0.5379799008369446, 'lr': 0.006}\n",
      "\n",
      "\n",
      "   Epoch 1/1224, Loss: 0.5379799008369446, lr: 0.006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                     | 0/1 [00:00<?, ?minibatches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 6, 256, 256])\n",
      "encoder 1: torch.Size([25, 16, 128, 128])\n",
      "encoder 2: torch.Size([25, 32, 64, 64])\n",
      "encoder 3: torch.Size([25, 64, 32, 32])\n",
      "encoder 4: torch.Size([25, 128, 16, 16])\n",
      "encoder 5: torch.Size([25, 256, 8, 8])\n",
      "encoder 6: torch.Size([25, 512, 4, 4])\n",
      "encoder 7: torch.Size([25, 1024, 2, 2])\n",
      "encoder 8: torch.Size([25, 2048, 1, 1])\n",
      "LATENTS HERE\n",
      "torch.Size([25, 2048, 1, 1, 1])\n",
      "res conn shape: torch.Size([25, 2048, 1, 1])\n",
      "inflated conn shape: torch.Size([25, 2048, 1, 1, 1])\n",
      "dencoder 1: torch.Size([25, 1024, 2, 2, 2])\n",
      "res conn shape: torch.Size([25, 1024, 2, 2])\n",
      "inflated conn shape: torch.Size([25, 1024, 2, 2, 2])\n",
      "dencoder 2: torch.Size([25, 512, 4, 4, 4])\n",
      "res conn shape: torch.Size([25, 512, 4, 4])\n",
      "inflated conn shape: torch.Size([25, 512, 4, 4, 4])\n",
      "dencoder 3: torch.Size([25, 256, 8, 8, 8])\n",
      "res conn shape: torch.Size([25, 256, 8, 8])\n",
      "inflated conn shape: torch.Size([25, 256, 8, 8, 8])\n",
      "dencoder 4: torch.Size([25, 128, 16, 16, 16])\n",
      "res conn shape: torch.Size([25, 128, 16, 16])\n",
      "inflated conn shape: torch.Size([25, 128, 16, 16, 16])\n",
      "dencoder 5: torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv1 torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv2 torch.Size([25, 32, 48, 48, 48])\n",
      "before final conv3 torch.Size([25, 16, 48, 48, 48])\n",
      "before final conv4 torch.Size([25, 4, 48, 48, 48])\n",
      "tensor(0.5158, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|█████████████████████████████| 1/1 [00:46<00:00, 46.09s/minibatches]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[misclassification_rate - train] 2317753.0\n",
      "Adding in dict for wandb: 'train_misclassification_rate': 2317753.0\n",
      "torch.Size([5, 6, 256, 256])\n",
      "encoder 1: torch.Size([5, 16, 128, 128])\n",
      "encoder 2: torch.Size([5, 32, 64, 64])\n",
      "encoder 3: torch.Size([5, 64, 32, 32])\n",
      "encoder 4: torch.Size([5, 128, 16, 16])\n",
      "encoder 5: torch.Size([5, 256, 8, 8])\n",
      "encoder 6: torch.Size([5, 512, 4, 4])\n",
      "encoder 7: torch.Size([5, 1024, 2, 2])\n",
      "encoder 8: torch.Size([5, 2048, 1, 1])\n",
      "LATENTS HERE\n",
      "torch.Size([5, 2048, 1, 1, 1])\n",
      "res conn shape: torch.Size([5, 2048, 1, 1])\n",
      "inflated conn shape: torch.Size([5, 2048, 1, 1, 1])\n",
      "dencoder 1: torch.Size([5, 1024, 2, 2, 2])\n",
      "res conn shape: torch.Size([5, 1024, 2, 2])\n",
      "inflated conn shape: torch.Size([5, 1024, 2, 2, 2])\n",
      "dencoder 2: torch.Size([5, 512, 4, 4, 4])\n",
      "res conn shape: torch.Size([5, 512, 4, 4])\n",
      "inflated conn shape: torch.Size([5, 512, 4, 4, 4])\n",
      "dencoder 3: torch.Size([5, 256, 8, 8, 8])\n",
      "res conn shape: torch.Size([5, 256, 8, 8])\n",
      "inflated conn shape: torch.Size([5, 256, 8, 8, 8])\n",
      "dencoder 4: torch.Size([5, 128, 16, 16, 16])\n",
      "res conn shape: torch.Size([5, 128, 16, 16])\n",
      "inflated conn shape: torch.Size([5, 128, 16, 16, 16])\n",
      "dencoder 5: torch.Size([5, 64, 48, 48, 48])\n",
      "before final conv1 torch.Size([5, 64, 48, 48, 48])\n",
      "before final conv2 torch.Size([5, 32, 48, 48, 48])\n",
      "before final conv3 torch.Size([5, 16, 48, 48, 48])\n",
      "before final conv4 torch.Size([5, 4, 48, 48, 48])\n",
      "[misclassification_rate - validation] 5973.0\n",
      "Adding in dict for wandb: 'validation_misclassification_rate': 5973.0\n",
      "\n",
      "Val loss: 8504.3681640625,  val batches: 1\n",
      "Logging to wandb: {'train_misclassification_rate': 2317753.0, 'validation_misclassification_rate': 5973.0, 'train_loss': 0.5158076286315918, 'val_loss': 0.5158076286315918, 'lr': 0.006}\n",
      "\n",
      "\n",
      "   Epoch 2/1224, Loss: 0.5158076286315918, lr: 0.006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                     | 0/1 [00:00<?, ?minibatches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 6, 256, 256])\n",
      "encoder 1: torch.Size([25, 16, 128, 128])\n",
      "encoder 2: torch.Size([25, 32, 64, 64])\n",
      "encoder 3: torch.Size([25, 64, 32, 32])\n",
      "encoder 4: torch.Size([25, 128, 16, 16])\n",
      "encoder 5: torch.Size([25, 256, 8, 8])\n",
      "encoder 6: torch.Size([25, 512, 4, 4])\n",
      "encoder 7: torch.Size([25, 1024, 2, 2])\n",
      "encoder 8: torch.Size([25, 2048, 1, 1])\n",
      "LATENTS HERE\n",
      "torch.Size([25, 2048, 1, 1, 1])\n",
      "res conn shape: torch.Size([25, 2048, 1, 1])\n",
      "inflated conn shape: torch.Size([25, 2048, 1, 1, 1])\n",
      "dencoder 1: torch.Size([25, 1024, 2, 2, 2])\n",
      "res conn shape: torch.Size([25, 1024, 2, 2])\n",
      "inflated conn shape: torch.Size([25, 1024, 2, 2, 2])\n",
      "dencoder 2: torch.Size([25, 512, 4, 4, 4])\n",
      "res conn shape: torch.Size([25, 512, 4, 4])\n",
      "inflated conn shape: torch.Size([25, 512, 4, 4, 4])\n",
      "dencoder 3: torch.Size([25, 256, 8, 8, 8])\n",
      "res conn shape: torch.Size([25, 256, 8, 8])\n",
      "inflated conn shape: torch.Size([25, 256, 8, 8, 8])\n",
      "dencoder 4: torch.Size([25, 128, 16, 16, 16])\n",
      "res conn shape: torch.Size([25, 128, 16, 16])\n",
      "inflated conn shape: torch.Size([25, 128, 16, 16, 16])\n",
      "dencoder 5: torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv1 torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv2 torch.Size([25, 32, 48, 48, 48])\n",
      "before final conv3 torch.Size([25, 16, 48, 48, 48])\n",
      "before final conv4 torch.Size([25, 4, 48, 48, 48])\n",
      "tensor(0.4364, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|█████████████████████████████| 1/1 [00:46<00:00, 46.06s/minibatches]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[misclassification_rate - train] 1014923.0\n",
      "Adding in dict for wandb: 'train_misclassification_rate': 1014923.0\n",
      "torch.Size([5, 6, 256, 256])\n",
      "encoder 1: torch.Size([5, 16, 128, 128])\n",
      "encoder 2: torch.Size([5, 32, 64, 64])\n",
      "encoder 3: torch.Size([5, 64, 32, 32])\n",
      "encoder 4: torch.Size([5, 128, 16, 16])\n",
      "encoder 5: torch.Size([5, 256, 8, 8])\n",
      "encoder 6: torch.Size([5, 512, 4, 4])\n",
      "encoder 7: torch.Size([5, 1024, 2, 2])\n",
      "encoder 8: torch.Size([5, 2048, 1, 1])\n",
      "LATENTS HERE\n",
      "torch.Size([5, 2048, 1, 1, 1])\n",
      "res conn shape: torch.Size([5, 2048, 1, 1])\n",
      "inflated conn shape: torch.Size([5, 2048, 1, 1, 1])\n",
      "dencoder 1: torch.Size([5, 1024, 2, 2, 2])\n",
      "res conn shape: torch.Size([5, 1024, 2, 2])\n",
      "inflated conn shape: torch.Size([5, 1024, 2, 2, 2])\n",
      "dencoder 2: torch.Size([5, 512, 4, 4, 4])\n",
      "res conn shape: torch.Size([5, 512, 4, 4])\n",
      "inflated conn shape: torch.Size([5, 512, 4, 4, 4])\n",
      "dencoder 3: torch.Size([5, 256, 8, 8, 8])\n",
      "res conn shape: torch.Size([5, 256, 8, 8])\n",
      "inflated conn shape: torch.Size([5, 256, 8, 8, 8])\n",
      "dencoder 4: torch.Size([5, 128, 16, 16, 16])\n",
      "res conn shape: torch.Size([5, 128, 16, 16])\n",
      "inflated conn shape: torch.Size([5, 128, 16, 16, 16])\n",
      "dencoder 5: torch.Size([5, 64, 48, 48, 48])\n",
      "before final conv1 torch.Size([5, 64, 48, 48, 48])\n",
      "before final conv2 torch.Size([5, 32, 48, 48, 48])\n",
      "before final conv3 torch.Size([5, 16, 48, 48, 48])\n",
      "before final conv4 torch.Size([5, 4, 48, 48, 48])\n",
      "[misclassification_rate - validation] 4296.0\n",
      "Adding in dict for wandb: 'validation_misclassification_rate': 4296.0\n",
      "\n",
      "Val loss: 9041.6591796875,  val batches: 1\n",
      "Logging to wandb: {'train_misclassification_rate': 1014923.0, 'validation_misclassification_rate': 4296.0, 'train_loss': 0.43637678027153015, 'val_loss': 0.43637678027153015, 'lr': 0.006}\n",
      "\n",
      "\n",
      "   Epoch 3/1224, Loss: 0.43637678027153015, lr: 0.006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                     | 0/1 [00:00<?, ?minibatches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 6, 256, 256])\n",
      "encoder 1: torch.Size([25, 16, 128, 128])\n",
      "encoder 2: torch.Size([25, 32, 64, 64])\n",
      "encoder 3: torch.Size([25, 64, 32, 32])\n",
      "encoder 4: torch.Size([25, 128, 16, 16])\n",
      "encoder 5: torch.Size([25, 256, 8, 8])\n",
      "encoder 6: torch.Size([25, 512, 4, 4])\n",
      "encoder 7: torch.Size([25, 1024, 2, 2])\n",
      "encoder 8: torch.Size([25, 2048, 1, 1])\n",
      "LATENTS HERE\n",
      "torch.Size([25, 2048, 1, 1, 1])\n",
      "res conn shape: torch.Size([25, 2048, 1, 1])\n",
      "inflated conn shape: torch.Size([25, 2048, 1, 1, 1])\n",
      "dencoder 1: torch.Size([25, 1024, 2, 2, 2])\n",
      "res conn shape: torch.Size([25, 1024, 2, 2])\n",
      "inflated conn shape: torch.Size([25, 1024, 2, 2, 2])\n",
      "dencoder 2: torch.Size([25, 512, 4, 4, 4])\n",
      "res conn shape: torch.Size([25, 512, 4, 4])\n",
      "inflated conn shape: torch.Size([25, 512, 4, 4, 4])\n",
      "dencoder 3: torch.Size([25, 256, 8, 8, 8])\n",
      "res conn shape: torch.Size([25, 256, 8, 8])\n",
      "inflated conn shape: torch.Size([25, 256, 8, 8, 8])\n",
      "dencoder 4: torch.Size([25, 128, 16, 16, 16])\n",
      "res conn shape: torch.Size([25, 128, 16, 16])\n",
      "inflated conn shape: torch.Size([25, 128, 16, 16, 16])\n",
      "dencoder 5: torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv1 torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv2 torch.Size([25, 32, 48, 48, 48])\n",
      "before final conv3 torch.Size([25, 16, 48, 48, 48])\n",
      "before final conv4 torch.Size([25, 4, 48, 48, 48])\n",
      "tensor(0.3914, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|█████████████████████████████| 1/1 [00:46<00:00, 46.43s/minibatches]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[misclassification_rate - train] 1749750.0\n",
      "Adding in dict for wandb: 'train_misclassification_rate': 1749750.0\n",
      "torch.Size([5, 6, 256, 256])\n",
      "encoder 1: torch.Size([5, 16, 128, 128])\n",
      "encoder 2: torch.Size([5, 32, 64, 64])\n",
      "encoder 3: torch.Size([5, 64, 32, 32])\n",
      "encoder 4: torch.Size([5, 128, 16, 16])\n",
      "encoder 5: torch.Size([5, 256, 8, 8])\n",
      "encoder 6: torch.Size([5, 512, 4, 4])\n",
      "encoder 7: torch.Size([5, 1024, 2, 2])\n",
      "encoder 8: torch.Size([5, 2048, 1, 1])\n",
      "LATENTS HERE\n",
      "torch.Size([5, 2048, 1, 1, 1])\n",
      "res conn shape: torch.Size([5, 2048, 1, 1])\n",
      "inflated conn shape: torch.Size([5, 2048, 1, 1, 1])\n",
      "dencoder 1: torch.Size([5, 1024, 2, 2, 2])\n",
      "res conn shape: torch.Size([5, 1024, 2, 2])\n",
      "inflated conn shape: torch.Size([5, 1024, 2, 2, 2])\n",
      "dencoder 2: torch.Size([5, 512, 4, 4, 4])\n",
      "res conn shape: torch.Size([5, 512, 4, 4])\n",
      "inflated conn shape: torch.Size([5, 512, 4, 4, 4])\n",
      "dencoder 3: torch.Size([5, 256, 8, 8, 8])\n",
      "res conn shape: torch.Size([5, 256, 8, 8])\n",
      "inflated conn shape: torch.Size([5, 256, 8, 8, 8])\n",
      "dencoder 4: torch.Size([5, 128, 16, 16, 16])\n",
      "res conn shape: torch.Size([5, 128, 16, 16])\n",
      "inflated conn shape: torch.Size([5, 128, 16, 16, 16])\n",
      "dencoder 5: torch.Size([5, 64, 48, 48, 48])\n",
      "before final conv1 torch.Size([5, 64, 48, 48, 48])\n",
      "before final conv2 torch.Size([5, 32, 48, 48, 48])\n",
      "before final conv3 torch.Size([5, 16, 48, 48, 48])\n",
      "before final conv4 torch.Size([5, 4, 48, 48, 48])\n",
      "[misclassification_rate - validation] 4346.0\n",
      "Adding in dict for wandb: 'validation_misclassification_rate': 4346.0\n",
      "\n",
      "Val loss: 58.959014892578125,  val batches: 1\n",
      "Logging to wandb: {'train_misclassification_rate': 1749750.0, 'validation_misclassification_rate': 4346.0, 'train_loss': 0.3913626968860626, 'val_loss': 0.3913626968860626, 'lr': 0.006}\n",
      "\n",
      "\n",
      "   Epoch 4/1224, Loss: 0.3913626968860626, lr: 0.006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                     | 0/1 [00:00<?, ?minibatches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 6, 256, 256])\n",
      "encoder 1: torch.Size([25, 16, 128, 128])\n",
      "encoder 2: torch.Size([25, 32, 64, 64])\n",
      "encoder 3: torch.Size([25, 64, 32, 32])\n",
      "encoder 4: torch.Size([25, 128, 16, 16])\n",
      "encoder 5: torch.Size([25, 256, 8, 8])\n",
      "encoder 6: torch.Size([25, 512, 4, 4])\n",
      "encoder 7: torch.Size([25, 1024, 2, 2])\n",
      "encoder 8: torch.Size([25, 2048, 1, 1])\n",
      "LATENTS HERE\n",
      "torch.Size([25, 2048, 1, 1, 1])\n",
      "res conn shape: torch.Size([25, 2048, 1, 1])\n",
      "inflated conn shape: torch.Size([25, 2048, 1, 1, 1])\n",
      "dencoder 1: torch.Size([25, 1024, 2, 2, 2])\n",
      "res conn shape: torch.Size([25, 1024, 2, 2])\n",
      "inflated conn shape: torch.Size([25, 1024, 2, 2, 2])\n",
      "dencoder 2: torch.Size([25, 512, 4, 4, 4])\n",
      "res conn shape: torch.Size([25, 512, 4, 4])\n",
      "inflated conn shape: torch.Size([25, 512, 4, 4, 4])\n",
      "dencoder 3: torch.Size([25, 256, 8, 8, 8])\n",
      "res conn shape: torch.Size([25, 256, 8, 8])\n",
      "inflated conn shape: torch.Size([25, 256, 8, 8, 8])\n",
      "dencoder 4: torch.Size([25, 128, 16, 16, 16])\n",
      "res conn shape: torch.Size([25, 128, 16, 16])\n",
      "inflated conn shape: torch.Size([25, 128, 16, 16, 16])\n",
      "dencoder 5: torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv1 torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv2 torch.Size([25, 32, 48, 48, 48])\n",
      "before final conv3 torch.Size([25, 16, 48, 48, 48])\n",
      "before final conv4 torch.Size([25, 4, 48, 48, 48])\n",
      "tensor(0.2946, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|█████████████████████████████| 1/1 [00:42<00:00, 42.67s/minibatches]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[misclassification_rate - train] 892587.0\n",
      "Adding in dict for wandb: 'train_misclassification_rate': 892587.0\n",
      "torch.Size([5, 6, 256, 256])\n",
      "encoder 1: torch.Size([5, 16, 128, 128])\n",
      "encoder 2: torch.Size([5, 32, 64, 64])\n",
      "encoder 3: torch.Size([5, 64, 32, 32])\n",
      "encoder 4: torch.Size([5, 128, 16, 16])\n",
      "encoder 5: torch.Size([5, 256, 8, 8])\n",
      "encoder 6: torch.Size([5, 512, 4, 4])\n",
      "encoder 7: torch.Size([5, 1024, 2, 2])\n",
      "encoder 8: torch.Size([5, 2048, 1, 1])\n",
      "LATENTS HERE\n",
      "torch.Size([5, 2048, 1, 1, 1])\n",
      "res conn shape: torch.Size([5, 2048, 1, 1])\n",
      "inflated conn shape: torch.Size([5, 2048, 1, 1, 1])\n",
      "dencoder 1: torch.Size([5, 1024, 2, 2, 2])\n",
      "res conn shape: torch.Size([5, 1024, 2, 2])\n",
      "inflated conn shape: torch.Size([5, 1024, 2, 2, 2])\n",
      "dencoder 2: torch.Size([5, 512, 4, 4, 4])\n",
      "res conn shape: torch.Size([5, 512, 4, 4])\n",
      "inflated conn shape: torch.Size([5, 512, 4, 4, 4])\n",
      "dencoder 3: torch.Size([5, 256, 8, 8, 8])\n",
      "res conn shape: torch.Size([5, 256, 8, 8])\n",
      "inflated conn shape: torch.Size([5, 256, 8, 8, 8])\n",
      "dencoder 4: torch.Size([5, 128, 16, 16, 16])\n",
      "res conn shape: torch.Size([5, 128, 16, 16])\n",
      "inflated conn shape: torch.Size([5, 128, 16, 16, 16])\n",
      "dencoder 5: torch.Size([5, 64, 48, 48, 48])\n",
      "before final conv1 torch.Size([5, 64, 48, 48, 48])\n",
      "before final conv2 torch.Size([5, 32, 48, 48, 48])\n",
      "before final conv3 torch.Size([5, 16, 48, 48, 48])\n",
      "before final conv4 torch.Size([5, 4, 48, 48, 48])\n",
      "[misclassification_rate - validation] 4383.0\n",
      "Adding in dict for wandb: 'validation_misclassification_rate': 4383.0\n",
      "\n",
      "Val loss: 79.40255737304688,  val batches: 1\n",
      "Logging to wandb: {'train_misclassification_rate': 892587.0, 'validation_misclassification_rate': 4383.0, 'train_loss': 0.2945989668369293, 'val_loss': 0.2945989668369293, 'lr': 0.006}\n",
      "\n",
      "\n",
      "   Epoch 5/1224, Loss: 0.2945989668369293, lr: 0.006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                     | 0/1 [00:00<?, ?minibatches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 6, 256, 256])\n",
      "encoder 1: torch.Size([25, 16, 128, 128])\n",
      "encoder 2: torch.Size([25, 32, 64, 64])\n",
      "encoder 3: torch.Size([25, 64, 32, 32])\n",
      "encoder 4: torch.Size([25, 128, 16, 16])\n",
      "encoder 5: torch.Size([25, 256, 8, 8])\n",
      "encoder 6: torch.Size([25, 512, 4, 4])\n",
      "encoder 7: torch.Size([25, 1024, 2, 2])\n",
      "encoder 8: torch.Size([25, 2048, 1, 1])\n",
      "LATENTS HERE\n",
      "torch.Size([25, 2048, 1, 1, 1])\n",
      "res conn shape: torch.Size([25, 2048, 1, 1])\n",
      "inflated conn shape: torch.Size([25, 2048, 1, 1, 1])\n",
      "dencoder 1: torch.Size([25, 1024, 2, 2, 2])\n",
      "res conn shape: torch.Size([25, 1024, 2, 2])\n",
      "inflated conn shape: torch.Size([25, 1024, 2, 2, 2])\n",
      "dencoder 2: torch.Size([25, 512, 4, 4, 4])\n",
      "res conn shape: torch.Size([25, 512, 4, 4])\n",
      "inflated conn shape: torch.Size([25, 512, 4, 4, 4])\n",
      "dencoder 3: torch.Size([25, 256, 8, 8, 8])\n",
      "res conn shape: torch.Size([25, 256, 8, 8])\n",
      "inflated conn shape: torch.Size([25, 256, 8, 8, 8])\n",
      "dencoder 4: torch.Size([25, 128, 16, 16, 16])\n",
      "res conn shape: torch.Size([25, 128, 16, 16])\n",
      "inflated conn shape: torch.Size([25, 128, 16, 16, 16])\n",
      "dencoder 5: torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv1 torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv2 torch.Size([25, 32, 48, 48, 48])\n",
      "before final conv3 torch.Size([25, 16, 48, 48, 48])\n",
      "before final conv4 torch.Size([25, 4, 48, 48, 48])\n",
      "tensor(0.2210, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|█████████████████████████████| 1/1 [00:43<00:00, 43.01s/minibatches]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[misclassification_rate - train] 877496.0\n",
      "Adding in dict for wandb: 'train_misclassification_rate': 877496.0\n",
      "torch.Size([5, 6, 256, 256])\n",
      "encoder 1: torch.Size([5, 16, 128, 128])\n",
      "encoder 2: torch.Size([5, 32, 64, 64])\n",
      "encoder 3: torch.Size([5, 64, 32, 32])\n",
      "encoder 4: torch.Size([5, 128, 16, 16])\n",
      "encoder 5: torch.Size([5, 256, 8, 8])\n",
      "encoder 6: torch.Size([5, 512, 4, 4])\n",
      "encoder 7: torch.Size([5, 1024, 2, 2])\n",
      "encoder 8: torch.Size([5, 2048, 1, 1])\n",
      "LATENTS HERE\n",
      "torch.Size([5, 2048, 1, 1, 1])\n",
      "res conn shape: torch.Size([5, 2048, 1, 1])\n",
      "inflated conn shape: torch.Size([5, 2048, 1, 1, 1])\n",
      "dencoder 1: torch.Size([5, 1024, 2, 2, 2])\n",
      "res conn shape: torch.Size([5, 1024, 2, 2])\n",
      "inflated conn shape: torch.Size([5, 1024, 2, 2, 2])\n",
      "dencoder 2: torch.Size([5, 512, 4, 4, 4])\n",
      "res conn shape: torch.Size([5, 512, 4, 4])\n",
      "inflated conn shape: torch.Size([5, 512, 4, 4, 4])\n",
      "dencoder 3: torch.Size([5, 256, 8, 8, 8])\n",
      "res conn shape: torch.Size([5, 256, 8, 8])\n",
      "inflated conn shape: torch.Size([5, 256, 8, 8, 8])\n",
      "dencoder 4: torch.Size([5, 128, 16, 16, 16])\n",
      "res conn shape: torch.Size([5, 128, 16, 16])\n",
      "inflated conn shape: torch.Size([5, 128, 16, 16, 16])\n",
      "dencoder 5: torch.Size([5, 64, 48, 48, 48])\n",
      "before final conv1 torch.Size([5, 64, 48, 48, 48])\n",
      "before final conv2 torch.Size([5, 32, 48, 48, 48])\n",
      "before final conv3 torch.Size([5, 16, 48, 48, 48])\n",
      "before final conv4 torch.Size([5, 4, 48, 48, 48])\n",
      "[misclassification_rate - validation] 4326.0\n",
      "Adding in dict for wandb: 'validation_misclassification_rate': 4326.0\n",
      "\n",
      "Val loss: 24.563505172729492,  val batches: 1\n",
      "Logging to wandb: {'train_misclassification_rate': 877496.0, 'validation_misclassification_rate': 4326.0, 'train_loss': 0.22100916504859924, 'val_loss': 0.22100916504859924, 'lr': 0.006}\n",
      "\n",
      "\n",
      "   Epoch 6/1224, Loss: 0.22100916504859924, lr: 0.006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                     | 0/1 [00:00<?, ?minibatches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 6, 256, 256])\n",
      "encoder 1: torch.Size([25, 16, 128, 128])\n",
      "encoder 2: torch.Size([25, 32, 64, 64])\n",
      "encoder 3: torch.Size([25, 64, 32, 32])\n",
      "encoder 4: torch.Size([25, 128, 16, 16])\n",
      "encoder 5: torch.Size([25, 256, 8, 8])\n",
      "encoder 6: torch.Size([25, 512, 4, 4])\n",
      "encoder 7: torch.Size([25, 1024, 2, 2])\n",
      "encoder 8: torch.Size([25, 2048, 1, 1])\n",
      "LATENTS HERE\n",
      "torch.Size([25, 2048, 1, 1, 1])\n",
      "res conn shape: torch.Size([25, 2048, 1, 1])\n",
      "inflated conn shape: torch.Size([25, 2048, 1, 1, 1])\n",
      "dencoder 1: torch.Size([25, 1024, 2, 2, 2])\n",
      "res conn shape: torch.Size([25, 1024, 2, 2])\n",
      "inflated conn shape: torch.Size([25, 1024, 2, 2, 2])\n",
      "dencoder 2: torch.Size([25, 512, 4, 4, 4])\n",
      "res conn shape: torch.Size([25, 512, 4, 4])\n",
      "inflated conn shape: torch.Size([25, 512, 4, 4, 4])\n",
      "dencoder 3: torch.Size([25, 256, 8, 8, 8])\n",
      "res conn shape: torch.Size([25, 256, 8, 8])\n",
      "inflated conn shape: torch.Size([25, 256, 8, 8, 8])\n",
      "dencoder 4: torch.Size([25, 128, 16, 16, 16])\n",
      "res conn shape: torch.Size([25, 128, 16, 16])\n",
      "inflated conn shape: torch.Size([25, 128, 16, 16, 16])\n",
      "dencoder 5: torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv1 torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv2 torch.Size([25, 32, 48, 48, 48])\n",
      "before final conv3 torch.Size([25, 16, 48, 48, 48])\n",
      "before final conv4 torch.Size([25, 4, 48, 48, 48])\n",
      "tensor(0.1734, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|█████████████████████████████| 1/1 [00:43<00:00, 43.30s/minibatches]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[misclassification_rate - train] 1008728.0\n",
      "Adding in dict for wandb: 'train_misclassification_rate': 1008728.0\n",
      "torch.Size([5, 6, 256, 256])\n",
      "encoder 1: torch.Size([5, 16, 128, 128])\n",
      "encoder 2: torch.Size([5, 32, 64, 64])\n",
      "encoder 3: torch.Size([5, 64, 32, 32])\n",
      "encoder 4: torch.Size([5, 128, 16, 16])\n",
      "encoder 5: torch.Size([5, 256, 8, 8])\n",
      "encoder 6: torch.Size([5, 512, 4, 4])\n",
      "encoder 7: torch.Size([5, 1024, 2, 2])\n",
      "encoder 8: torch.Size([5, 2048, 1, 1])\n",
      "LATENTS HERE\n",
      "torch.Size([5, 2048, 1, 1, 1])\n",
      "res conn shape: torch.Size([5, 2048, 1, 1])\n",
      "inflated conn shape: torch.Size([5, 2048, 1, 1, 1])\n",
      "dencoder 1: torch.Size([5, 1024, 2, 2, 2])\n",
      "res conn shape: torch.Size([5, 1024, 2, 2])\n",
      "inflated conn shape: torch.Size([5, 1024, 2, 2, 2])\n",
      "dencoder 2: torch.Size([5, 512, 4, 4, 4])\n",
      "res conn shape: torch.Size([5, 512, 4, 4])\n",
      "inflated conn shape: torch.Size([5, 512, 4, 4, 4])\n",
      "dencoder 3: torch.Size([5, 256, 8, 8, 8])\n",
      "res conn shape: torch.Size([5, 256, 8, 8])\n",
      "inflated conn shape: torch.Size([5, 256, 8, 8, 8])\n",
      "dencoder 4: torch.Size([5, 128, 16, 16, 16])\n",
      "res conn shape: torch.Size([5, 128, 16, 16])\n",
      "inflated conn shape: torch.Size([5, 128, 16, 16, 16])\n",
      "dencoder 5: torch.Size([5, 64, 48, 48, 48])\n",
      "before final conv1 torch.Size([5, 64, 48, 48, 48])\n",
      "before final conv2 torch.Size([5, 32, 48, 48, 48])\n",
      "before final conv3 torch.Size([5, 16, 48, 48, 48])\n",
      "before final conv4 torch.Size([5, 4, 48, 48, 48])\n",
      "[misclassification_rate - validation] 4312.0\n",
      "Adding in dict for wandb: 'validation_misclassification_rate': 4312.0\n",
      "\n",
      "Val loss: 7.574634552001953,  val batches: 1\n",
      "Logging to wandb: {'train_misclassification_rate': 1008728.0, 'validation_misclassification_rate': 4312.0, 'train_loss': 0.1734214574098587, 'val_loss': 0.1734214574098587, 'lr': 0.006}\n",
      "\n",
      "\n",
      "   Epoch 7/1224, Loss: 0.1734214574098587, lr: 0.006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                     | 0/1 [00:00<?, ?minibatches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 6, 256, 256])\n",
      "encoder 1: torch.Size([25, 16, 128, 128])\n",
      "encoder 2: torch.Size([25, 32, 64, 64])\n",
      "encoder 3: torch.Size([25, 64, 32, 32])\n",
      "encoder 4: torch.Size([25, 128, 16, 16])\n",
      "encoder 5: torch.Size([25, 256, 8, 8])\n",
      "encoder 6: torch.Size([25, 512, 4, 4])\n",
      "encoder 7: torch.Size([25, 1024, 2, 2])\n",
      "encoder 8: torch.Size([25, 2048, 1, 1])\n",
      "LATENTS HERE\n",
      "torch.Size([25, 2048, 1, 1, 1])\n",
      "res conn shape: torch.Size([25, 2048, 1, 1])\n",
      "inflated conn shape: torch.Size([25, 2048, 1, 1, 1])\n",
      "dencoder 1: torch.Size([25, 1024, 2, 2, 2])\n",
      "res conn shape: torch.Size([25, 1024, 2, 2])\n",
      "inflated conn shape: torch.Size([25, 1024, 2, 2, 2])\n",
      "dencoder 2: torch.Size([25, 512, 4, 4, 4])\n",
      "res conn shape: torch.Size([25, 512, 4, 4])\n",
      "inflated conn shape: torch.Size([25, 512, 4, 4, 4])\n",
      "dencoder 3: torch.Size([25, 256, 8, 8, 8])\n",
      "res conn shape: torch.Size([25, 256, 8, 8])\n",
      "inflated conn shape: torch.Size([25, 256, 8, 8, 8])\n",
      "dencoder 4: torch.Size([25, 128, 16, 16, 16])\n",
      "res conn shape: torch.Size([25, 128, 16, 16])\n",
      "inflated conn shape: torch.Size([25, 128, 16, 16, 16])\n",
      "dencoder 5: torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv1 torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv2 torch.Size([25, 32, 48, 48, 48])\n",
      "before final conv3 torch.Size([25, 16, 48, 48, 48])\n",
      "before final conv4 torch.Size([25, 4, 48, 48, 48])\n",
      "tensor(0.1311, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|█████████████████████████████| 1/1 [00:43<00:00, 43.27s/minibatches]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[misclassification_rate - train] 471220.0\n",
      "Adding in dict for wandb: 'train_misclassification_rate': 471220.0\n",
      "torch.Size([5, 6, 256, 256])\n",
      "encoder 1: torch.Size([5, 16, 128, 128])\n",
      "encoder 2: torch.Size([5, 32, 64, 64])\n",
      "encoder 3: torch.Size([5, 64, 32, 32])\n",
      "encoder 4: torch.Size([5, 128, 16, 16])\n",
      "encoder 5: torch.Size([5, 256, 8, 8])\n",
      "encoder 6: torch.Size([5, 512, 4, 4])\n",
      "encoder 7: torch.Size([5, 1024, 2, 2])\n",
      "encoder 8: torch.Size([5, 2048, 1, 1])\n",
      "LATENTS HERE\n",
      "torch.Size([5, 2048, 1, 1, 1])\n",
      "res conn shape: torch.Size([5, 2048, 1, 1])\n",
      "inflated conn shape: torch.Size([5, 2048, 1, 1, 1])\n",
      "dencoder 1: torch.Size([5, 1024, 2, 2, 2])\n",
      "res conn shape: torch.Size([5, 1024, 2, 2])\n",
      "inflated conn shape: torch.Size([5, 1024, 2, 2, 2])\n",
      "dencoder 2: torch.Size([5, 512, 4, 4, 4])\n",
      "res conn shape: torch.Size([5, 512, 4, 4])\n",
      "inflated conn shape: torch.Size([5, 512, 4, 4, 4])\n",
      "dencoder 3: torch.Size([5, 256, 8, 8, 8])\n",
      "res conn shape: torch.Size([5, 256, 8, 8])\n",
      "inflated conn shape: torch.Size([5, 256, 8, 8, 8])\n",
      "dencoder 4: torch.Size([5, 128, 16, 16, 16])\n",
      "res conn shape: torch.Size([5, 128, 16, 16])\n",
      "inflated conn shape: torch.Size([5, 128, 16, 16, 16])\n",
      "dencoder 5: torch.Size([5, 64, 48, 48, 48])\n",
      "before final conv1 torch.Size([5, 64, 48, 48, 48])\n",
      "before final conv2 torch.Size([5, 32, 48, 48, 48])\n",
      "before final conv3 torch.Size([5, 16, 48, 48, 48])\n",
      "before final conv4 torch.Size([5, 4, 48, 48, 48])\n",
      "[misclassification_rate - validation] 4361.0\n",
      "Adding in dict for wandb: 'validation_misclassification_rate': 4361.0\n",
      "\n",
      "Val loss: 0.9063116312026978,  val batches: 1\n",
      "Logging to wandb: {'train_misclassification_rate': 471220.0, 'validation_misclassification_rate': 4361.0, 'train_loss': 0.13106399774551392, 'val_loss': 0.13106399774551392, 'lr': 0.006}\n",
      "\n",
      "\n",
      "   Epoch 8/1224, Loss: 0.13106399774551392, lr: 0.006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                     | 0/1 [00:00<?, ?minibatches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 6, 256, 256])\n",
      "encoder 1: torch.Size([25, 16, 128, 128])\n",
      "encoder 2: torch.Size([25, 32, 64, 64])\n",
      "encoder 3: torch.Size([25, 64, 32, 32])\n",
      "encoder 4: torch.Size([25, 128, 16, 16])\n",
      "encoder 5: torch.Size([25, 256, 8, 8])\n",
      "encoder 6: torch.Size([25, 512, 4, 4])\n",
      "encoder 7: torch.Size([25, 1024, 2, 2])\n",
      "encoder 8: torch.Size([25, 2048, 1, 1])\n",
      "LATENTS HERE\n",
      "torch.Size([25, 2048, 1, 1, 1])\n",
      "res conn shape: torch.Size([25, 2048, 1, 1])\n",
      "inflated conn shape: torch.Size([25, 2048, 1, 1, 1])\n",
      "dencoder 1: torch.Size([25, 1024, 2, 2, 2])\n",
      "res conn shape: torch.Size([25, 1024, 2, 2])\n",
      "inflated conn shape: torch.Size([25, 1024, 2, 2, 2])\n",
      "dencoder 2: torch.Size([25, 512, 4, 4, 4])\n",
      "res conn shape: torch.Size([25, 512, 4, 4])\n",
      "inflated conn shape: torch.Size([25, 512, 4, 4, 4])\n",
      "dencoder 3: torch.Size([25, 256, 8, 8, 8])\n",
      "res conn shape: torch.Size([25, 256, 8, 8])\n",
      "inflated conn shape: torch.Size([25, 256, 8, 8, 8])\n",
      "dencoder 4: torch.Size([25, 128, 16, 16, 16])\n",
      "res conn shape: torch.Size([25, 128, 16, 16])\n",
      "inflated conn shape: torch.Size([25, 128, 16, 16, 16])\n",
      "dencoder 5: torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv1 torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv2 torch.Size([25, 32, 48, 48, 48])\n",
      "before final conv3 torch.Size([25, 16, 48, 48, 48])\n",
      "before final conv4 torch.Size([25, 4, 48, 48, 48])\n",
      "tensor(0.0985, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|█████████████████████████████| 1/1 [00:43<00:00, 43.23s/minibatches]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[misclassification_rate - train] 546800.0\n",
      "Adding in dict for wandb: 'train_misclassification_rate': 546800.0\n",
      "torch.Size([5, 6, 256, 256])\n",
      "encoder 1: torch.Size([5, 16, 128, 128])\n",
      "encoder 2: torch.Size([5, 32, 64, 64])\n",
      "encoder 3: torch.Size([5, 64, 32, 32])\n",
      "encoder 4: torch.Size([5, 128, 16, 16])\n",
      "encoder 5: torch.Size([5, 256, 8, 8])\n",
      "encoder 6: torch.Size([5, 512, 4, 4])\n",
      "encoder 7: torch.Size([5, 1024, 2, 2])\n",
      "encoder 8: torch.Size([5, 2048, 1, 1])\n",
      "LATENTS HERE\n",
      "torch.Size([5, 2048, 1, 1, 1])\n",
      "res conn shape: torch.Size([5, 2048, 1, 1])\n",
      "inflated conn shape: torch.Size([5, 2048, 1, 1, 1])\n",
      "dencoder 1: torch.Size([5, 1024, 2, 2, 2])\n",
      "res conn shape: torch.Size([5, 1024, 2, 2])\n",
      "inflated conn shape: torch.Size([5, 1024, 2, 2, 2])\n",
      "dencoder 2: torch.Size([5, 512, 4, 4, 4])\n",
      "res conn shape: torch.Size([5, 512, 4, 4])\n",
      "inflated conn shape: torch.Size([5, 512, 4, 4, 4])\n",
      "dencoder 3: torch.Size([5, 256, 8, 8, 8])\n",
      "res conn shape: torch.Size([5, 256, 8, 8])\n",
      "inflated conn shape: torch.Size([5, 256, 8, 8, 8])\n",
      "dencoder 4: torch.Size([5, 128, 16, 16, 16])\n",
      "res conn shape: torch.Size([5, 128, 16, 16])\n",
      "inflated conn shape: torch.Size([5, 128, 16, 16, 16])\n",
      "dencoder 5: torch.Size([5, 64, 48, 48, 48])\n",
      "before final conv1 torch.Size([5, 64, 48, 48, 48])\n",
      "before final conv2 torch.Size([5, 32, 48, 48, 48])\n",
      "before final conv3 torch.Size([5, 16, 48, 48, 48])\n",
      "before final conv4 torch.Size([5, 4, 48, 48, 48])\n",
      "[misclassification_rate - validation] 4708.0\n",
      "Adding in dict for wandb: 'validation_misclassification_rate': 4708.0\n",
      "\n",
      "Val loss: 0.2762439548969269,  val batches: 1\n",
      "Logging to wandb: {'train_misclassification_rate': 546800.0, 'validation_misclassification_rate': 4708.0, 'train_loss': 0.09848766028881073, 'val_loss': 0.09848766028881073, 'lr': 0.006}\n",
      "\n",
      "\n",
      "   Epoch 9/1224, Loss: 0.09848766028881073, lr: 0.006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                     | 0/1 [00:00<?, ?minibatches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 6, 256, 256])\n",
      "encoder 1: torch.Size([25, 16, 128, 128])\n",
      "encoder 2: torch.Size([25, 32, 64, 64])\n",
      "encoder 3: torch.Size([25, 64, 32, 32])\n",
      "encoder 4: torch.Size([25, 128, 16, 16])\n",
      "encoder 5: torch.Size([25, 256, 8, 8])\n",
      "encoder 6: torch.Size([25, 512, 4, 4])\n",
      "encoder 7: torch.Size([25, 1024, 2, 2])\n",
      "encoder 8: torch.Size([25, 2048, 1, 1])\n",
      "LATENTS HERE\n",
      "torch.Size([25, 2048, 1, 1, 1])\n",
      "res conn shape: torch.Size([25, 2048, 1, 1])\n",
      "inflated conn shape: torch.Size([25, 2048, 1, 1, 1])\n",
      "dencoder 1: torch.Size([25, 1024, 2, 2, 2])\n",
      "res conn shape: torch.Size([25, 1024, 2, 2])\n",
      "inflated conn shape: torch.Size([25, 1024, 2, 2, 2])\n",
      "dencoder 2: torch.Size([25, 512, 4, 4, 4])\n",
      "res conn shape: torch.Size([25, 512, 4, 4])\n",
      "inflated conn shape: torch.Size([25, 512, 4, 4, 4])\n",
      "dencoder 3: torch.Size([25, 256, 8, 8, 8])\n",
      "res conn shape: torch.Size([25, 256, 8, 8])\n",
      "inflated conn shape: torch.Size([25, 256, 8, 8, 8])\n",
      "dencoder 4: torch.Size([25, 128, 16, 16, 16])\n",
      "res conn shape: torch.Size([25, 128, 16, 16])\n",
      "inflated conn shape: torch.Size([25, 128, 16, 16, 16])\n",
      "dencoder 5: torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv1 torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv2 torch.Size([25, 32, 48, 48, 48])\n",
      "before final conv3 torch.Size([25, 16, 48, 48, 48])\n",
      "before final conv4 torch.Size([25, 4, 48, 48, 48])\n",
      "tensor(0.0775, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|█████████████████████████████| 1/1 [00:42<00:00, 42.75s/minibatches]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[misclassification_rate - train] 426546.0\n",
      "Adding in dict for wandb: 'train_misclassification_rate': 426546.0\n",
      "torch.Size([5, 6, 256, 256])\n",
      "encoder 1: torch.Size([5, 16, 128, 128])\n",
      "encoder 2: torch.Size([5, 32, 64, 64])\n",
      "encoder 3: torch.Size([5, 64, 32, 32])\n",
      "encoder 4: torch.Size([5, 128, 16, 16])\n",
      "encoder 5: torch.Size([5, 256, 8, 8])\n",
      "encoder 6: torch.Size([5, 512, 4, 4])\n",
      "encoder 7: torch.Size([5, 1024, 2, 2])\n",
      "encoder 8: torch.Size([5, 2048, 1, 1])\n",
      "LATENTS HERE\n",
      "torch.Size([5, 2048, 1, 1, 1])\n",
      "res conn shape: torch.Size([5, 2048, 1, 1])\n",
      "inflated conn shape: torch.Size([5, 2048, 1, 1, 1])\n",
      "dencoder 1: torch.Size([5, 1024, 2, 2, 2])\n",
      "res conn shape: torch.Size([5, 1024, 2, 2])\n",
      "inflated conn shape: torch.Size([5, 1024, 2, 2, 2])\n",
      "dencoder 2: torch.Size([5, 512, 4, 4, 4])\n",
      "res conn shape: torch.Size([5, 512, 4, 4])\n",
      "inflated conn shape: torch.Size([5, 512, 4, 4, 4])\n",
      "dencoder 3: torch.Size([5, 256, 8, 8, 8])\n",
      "res conn shape: torch.Size([5, 256, 8, 8])\n",
      "inflated conn shape: torch.Size([5, 256, 8, 8, 8])\n",
      "dencoder 4: torch.Size([5, 128, 16, 16, 16])\n",
      "res conn shape: torch.Size([5, 128, 16, 16])\n",
      "inflated conn shape: torch.Size([5, 128, 16, 16, 16])\n",
      "dencoder 5: torch.Size([5, 64, 48, 48, 48])\n",
      "before final conv1 torch.Size([5, 64, 48, 48, 48])\n",
      "before final conv2 torch.Size([5, 32, 48, 48, 48])\n",
      "before final conv3 torch.Size([5, 16, 48, 48, 48])\n",
      "before final conv4 torch.Size([5, 4, 48, 48, 48])\n",
      "[misclassification_rate - validation] 5781.0\n",
      "Adding in dict for wandb: 'validation_misclassification_rate': 5781.0\n",
      "\n",
      "Val loss: 0.19880451261997223,  val batches: 1\n",
      "Logging to wandb: {'train_misclassification_rate': 426546.0, 'validation_misclassification_rate': 5781.0, 'train_loss': 0.07754744589328766, 'val_loss': 0.07754744589328766, 'lr': 0.006}\n",
      "\n",
      "\n",
      "   Epoch 10/1224, Loss: 0.07754744589328766, lr: 0.006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                     | 0/1 [00:00<?, ?minibatches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 6, 256, 256])\n",
      "encoder 1: torch.Size([25, 16, 128, 128])\n",
      "encoder 2: torch.Size([25, 32, 64, 64])\n",
      "encoder 3: torch.Size([25, 64, 32, 32])\n",
      "encoder 4: torch.Size([25, 128, 16, 16])\n",
      "encoder 5: torch.Size([25, 256, 8, 8])\n",
      "encoder 6: torch.Size([25, 512, 4, 4])\n",
      "encoder 7: torch.Size([25, 1024, 2, 2])\n",
      "encoder 8: torch.Size([25, 2048, 1, 1])\n",
      "LATENTS HERE\n",
      "torch.Size([25, 2048, 1, 1, 1])\n",
      "res conn shape: torch.Size([25, 2048, 1, 1])\n",
      "inflated conn shape: torch.Size([25, 2048, 1, 1, 1])\n",
      "dencoder 1: torch.Size([25, 1024, 2, 2, 2])\n",
      "res conn shape: torch.Size([25, 1024, 2, 2])\n",
      "inflated conn shape: torch.Size([25, 1024, 2, 2, 2])\n",
      "dencoder 2: torch.Size([25, 512, 4, 4, 4])\n",
      "res conn shape: torch.Size([25, 512, 4, 4])\n",
      "inflated conn shape: torch.Size([25, 512, 4, 4, 4])\n",
      "dencoder 3: torch.Size([25, 256, 8, 8, 8])\n",
      "res conn shape: torch.Size([25, 256, 8, 8])\n",
      "inflated conn shape: torch.Size([25, 256, 8, 8, 8])\n",
      "dencoder 4: torch.Size([25, 128, 16, 16, 16])\n",
      "res conn shape: torch.Size([25, 128, 16, 16])\n",
      "inflated conn shape: torch.Size([25, 128, 16, 16, 16])\n",
      "dencoder 5: torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv1 torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv2 torch.Size([25, 32, 48, 48, 48])\n",
      "before final conv3 torch.Size([25, 16, 48, 48, 48])\n",
      "before final conv4 torch.Size([25, 4, 48, 48, 48])\n",
      "tensor(0.0641, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|█████████████████████████████| 1/1 [00:43<00:00, 43.22s/minibatches]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[misclassification_rate - train] 356369.0\n",
      "Adding in dict for wandb: 'train_misclassification_rate': 356369.0\n",
      "torch.Size([5, 6, 256, 256])\n",
      "encoder 1: torch.Size([5, 16, 128, 128])\n",
      "encoder 2: torch.Size([5, 32, 64, 64])\n",
      "encoder 3: torch.Size([5, 64, 32, 32])\n",
      "encoder 4: torch.Size([5, 128, 16, 16])\n",
      "encoder 5: torch.Size([5, 256, 8, 8])\n",
      "encoder 6: torch.Size([5, 512, 4, 4])\n",
      "encoder 7: torch.Size([5, 1024, 2, 2])\n",
      "encoder 8: torch.Size([5, 2048, 1, 1])\n",
      "LATENTS HERE\n",
      "torch.Size([5, 2048, 1, 1, 1])\n",
      "res conn shape: torch.Size([5, 2048, 1, 1])\n",
      "inflated conn shape: torch.Size([5, 2048, 1, 1, 1])\n",
      "dencoder 1: torch.Size([5, 1024, 2, 2, 2])\n",
      "res conn shape: torch.Size([5, 1024, 2, 2])\n",
      "inflated conn shape: torch.Size([5, 1024, 2, 2, 2])\n",
      "dencoder 2: torch.Size([5, 512, 4, 4, 4])\n",
      "res conn shape: torch.Size([5, 512, 4, 4])\n",
      "inflated conn shape: torch.Size([5, 512, 4, 4, 4])\n",
      "dencoder 3: torch.Size([5, 256, 8, 8, 8])\n",
      "res conn shape: torch.Size([5, 256, 8, 8])\n",
      "inflated conn shape: torch.Size([5, 256, 8, 8, 8])\n",
      "dencoder 4: torch.Size([5, 128, 16, 16, 16])\n",
      "res conn shape: torch.Size([5, 128, 16, 16])\n",
      "inflated conn shape: torch.Size([5, 128, 16, 16, 16])\n",
      "dencoder 5: torch.Size([5, 64, 48, 48, 48])\n",
      "before final conv1 torch.Size([5, 64, 48, 48, 48])\n",
      "before final conv2 torch.Size([5, 32, 48, 48, 48])\n",
      "before final conv3 torch.Size([5, 16, 48, 48, 48])\n",
      "before final conv4 torch.Size([5, 4, 48, 48, 48])\n",
      "[misclassification_rate - validation] 8257.0\n",
      "Adding in dict for wandb: 'validation_misclassification_rate': 8257.0\n",
      "\n",
      "Val loss: 0.15938936173915863,  val batches: 1\n",
      "Logging to wandb: {'train_misclassification_rate': 356369.0, 'validation_misclassification_rate': 8257.0, 'train_loss': 0.06405065208673477, 'val_loss': 0.06405065208673477, 'lr': 0.006}\n",
      "\n",
      "\n",
      "   Epoch 11/1224, Loss: 0.06405065208673477, lr: 0.006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                     | 0/1 [00:00<?, ?minibatches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 6, 256, 256])\n",
      "encoder 1: torch.Size([25, 16, 128, 128])\n",
      "encoder 2: torch.Size([25, 32, 64, 64])\n",
      "encoder 3: torch.Size([25, 64, 32, 32])\n",
      "encoder 4: torch.Size([25, 128, 16, 16])\n",
      "encoder 5: torch.Size([25, 256, 8, 8])\n",
      "encoder 6: torch.Size([25, 512, 4, 4])\n",
      "encoder 7: torch.Size([25, 1024, 2, 2])\n",
      "encoder 8: torch.Size([25, 2048, 1, 1])\n",
      "LATENTS HERE\n",
      "torch.Size([25, 2048, 1, 1, 1])\n",
      "res conn shape: torch.Size([25, 2048, 1, 1])\n",
      "inflated conn shape: torch.Size([25, 2048, 1, 1, 1])\n",
      "dencoder 1: torch.Size([25, 1024, 2, 2, 2])\n",
      "res conn shape: torch.Size([25, 1024, 2, 2])\n",
      "inflated conn shape: torch.Size([25, 1024, 2, 2, 2])\n",
      "dencoder 2: torch.Size([25, 512, 4, 4, 4])\n",
      "res conn shape: torch.Size([25, 512, 4, 4])\n",
      "inflated conn shape: torch.Size([25, 512, 4, 4, 4])\n",
      "dencoder 3: torch.Size([25, 256, 8, 8, 8])\n",
      "res conn shape: torch.Size([25, 256, 8, 8])\n",
      "inflated conn shape: torch.Size([25, 256, 8, 8, 8])\n",
      "dencoder 4: torch.Size([25, 128, 16, 16, 16])\n",
      "res conn shape: torch.Size([25, 128, 16, 16])\n",
      "inflated conn shape: torch.Size([25, 128, 16, 16, 16])\n",
      "dencoder 5: torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv1 torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv2 torch.Size([25, 32, 48, 48, 48])\n",
      "before final conv3 torch.Size([25, 16, 48, 48, 48])\n",
      "before final conv4 torch.Size([25, 4, 48, 48, 48])\n",
      "tensor(0.0554, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|█████████████████████████████| 1/1 [00:43<00:00, 43.61s/minibatches]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[misclassification_rate - train] 276709.0\n",
      "Adding in dict for wandb: 'train_misclassification_rate': 276709.0\n",
      "torch.Size([5, 6, 256, 256])\n",
      "encoder 1: torch.Size([5, 16, 128, 128])\n",
      "encoder 2: torch.Size([5, 32, 64, 64])\n",
      "encoder 3: torch.Size([5, 64, 32, 32])\n",
      "encoder 4: torch.Size([5, 128, 16, 16])\n",
      "encoder 5: torch.Size([5, 256, 8, 8])\n",
      "encoder 6: torch.Size([5, 512, 4, 4])\n",
      "encoder 7: torch.Size([5, 1024, 2, 2])\n",
      "encoder 8: torch.Size([5, 2048, 1, 1])\n",
      "LATENTS HERE\n",
      "torch.Size([5, 2048, 1, 1, 1])\n",
      "res conn shape: torch.Size([5, 2048, 1, 1])\n",
      "inflated conn shape: torch.Size([5, 2048, 1, 1, 1])\n",
      "dencoder 1: torch.Size([5, 1024, 2, 2, 2])\n",
      "res conn shape: torch.Size([5, 1024, 2, 2])\n",
      "inflated conn shape: torch.Size([5, 1024, 2, 2, 2])\n",
      "dencoder 2: torch.Size([5, 512, 4, 4, 4])\n",
      "res conn shape: torch.Size([5, 512, 4, 4])\n",
      "inflated conn shape: torch.Size([5, 512, 4, 4, 4])\n",
      "dencoder 3: torch.Size([5, 256, 8, 8, 8])\n",
      "res conn shape: torch.Size([5, 256, 8, 8])\n",
      "inflated conn shape: torch.Size([5, 256, 8, 8, 8])\n",
      "dencoder 4: torch.Size([5, 128, 16, 16, 16])\n",
      "res conn shape: torch.Size([5, 128, 16, 16])\n",
      "inflated conn shape: torch.Size([5, 128, 16, 16, 16])\n",
      "dencoder 5: torch.Size([5, 64, 48, 48, 48])\n",
      "before final conv1 torch.Size([5, 64, 48, 48, 48])\n",
      "before final conv2 torch.Size([5, 32, 48, 48, 48])\n",
      "before final conv3 torch.Size([5, 16, 48, 48, 48])\n",
      "before final conv4 torch.Size([5, 4, 48, 48, 48])\n",
      "[misclassification_rate - validation] 8930.0\n",
      "Adding in dict for wandb: 'validation_misclassification_rate': 8930.0\n",
      "\n",
      "Val loss: 0.1309642195701599,  val batches: 1\n",
      "Logging to wandb: {'train_misclassification_rate': 276709.0, 'validation_misclassification_rate': 8930.0, 'train_loss': 0.05537038668990135, 'val_loss': 0.05537038668990135, 'lr': 0.006}\n",
      "\n",
      "\n",
      "   Epoch 12/1224, Loss: 0.05537038668990135, lr: 0.006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                     | 0/1 [00:00<?, ?minibatches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 6, 256, 256])\n",
      "encoder 1: torch.Size([25, 16, 128, 128])\n",
      "encoder 2: torch.Size([25, 32, 64, 64])\n",
      "encoder 3: torch.Size([25, 64, 32, 32])\n",
      "encoder 4: torch.Size([25, 128, 16, 16])\n",
      "encoder 5: torch.Size([25, 256, 8, 8])\n",
      "encoder 6: torch.Size([25, 512, 4, 4])\n",
      "encoder 7: torch.Size([25, 1024, 2, 2])\n",
      "encoder 8: torch.Size([25, 2048, 1, 1])\n",
      "LATENTS HERE\n",
      "torch.Size([25, 2048, 1, 1, 1])\n",
      "res conn shape: torch.Size([25, 2048, 1, 1])\n",
      "inflated conn shape: torch.Size([25, 2048, 1, 1, 1])\n",
      "dencoder 1: torch.Size([25, 1024, 2, 2, 2])\n",
      "res conn shape: torch.Size([25, 1024, 2, 2])\n",
      "inflated conn shape: torch.Size([25, 1024, 2, 2, 2])\n",
      "dencoder 2: torch.Size([25, 512, 4, 4, 4])\n",
      "res conn shape: torch.Size([25, 512, 4, 4])\n",
      "inflated conn shape: torch.Size([25, 512, 4, 4, 4])\n",
      "dencoder 3: torch.Size([25, 256, 8, 8, 8])\n",
      "res conn shape: torch.Size([25, 256, 8, 8])\n",
      "inflated conn shape: torch.Size([25, 256, 8, 8, 8])\n",
      "dencoder 4: torch.Size([25, 128, 16, 16, 16])\n",
      "res conn shape: torch.Size([25, 128, 16, 16])\n",
      "inflated conn shape: torch.Size([25, 128, 16, 16, 16])\n",
      "dencoder 5: torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv1 torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv2 torch.Size([25, 32, 48, 48, 48])\n",
      "before final conv3 torch.Size([25, 16, 48, 48, 48])\n",
      "before final conv4 torch.Size([25, 4, 48, 48, 48])\n",
      "tensor(0.0505, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|█████████████████████████████| 1/1 [00:43<00:00, 43.64s/minibatches]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[misclassification_rate - train] 174525.0\n",
      "Adding in dict for wandb: 'train_misclassification_rate': 174525.0\n",
      "torch.Size([5, 6, 256, 256])\n",
      "encoder 1: torch.Size([5, 16, 128, 128])\n",
      "encoder 2: torch.Size([5, 32, 64, 64])\n",
      "encoder 3: torch.Size([5, 64, 32, 32])\n",
      "encoder 4: torch.Size([5, 128, 16, 16])\n",
      "encoder 5: torch.Size([5, 256, 8, 8])\n",
      "encoder 6: torch.Size([5, 512, 4, 4])\n",
      "encoder 7: torch.Size([5, 1024, 2, 2])\n",
      "encoder 8: torch.Size([5, 2048, 1, 1])\n",
      "LATENTS HERE\n",
      "torch.Size([5, 2048, 1, 1, 1])\n",
      "res conn shape: torch.Size([5, 2048, 1, 1])\n",
      "inflated conn shape: torch.Size([5, 2048, 1, 1, 1])\n",
      "dencoder 1: torch.Size([5, 1024, 2, 2, 2])\n",
      "res conn shape: torch.Size([5, 1024, 2, 2])\n",
      "inflated conn shape: torch.Size([5, 1024, 2, 2, 2])\n",
      "dencoder 2: torch.Size([5, 512, 4, 4, 4])\n",
      "res conn shape: torch.Size([5, 512, 4, 4])\n",
      "inflated conn shape: torch.Size([5, 512, 4, 4, 4])\n",
      "dencoder 3: torch.Size([5, 256, 8, 8, 8])\n",
      "res conn shape: torch.Size([5, 256, 8, 8])\n",
      "inflated conn shape: torch.Size([5, 256, 8, 8, 8])\n",
      "dencoder 4: torch.Size([5, 128, 16, 16, 16])\n",
      "res conn shape: torch.Size([5, 128, 16, 16])\n",
      "inflated conn shape: torch.Size([5, 128, 16, 16, 16])\n",
      "dencoder 5: torch.Size([5, 64, 48, 48, 48])\n",
      "before final conv1 torch.Size([5, 64, 48, 48, 48])\n",
      "before final conv2 torch.Size([5, 32, 48, 48, 48])\n",
      "before final conv3 torch.Size([5, 16, 48, 48, 48])\n",
      "before final conv4 torch.Size([5, 4, 48, 48, 48])\n",
      "[misclassification_rate - validation] 5008.0\n",
      "Adding in dict for wandb: 'validation_misclassification_rate': 5008.0\n",
      "\n",
      "Val loss: 0.12230988591909409,  val batches: 1\n",
      "Logging to wandb: {'train_misclassification_rate': 174525.0, 'validation_misclassification_rate': 5008.0, 'train_loss': 0.050476063042879105, 'val_loss': 0.050476063042879105, 'lr': 0.006}\n",
      "\n",
      "\n",
      "   Epoch 13/1224, Loss: 0.050476063042879105, lr: 0.006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                     | 0/1 [00:00<?, ?minibatches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 6, 256, 256])\n",
      "encoder 1: torch.Size([25, 16, 128, 128])\n",
      "encoder 2: torch.Size([25, 32, 64, 64])\n",
      "encoder 3: torch.Size([25, 64, 32, 32])\n",
      "encoder 4: torch.Size([25, 128, 16, 16])\n",
      "encoder 5: torch.Size([25, 256, 8, 8])\n",
      "encoder 6: torch.Size([25, 512, 4, 4])\n",
      "encoder 7: torch.Size([25, 1024, 2, 2])\n",
      "encoder 8: torch.Size([25, 2048, 1, 1])\n",
      "LATENTS HERE\n",
      "torch.Size([25, 2048, 1, 1, 1])\n",
      "res conn shape: torch.Size([25, 2048, 1, 1])\n",
      "inflated conn shape: torch.Size([25, 2048, 1, 1, 1])\n",
      "dencoder 1: torch.Size([25, 1024, 2, 2, 2])\n",
      "res conn shape: torch.Size([25, 1024, 2, 2])\n",
      "inflated conn shape: torch.Size([25, 1024, 2, 2, 2])\n",
      "dencoder 2: torch.Size([25, 512, 4, 4, 4])\n",
      "res conn shape: torch.Size([25, 512, 4, 4])\n",
      "inflated conn shape: torch.Size([25, 512, 4, 4, 4])\n",
      "dencoder 3: torch.Size([25, 256, 8, 8, 8])\n",
      "res conn shape: torch.Size([25, 256, 8, 8])\n",
      "inflated conn shape: torch.Size([25, 256, 8, 8, 8])\n",
      "dencoder 4: torch.Size([25, 128, 16, 16, 16])\n",
      "res conn shape: torch.Size([25, 128, 16, 16])\n",
      "inflated conn shape: torch.Size([25, 128, 16, 16, 16])\n",
      "dencoder 5: torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv1 torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv2 torch.Size([25, 32, 48, 48, 48])\n",
      "before final conv3 torch.Size([25, 16, 48, 48, 48])\n",
      "before final conv4 torch.Size([25, 4, 48, 48, 48])\n",
      "tensor(0.0485, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|█████████████████████████████| 1/1 [00:43<00:00, 43.29s/minibatches]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[misclassification_rate - train] 118428.0\n",
      "Adding in dict for wandb: 'train_misclassification_rate': 118428.0\n",
      "torch.Size([5, 6, 256, 256])\n",
      "encoder 1: torch.Size([5, 16, 128, 128])\n",
      "encoder 2: torch.Size([5, 32, 64, 64])\n",
      "encoder 3: torch.Size([5, 64, 32, 32])\n",
      "encoder 4: torch.Size([5, 128, 16, 16])\n",
      "encoder 5: torch.Size([5, 256, 8, 8])\n",
      "encoder 6: torch.Size([5, 512, 4, 4])\n",
      "encoder 7: torch.Size([5, 1024, 2, 2])\n",
      "encoder 8: torch.Size([5, 2048, 1, 1])\n",
      "LATENTS HERE\n",
      "torch.Size([5, 2048, 1, 1, 1])\n",
      "res conn shape: torch.Size([5, 2048, 1, 1])\n",
      "inflated conn shape: torch.Size([5, 2048, 1, 1, 1])\n",
      "dencoder 1: torch.Size([5, 1024, 2, 2, 2])\n",
      "res conn shape: torch.Size([5, 1024, 2, 2])\n",
      "inflated conn shape: torch.Size([5, 1024, 2, 2, 2])\n",
      "dencoder 2: torch.Size([5, 512, 4, 4, 4])\n",
      "res conn shape: torch.Size([5, 512, 4, 4])\n",
      "inflated conn shape: torch.Size([5, 512, 4, 4, 4])\n",
      "dencoder 3: torch.Size([5, 256, 8, 8, 8])\n",
      "res conn shape: torch.Size([5, 256, 8, 8])\n",
      "inflated conn shape: torch.Size([5, 256, 8, 8, 8])\n",
      "dencoder 4: torch.Size([5, 128, 16, 16, 16])\n",
      "res conn shape: torch.Size([5, 128, 16, 16])\n",
      "inflated conn shape: torch.Size([5, 128, 16, 16, 16])\n",
      "dencoder 5: torch.Size([5, 64, 48, 48, 48])\n",
      "before final conv1 torch.Size([5, 64, 48, 48, 48])\n",
      "before final conv2 torch.Size([5, 32, 48, 48, 48])\n",
      "before final conv3 torch.Size([5, 16, 48, 48, 48])\n",
      "before final conv4 torch.Size([5, 4, 48, 48, 48])\n",
      "[misclassification_rate - validation] 4649.0\n",
      "Adding in dict for wandb: 'validation_misclassification_rate': 4649.0\n",
      "\n",
      "Val loss: 0.10885082185268402,  val batches: 1\n",
      "Logging to wandb: {'train_misclassification_rate': 118428.0, 'validation_misclassification_rate': 4649.0, 'train_loss': 0.04845590516924858, 'val_loss': 0.04845590516924858, 'lr': 0.006}\n",
      "\n",
      "\n",
      "   Epoch 14/1224, Loss: 0.04845590516924858, lr: 0.006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                     | 0/1 [00:00<?, ?minibatches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 6, 256, 256])\n",
      "encoder 1: torch.Size([25, 16, 128, 128])\n",
      "encoder 2: torch.Size([25, 32, 64, 64])\n",
      "encoder 3: torch.Size([25, 64, 32, 32])\n",
      "encoder 4: torch.Size([25, 128, 16, 16])\n",
      "encoder 5: torch.Size([25, 256, 8, 8])\n",
      "encoder 6: torch.Size([25, 512, 4, 4])\n",
      "encoder 7: torch.Size([25, 1024, 2, 2])\n",
      "encoder 8: torch.Size([25, 2048, 1, 1])\n",
      "LATENTS HERE\n",
      "torch.Size([25, 2048, 1, 1, 1])\n",
      "res conn shape: torch.Size([25, 2048, 1, 1])\n",
      "inflated conn shape: torch.Size([25, 2048, 1, 1, 1])\n",
      "dencoder 1: torch.Size([25, 1024, 2, 2, 2])\n",
      "res conn shape: torch.Size([25, 1024, 2, 2])\n",
      "inflated conn shape: torch.Size([25, 1024, 2, 2, 2])\n",
      "dencoder 2: torch.Size([25, 512, 4, 4, 4])\n",
      "res conn shape: torch.Size([25, 512, 4, 4])\n",
      "inflated conn shape: torch.Size([25, 512, 4, 4, 4])\n",
      "dencoder 3: torch.Size([25, 256, 8, 8, 8])\n",
      "res conn shape: torch.Size([25, 256, 8, 8])\n",
      "inflated conn shape: torch.Size([25, 256, 8, 8, 8])\n",
      "dencoder 4: torch.Size([25, 128, 16, 16, 16])\n",
      "res conn shape: torch.Size([25, 128, 16, 16])\n",
      "inflated conn shape: torch.Size([25, 128, 16, 16, 16])\n",
      "dencoder 5: torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv1 torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv2 torch.Size([25, 32, 48, 48, 48])\n",
      "before final conv3 torch.Size([25, 16, 48, 48, 48])\n",
      "before final conv4 torch.Size([25, 4, 48, 48, 48])\n",
      "tensor(0.0479, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|█████████████████████████████| 1/1 [00:43<00:00, 43.73s/minibatches]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[misclassification_rate - train] 73031.0\n",
      "Adding in dict for wandb: 'train_misclassification_rate': 73031.0\n",
      "torch.Size([5, 6, 256, 256])\n",
      "encoder 1: torch.Size([5, 16, 128, 128])\n",
      "encoder 2: torch.Size([5, 32, 64, 64])\n",
      "encoder 3: torch.Size([5, 64, 32, 32])\n",
      "encoder 4: torch.Size([5, 128, 16, 16])\n",
      "encoder 5: torch.Size([5, 256, 8, 8])\n",
      "encoder 6: torch.Size([5, 512, 4, 4])\n",
      "encoder 7: torch.Size([5, 1024, 2, 2])\n",
      "encoder 8: torch.Size([5, 2048, 1, 1])\n",
      "LATENTS HERE\n",
      "torch.Size([5, 2048, 1, 1, 1])\n",
      "res conn shape: torch.Size([5, 2048, 1, 1])\n",
      "inflated conn shape: torch.Size([5, 2048, 1, 1, 1])\n",
      "dencoder 1: torch.Size([5, 1024, 2, 2, 2])\n",
      "res conn shape: torch.Size([5, 1024, 2, 2])\n",
      "inflated conn shape: torch.Size([5, 1024, 2, 2, 2])\n",
      "dencoder 2: torch.Size([5, 512, 4, 4, 4])\n",
      "res conn shape: torch.Size([5, 512, 4, 4])\n",
      "inflated conn shape: torch.Size([5, 512, 4, 4, 4])\n",
      "dencoder 3: torch.Size([5, 256, 8, 8, 8])\n",
      "res conn shape: torch.Size([5, 256, 8, 8])\n",
      "inflated conn shape: torch.Size([5, 256, 8, 8, 8])\n",
      "dencoder 4: torch.Size([5, 128, 16, 16, 16])\n",
      "res conn shape: torch.Size([5, 128, 16, 16])\n",
      "inflated conn shape: torch.Size([5, 128, 16, 16, 16])\n",
      "dencoder 5: torch.Size([5, 64, 48, 48, 48])\n",
      "before final conv1 torch.Size([5, 64, 48, 48, 48])\n",
      "before final conv2 torch.Size([5, 32, 48, 48, 48])\n",
      "before final conv3 torch.Size([5, 16, 48, 48, 48])\n",
      "before final conv4 torch.Size([5, 4, 48, 48, 48])\n",
      "[misclassification_rate - validation] 4612.0\n",
      "Adding in dict for wandb: 'validation_misclassification_rate': 4612.0\n",
      "\n",
      "Val loss: 0.10948485881090164,  val batches: 1\n",
      "Logging to wandb: {'train_misclassification_rate': 73031.0, 'validation_misclassification_rate': 4612.0, 'train_loss': 0.04785596951842308, 'val_loss': 0.04785596951842308, 'lr': 0.006}\n",
      "\n",
      "\n",
      "   Epoch 15/1224, Loss: 0.04785596951842308, lr: 0.006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                     | 0/1 [00:00<?, ?minibatches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 6, 256, 256])\n",
      "encoder 1: torch.Size([25, 16, 128, 128])\n",
      "encoder 2: torch.Size([25, 32, 64, 64])\n",
      "encoder 3: torch.Size([25, 64, 32, 32])\n",
      "encoder 4: torch.Size([25, 128, 16, 16])\n",
      "encoder 5: torch.Size([25, 256, 8, 8])\n",
      "encoder 6: torch.Size([25, 512, 4, 4])\n",
      "encoder 7: torch.Size([25, 1024, 2, 2])\n",
      "encoder 8: torch.Size([25, 2048, 1, 1])\n",
      "LATENTS HERE\n",
      "torch.Size([25, 2048, 1, 1, 1])\n",
      "res conn shape: torch.Size([25, 2048, 1, 1])\n",
      "inflated conn shape: torch.Size([25, 2048, 1, 1, 1])\n",
      "dencoder 1: torch.Size([25, 1024, 2, 2, 2])\n",
      "res conn shape: torch.Size([25, 1024, 2, 2])\n",
      "inflated conn shape: torch.Size([25, 1024, 2, 2, 2])\n",
      "dencoder 2: torch.Size([25, 512, 4, 4, 4])\n",
      "res conn shape: torch.Size([25, 512, 4, 4])\n",
      "inflated conn shape: torch.Size([25, 512, 4, 4, 4])\n",
      "dencoder 3: torch.Size([25, 256, 8, 8, 8])\n",
      "res conn shape: torch.Size([25, 256, 8, 8])\n",
      "inflated conn shape: torch.Size([25, 256, 8, 8, 8])\n",
      "dencoder 4: torch.Size([25, 128, 16, 16, 16])\n",
      "res conn shape: torch.Size([25, 128, 16, 16])\n",
      "inflated conn shape: torch.Size([25, 128, 16, 16, 16])\n",
      "dencoder 5: torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv1 torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv2 torch.Size([25, 32, 48, 48, 48])\n",
      "before final conv3 torch.Size([25, 16, 48, 48, 48])\n",
      "before final conv4 torch.Size([25, 4, 48, 48, 48])\n",
      "tensor(0.0478, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|█████████████████████████████| 1/1 [00:43<00:00, 43.15s/minibatches]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[misclassification_rate - train] 54381.0\n",
      "Adding in dict for wandb: 'train_misclassification_rate': 54381.0\n",
      "torch.Size([5, 6, 256, 256])\n",
      "encoder 1: torch.Size([5, 16, 128, 128])\n",
      "encoder 2: torch.Size([5, 32, 64, 64])\n",
      "encoder 3: torch.Size([5, 64, 32, 32])\n",
      "encoder 4: torch.Size([5, 128, 16, 16])\n",
      "encoder 5: torch.Size([5, 256, 8, 8])\n",
      "encoder 6: torch.Size([5, 512, 4, 4])\n",
      "encoder 7: torch.Size([5, 1024, 2, 2])\n",
      "encoder 8: torch.Size([5, 2048, 1, 1])\n",
      "LATENTS HERE\n",
      "torch.Size([5, 2048, 1, 1, 1])\n",
      "res conn shape: torch.Size([5, 2048, 1, 1])\n",
      "inflated conn shape: torch.Size([5, 2048, 1, 1, 1])\n",
      "dencoder 1: torch.Size([5, 1024, 2, 2, 2])\n",
      "res conn shape: torch.Size([5, 1024, 2, 2])\n",
      "inflated conn shape: torch.Size([5, 1024, 2, 2, 2])\n",
      "dencoder 2: torch.Size([5, 512, 4, 4, 4])\n",
      "res conn shape: torch.Size([5, 512, 4, 4])\n",
      "inflated conn shape: torch.Size([5, 512, 4, 4, 4])\n",
      "dencoder 3: torch.Size([5, 256, 8, 8, 8])\n",
      "res conn shape: torch.Size([5, 256, 8, 8])\n",
      "inflated conn shape: torch.Size([5, 256, 8, 8, 8])\n",
      "dencoder 4: torch.Size([5, 128, 16, 16, 16])\n",
      "res conn shape: torch.Size([5, 128, 16, 16])\n",
      "inflated conn shape: torch.Size([5, 128, 16, 16, 16])\n",
      "dencoder 5: torch.Size([5, 64, 48, 48, 48])\n",
      "before final conv1 torch.Size([5, 64, 48, 48, 48])\n",
      "before final conv2 torch.Size([5, 32, 48, 48, 48])\n",
      "before final conv3 torch.Size([5, 16, 48, 48, 48])\n",
      "before final conv4 torch.Size([5, 4, 48, 48, 48])\n",
      "[misclassification_rate - validation] 4431.0\n",
      "Adding in dict for wandb: 'validation_misclassification_rate': 4431.0\n",
      "\n",
      "Val loss: 0.10220393538475037,  val batches: 1\n",
      "Logging to wandb: {'train_misclassification_rate': 54381.0, 'validation_misclassification_rate': 4431.0, 'train_loss': 0.0477614626288414, 'val_loss': 0.0477614626288414, 'lr': 0.006}\n",
      "\n",
      "\n",
      "   Epoch 16/1224, Loss: 0.0477614626288414, lr: 0.006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                     | 0/1 [00:00<?, ?minibatches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 6, 256, 256])\n",
      "encoder 1: torch.Size([25, 16, 128, 128])\n",
      "encoder 2: torch.Size([25, 32, 64, 64])\n",
      "encoder 3: torch.Size([25, 64, 32, 32])\n",
      "encoder 4: torch.Size([25, 128, 16, 16])\n",
      "encoder 5: torch.Size([25, 256, 8, 8])\n",
      "encoder 6: torch.Size([25, 512, 4, 4])\n",
      "encoder 7: torch.Size([25, 1024, 2, 2])\n",
      "encoder 8: torch.Size([25, 2048, 1, 1])\n",
      "LATENTS HERE\n",
      "torch.Size([25, 2048, 1, 1, 1])\n",
      "res conn shape: torch.Size([25, 2048, 1, 1])\n",
      "inflated conn shape: torch.Size([25, 2048, 1, 1, 1])\n",
      "dencoder 1: torch.Size([25, 1024, 2, 2, 2])\n",
      "res conn shape: torch.Size([25, 1024, 2, 2])\n",
      "inflated conn shape: torch.Size([25, 1024, 2, 2, 2])\n",
      "dencoder 2: torch.Size([25, 512, 4, 4, 4])\n",
      "res conn shape: torch.Size([25, 512, 4, 4])\n",
      "inflated conn shape: torch.Size([25, 512, 4, 4, 4])\n",
      "dencoder 3: torch.Size([25, 256, 8, 8, 8])\n",
      "res conn shape: torch.Size([25, 256, 8, 8])\n",
      "inflated conn shape: torch.Size([25, 256, 8, 8, 8])\n",
      "dencoder 4: torch.Size([25, 128, 16, 16, 16])\n",
      "res conn shape: torch.Size([25, 128, 16, 16])\n",
      "inflated conn shape: torch.Size([25, 128, 16, 16, 16])\n",
      "dencoder 5: torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv1 torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv2 torch.Size([25, 32, 48, 48, 48])\n",
      "before final conv3 torch.Size([25, 16, 48, 48, 48])\n",
      "before final conv4 torch.Size([25, 4, 48, 48, 48])\n",
      "tensor(0.0474, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|█████████████████████████████| 1/1 [00:43<00:00, 43.02s/minibatches]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[misclassification_rate - train] 39315.0\n",
      "Adding in dict for wandb: 'train_misclassification_rate': 39315.0\n",
      "torch.Size([5, 6, 256, 256])\n",
      "encoder 1: torch.Size([5, 16, 128, 128])\n",
      "encoder 2: torch.Size([5, 32, 64, 64])\n",
      "encoder 3: torch.Size([5, 64, 32, 32])\n",
      "encoder 4: torch.Size([5, 128, 16, 16])\n",
      "encoder 5: torch.Size([5, 256, 8, 8])\n",
      "encoder 6: torch.Size([5, 512, 4, 4])\n",
      "encoder 7: torch.Size([5, 1024, 2, 2])\n",
      "encoder 8: torch.Size([5, 2048, 1, 1])\n",
      "LATENTS HERE\n",
      "torch.Size([5, 2048, 1, 1, 1])\n",
      "res conn shape: torch.Size([5, 2048, 1, 1])\n",
      "inflated conn shape: torch.Size([5, 2048, 1, 1, 1])\n",
      "dencoder 1: torch.Size([5, 1024, 2, 2, 2])\n",
      "res conn shape: torch.Size([5, 1024, 2, 2])\n",
      "inflated conn shape: torch.Size([5, 1024, 2, 2, 2])\n",
      "dencoder 2: torch.Size([5, 512, 4, 4, 4])\n",
      "res conn shape: torch.Size([5, 512, 4, 4])\n",
      "inflated conn shape: torch.Size([5, 512, 4, 4, 4])\n",
      "dencoder 3: torch.Size([5, 256, 8, 8, 8])\n",
      "res conn shape: torch.Size([5, 256, 8, 8])\n",
      "inflated conn shape: torch.Size([5, 256, 8, 8, 8])\n",
      "dencoder 4: torch.Size([5, 128, 16, 16, 16])\n",
      "res conn shape: torch.Size([5, 128, 16, 16])\n",
      "inflated conn shape: torch.Size([5, 128, 16, 16, 16])\n",
      "dencoder 5: torch.Size([5, 64, 48, 48, 48])\n",
      "before final conv1 torch.Size([5, 64, 48, 48, 48])\n",
      "before final conv2 torch.Size([5, 32, 48, 48, 48])\n",
      "before final conv3 torch.Size([5, 16, 48, 48, 48])\n",
      "before final conv4 torch.Size([5, 4, 48, 48, 48])\n",
      "[misclassification_rate - validation] 4535.0\n",
      "Adding in dict for wandb: 'validation_misclassification_rate': 4535.0\n",
      "\n",
      "Val loss: 0.09729896485805511,  val batches: 1\n",
      "Logging to wandb: {'train_misclassification_rate': 39315.0, 'validation_misclassification_rate': 4535.0, 'train_loss': 0.04742768406867981, 'val_loss': 0.04742768406867981, 'lr': 0.006}\n",
      "\n",
      "\n",
      "   Epoch 17/1224, Loss: 0.04742768406867981, lr: 0.006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                     | 0/1 [00:00<?, ?minibatches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 6, 256, 256])\n",
      "encoder 1: torch.Size([25, 16, 128, 128])\n",
      "encoder 2: torch.Size([25, 32, 64, 64])\n",
      "encoder 3: torch.Size([25, 64, 32, 32])\n",
      "encoder 4: torch.Size([25, 128, 16, 16])\n",
      "encoder 5: torch.Size([25, 256, 8, 8])\n",
      "encoder 6: torch.Size([25, 512, 4, 4])\n",
      "encoder 7: torch.Size([25, 1024, 2, 2])\n",
      "encoder 8: torch.Size([25, 2048, 1, 1])\n",
      "LATENTS HERE\n",
      "torch.Size([25, 2048, 1, 1, 1])\n",
      "res conn shape: torch.Size([25, 2048, 1, 1])\n",
      "inflated conn shape: torch.Size([25, 2048, 1, 1, 1])\n",
      "dencoder 1: torch.Size([25, 1024, 2, 2, 2])\n",
      "res conn shape: torch.Size([25, 1024, 2, 2])\n",
      "inflated conn shape: torch.Size([25, 1024, 2, 2, 2])\n",
      "dencoder 2: torch.Size([25, 512, 4, 4, 4])\n",
      "res conn shape: torch.Size([25, 512, 4, 4])\n",
      "inflated conn shape: torch.Size([25, 512, 4, 4, 4])\n",
      "dencoder 3: torch.Size([25, 256, 8, 8, 8])\n",
      "res conn shape: torch.Size([25, 256, 8, 8])\n",
      "inflated conn shape: torch.Size([25, 256, 8, 8, 8])\n",
      "dencoder 4: torch.Size([25, 128, 16, 16, 16])\n",
      "res conn shape: torch.Size([25, 128, 16, 16])\n",
      "inflated conn shape: torch.Size([25, 128, 16, 16, 16])\n",
      "dencoder 5: torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv1 torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv2 torch.Size([25, 32, 48, 48, 48])\n",
      "before final conv3 torch.Size([25, 16, 48, 48, 48])\n",
      "before final conv4 torch.Size([25, 4, 48, 48, 48])\n",
      "tensor(0.0472, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|█████████████████████████████| 1/1 [00:43<00:00, 43.43s/minibatches]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[misclassification_rate - train] 36539.0\n",
      "Adding in dict for wandb: 'train_misclassification_rate': 36539.0\n",
      "torch.Size([5, 6, 256, 256])\n",
      "encoder 1: torch.Size([5, 16, 128, 128])\n",
      "encoder 2: torch.Size([5, 32, 64, 64])\n",
      "encoder 3: torch.Size([5, 64, 32, 32])\n",
      "encoder 4: torch.Size([5, 128, 16, 16])\n",
      "encoder 5: torch.Size([5, 256, 8, 8])\n",
      "encoder 6: torch.Size([5, 512, 4, 4])\n",
      "encoder 7: torch.Size([5, 1024, 2, 2])\n",
      "encoder 8: torch.Size([5, 2048, 1, 1])\n",
      "LATENTS HERE\n",
      "torch.Size([5, 2048, 1, 1, 1])\n",
      "res conn shape: torch.Size([5, 2048, 1, 1])\n",
      "inflated conn shape: torch.Size([5, 2048, 1, 1, 1])\n",
      "dencoder 1: torch.Size([5, 1024, 2, 2, 2])\n",
      "res conn shape: torch.Size([5, 1024, 2, 2])\n",
      "inflated conn shape: torch.Size([5, 1024, 2, 2, 2])\n",
      "dencoder 2: torch.Size([5, 512, 4, 4, 4])\n",
      "res conn shape: torch.Size([5, 512, 4, 4])\n",
      "inflated conn shape: torch.Size([5, 512, 4, 4, 4])\n",
      "dencoder 3: torch.Size([5, 256, 8, 8, 8])\n",
      "res conn shape: torch.Size([5, 256, 8, 8])\n",
      "inflated conn shape: torch.Size([5, 256, 8, 8, 8])\n",
      "dencoder 4: torch.Size([5, 128, 16, 16, 16])\n",
      "res conn shape: torch.Size([5, 128, 16, 16])\n",
      "inflated conn shape: torch.Size([5, 128, 16, 16, 16])\n",
      "dencoder 5: torch.Size([5, 64, 48, 48, 48])\n",
      "before final conv1 torch.Size([5, 64, 48, 48, 48])\n",
      "before final conv2 torch.Size([5, 32, 48, 48, 48])\n",
      "before final conv3 torch.Size([5, 16, 48, 48, 48])\n",
      "before final conv4 torch.Size([5, 4, 48, 48, 48])\n",
      "[misclassification_rate - validation] 4543.0\n",
      "Adding in dict for wandb: 'validation_misclassification_rate': 4543.0\n",
      "\n",
      "Val loss: 0.1001327708363533,  val batches: 1\n",
      "Logging to wandb: {'train_misclassification_rate': 36539.0, 'validation_misclassification_rate': 4543.0, 'train_loss': 0.04722500592470169, 'val_loss': 0.04722500592470169, 'lr': 0.006}\n",
      "\n",
      "\n",
      "   Epoch 18/1224, Loss: 0.04722500592470169, lr: 0.006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                     | 0/1 [00:00<?, ?minibatches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 6, 256, 256])\n",
      "encoder 1: torch.Size([25, 16, 128, 128])\n",
      "encoder 2: torch.Size([25, 32, 64, 64])\n",
      "encoder 3: torch.Size([25, 64, 32, 32])\n",
      "encoder 4: torch.Size([25, 128, 16, 16])\n",
      "encoder 5: torch.Size([25, 256, 8, 8])\n",
      "encoder 6: torch.Size([25, 512, 4, 4])\n",
      "encoder 7: torch.Size([25, 1024, 2, 2])\n",
      "encoder 8: torch.Size([25, 2048, 1, 1])\n",
      "LATENTS HERE\n",
      "torch.Size([25, 2048, 1, 1, 1])\n",
      "res conn shape: torch.Size([25, 2048, 1, 1])\n",
      "inflated conn shape: torch.Size([25, 2048, 1, 1, 1])\n",
      "dencoder 1: torch.Size([25, 1024, 2, 2, 2])\n",
      "res conn shape: torch.Size([25, 1024, 2, 2])\n",
      "inflated conn shape: torch.Size([25, 1024, 2, 2, 2])\n",
      "dencoder 2: torch.Size([25, 512, 4, 4, 4])\n",
      "res conn shape: torch.Size([25, 512, 4, 4])\n",
      "inflated conn shape: torch.Size([25, 512, 4, 4, 4])\n",
      "dencoder 3: torch.Size([25, 256, 8, 8, 8])\n",
      "res conn shape: torch.Size([25, 256, 8, 8])\n",
      "inflated conn shape: torch.Size([25, 256, 8, 8, 8])\n",
      "dencoder 4: torch.Size([25, 128, 16, 16, 16])\n",
      "res conn shape: torch.Size([25, 128, 16, 16])\n",
      "inflated conn shape: torch.Size([25, 128, 16, 16, 16])\n",
      "dencoder 5: torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv1 torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv2 torch.Size([25, 32, 48, 48, 48])\n",
      "before final conv3 torch.Size([25, 16, 48, 48, 48])\n",
      "before final conv4 torch.Size([25, 4, 48, 48, 48])\n",
      "tensor(0.0471, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|█████████████████████████████| 1/1 [00:43<00:00, 43.05s/minibatches]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[misclassification_rate - train] 37441.0\n",
      "Adding in dict for wandb: 'train_misclassification_rate': 37441.0\n",
      "torch.Size([5, 6, 256, 256])\n",
      "encoder 1: torch.Size([5, 16, 128, 128])\n",
      "encoder 2: torch.Size([5, 32, 64, 64])\n",
      "encoder 3: torch.Size([5, 64, 32, 32])\n",
      "encoder 4: torch.Size([5, 128, 16, 16])\n",
      "encoder 5: torch.Size([5, 256, 8, 8])\n",
      "encoder 6: torch.Size([5, 512, 4, 4])\n",
      "encoder 7: torch.Size([5, 1024, 2, 2])\n",
      "encoder 8: torch.Size([5, 2048, 1, 1])\n",
      "LATENTS HERE\n",
      "torch.Size([5, 2048, 1, 1, 1])\n",
      "res conn shape: torch.Size([5, 2048, 1, 1])\n",
      "inflated conn shape: torch.Size([5, 2048, 1, 1, 1])\n",
      "dencoder 1: torch.Size([5, 1024, 2, 2, 2])\n",
      "res conn shape: torch.Size([5, 1024, 2, 2])\n",
      "inflated conn shape: torch.Size([5, 1024, 2, 2, 2])\n",
      "dencoder 2: torch.Size([5, 512, 4, 4, 4])\n",
      "res conn shape: torch.Size([5, 512, 4, 4])\n",
      "inflated conn shape: torch.Size([5, 512, 4, 4, 4])\n",
      "dencoder 3: torch.Size([5, 256, 8, 8, 8])\n",
      "res conn shape: torch.Size([5, 256, 8, 8])\n",
      "inflated conn shape: torch.Size([5, 256, 8, 8, 8])\n",
      "dencoder 4: torch.Size([5, 128, 16, 16, 16])\n",
      "res conn shape: torch.Size([5, 128, 16, 16])\n",
      "inflated conn shape: torch.Size([5, 128, 16, 16, 16])\n",
      "dencoder 5: torch.Size([5, 64, 48, 48, 48])\n",
      "before final conv1 torch.Size([5, 64, 48, 48, 48])\n",
      "before final conv2 torch.Size([5, 32, 48, 48, 48])\n",
      "before final conv3 torch.Size([5, 16, 48, 48, 48])\n",
      "before final conv4 torch.Size([5, 4, 48, 48, 48])\n",
      "[misclassification_rate - validation] 4607.0\n",
      "Adding in dict for wandb: 'validation_misclassification_rate': 4607.0\n",
      "\n",
      "Val loss: 0.09076765179634094,  val batches: 1\n",
      "Logging to wandb: {'train_misclassification_rate': 37441.0, 'validation_misclassification_rate': 4607.0, 'train_loss': 0.04708082973957062, 'val_loss': 0.04708082973957062, 'lr': 0.006}\n",
      "\n",
      "\n",
      "   Epoch 19/1224, Loss: 0.04708082973957062, lr: 0.006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                     | 0/1 [00:00<?, ?minibatches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 6, 256, 256])\n",
      "encoder 1: torch.Size([25, 16, 128, 128])\n",
      "encoder 2: torch.Size([25, 32, 64, 64])\n",
      "encoder 3: torch.Size([25, 64, 32, 32])\n",
      "encoder 4: torch.Size([25, 128, 16, 16])\n",
      "encoder 5: torch.Size([25, 256, 8, 8])\n",
      "encoder 6: torch.Size([25, 512, 4, 4])\n",
      "encoder 7: torch.Size([25, 1024, 2, 2])\n",
      "encoder 8: torch.Size([25, 2048, 1, 1])\n",
      "LATENTS HERE\n",
      "torch.Size([25, 2048, 1, 1, 1])\n",
      "res conn shape: torch.Size([25, 2048, 1, 1])\n",
      "inflated conn shape: torch.Size([25, 2048, 1, 1, 1])\n",
      "dencoder 1: torch.Size([25, 1024, 2, 2, 2])\n",
      "res conn shape: torch.Size([25, 1024, 2, 2])\n",
      "inflated conn shape: torch.Size([25, 1024, 2, 2, 2])\n",
      "dencoder 2: torch.Size([25, 512, 4, 4, 4])\n",
      "res conn shape: torch.Size([25, 512, 4, 4])\n",
      "inflated conn shape: torch.Size([25, 512, 4, 4, 4])\n",
      "dencoder 3: torch.Size([25, 256, 8, 8, 8])\n",
      "res conn shape: torch.Size([25, 256, 8, 8])\n",
      "inflated conn shape: torch.Size([25, 256, 8, 8, 8])\n",
      "dencoder 4: torch.Size([25, 128, 16, 16, 16])\n",
      "res conn shape: torch.Size([25, 128, 16, 16])\n",
      "inflated conn shape: torch.Size([25, 128, 16, 16, 16])\n",
      "dencoder 5: torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv1 torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv2 torch.Size([25, 32, 48, 48, 48])\n",
      "before final conv3 torch.Size([25, 16, 48, 48, 48])\n",
      "before final conv4 torch.Size([25, 4, 48, 48, 48])\n",
      "tensor(0.0469, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|█████████████████████████████| 1/1 [00:43<00:00, 43.21s/minibatches]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[misclassification_rate - train] 37643.0\n",
      "Adding in dict for wandb: 'train_misclassification_rate': 37643.0\n",
      "torch.Size([5, 6, 256, 256])\n",
      "encoder 1: torch.Size([5, 16, 128, 128])\n",
      "encoder 2: torch.Size([5, 32, 64, 64])\n",
      "encoder 3: torch.Size([5, 64, 32, 32])\n",
      "encoder 4: torch.Size([5, 128, 16, 16])\n",
      "encoder 5: torch.Size([5, 256, 8, 8])\n",
      "encoder 6: torch.Size([5, 512, 4, 4])\n",
      "encoder 7: torch.Size([5, 1024, 2, 2])\n",
      "encoder 8: torch.Size([5, 2048, 1, 1])\n",
      "LATENTS HERE\n",
      "torch.Size([5, 2048, 1, 1, 1])\n",
      "res conn shape: torch.Size([5, 2048, 1, 1])\n",
      "inflated conn shape: torch.Size([5, 2048, 1, 1, 1])\n",
      "dencoder 1: torch.Size([5, 1024, 2, 2, 2])\n",
      "res conn shape: torch.Size([5, 1024, 2, 2])\n",
      "inflated conn shape: torch.Size([5, 1024, 2, 2, 2])\n",
      "dencoder 2: torch.Size([5, 512, 4, 4, 4])\n",
      "res conn shape: torch.Size([5, 512, 4, 4])\n",
      "inflated conn shape: torch.Size([5, 512, 4, 4, 4])\n",
      "dencoder 3: torch.Size([5, 256, 8, 8, 8])\n",
      "res conn shape: torch.Size([5, 256, 8, 8])\n",
      "inflated conn shape: torch.Size([5, 256, 8, 8, 8])\n",
      "dencoder 4: torch.Size([5, 128, 16, 16, 16])\n",
      "res conn shape: torch.Size([5, 128, 16, 16])\n",
      "inflated conn shape: torch.Size([5, 128, 16, 16, 16])\n",
      "dencoder 5: torch.Size([5, 64, 48, 48, 48])\n",
      "before final conv1 torch.Size([5, 64, 48, 48, 48])\n",
      "before final conv2 torch.Size([5, 32, 48, 48, 48])\n",
      "before final conv3 torch.Size([5, 16, 48, 48, 48])\n",
      "before final conv4 torch.Size([5, 4, 48, 48, 48])\n",
      "[misclassification_rate - validation] 4725.0\n",
      "Adding in dict for wandb: 'validation_misclassification_rate': 4725.0\n",
      "\n",
      "Val loss: 0.08633457869291306,  val batches: 1\n",
      "Logging to wandb: {'train_misclassification_rate': 37643.0, 'validation_misclassification_rate': 4725.0, 'train_loss': 0.04690033569931984, 'val_loss': 0.04690033569931984, 'lr': 0.006}\n",
      "\n",
      "\n",
      "   Epoch 20/1224, Loss: 0.04690033569931984, lr: 0.006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                     | 0/1 [00:00<?, ?minibatches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 6, 256, 256])\n",
      "encoder 1: torch.Size([25, 16, 128, 128])\n",
      "encoder 2: torch.Size([25, 32, 64, 64])\n",
      "encoder 3: torch.Size([25, 64, 32, 32])\n",
      "encoder 4: torch.Size([25, 128, 16, 16])\n",
      "encoder 5: torch.Size([25, 256, 8, 8])\n",
      "encoder 6: torch.Size([25, 512, 4, 4])\n",
      "encoder 7: torch.Size([25, 1024, 2, 2])\n",
      "encoder 8: torch.Size([25, 2048, 1, 1])\n",
      "LATENTS HERE\n",
      "torch.Size([25, 2048, 1, 1, 1])\n",
      "res conn shape: torch.Size([25, 2048, 1, 1])\n",
      "inflated conn shape: torch.Size([25, 2048, 1, 1, 1])\n",
      "dencoder 1: torch.Size([25, 1024, 2, 2, 2])\n",
      "res conn shape: torch.Size([25, 1024, 2, 2])\n",
      "inflated conn shape: torch.Size([25, 1024, 2, 2, 2])\n",
      "dencoder 2: torch.Size([25, 512, 4, 4, 4])\n",
      "res conn shape: torch.Size([25, 512, 4, 4])\n",
      "inflated conn shape: torch.Size([25, 512, 4, 4, 4])\n",
      "dencoder 3: torch.Size([25, 256, 8, 8, 8])\n",
      "res conn shape: torch.Size([25, 256, 8, 8])\n",
      "inflated conn shape: torch.Size([25, 256, 8, 8, 8])\n",
      "dencoder 4: torch.Size([25, 128, 16, 16, 16])\n",
      "res conn shape: torch.Size([25, 128, 16, 16])\n",
      "inflated conn shape: torch.Size([25, 128, 16, 16, 16])\n",
      "dencoder 5: torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv1 torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv2 torch.Size([25, 32, 48, 48, 48])\n",
      "before final conv3 torch.Size([25, 16, 48, 48, 48])\n",
      "before final conv4 torch.Size([25, 4, 48, 48, 48])\n",
      "tensor(0.0458, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|█████████████████████████████| 1/1 [00:43<00:00, 43.30s/minibatches]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[misclassification_rate - train] 51159.0\n",
      "Adding in dict for wandb: 'train_misclassification_rate': 51159.0\n",
      "torch.Size([5, 6, 256, 256])\n",
      "encoder 1: torch.Size([5, 16, 128, 128])\n",
      "encoder 2: torch.Size([5, 32, 64, 64])\n",
      "encoder 3: torch.Size([5, 64, 32, 32])\n",
      "encoder 4: torch.Size([5, 128, 16, 16])\n",
      "encoder 5: torch.Size([5, 256, 8, 8])\n",
      "encoder 6: torch.Size([5, 512, 4, 4])\n",
      "encoder 7: torch.Size([5, 1024, 2, 2])\n",
      "encoder 8: torch.Size([5, 2048, 1, 1])\n",
      "LATENTS HERE\n",
      "torch.Size([5, 2048, 1, 1, 1])\n",
      "res conn shape: torch.Size([5, 2048, 1, 1])\n",
      "inflated conn shape: torch.Size([5, 2048, 1, 1, 1])\n",
      "dencoder 1: torch.Size([5, 1024, 2, 2, 2])\n",
      "res conn shape: torch.Size([5, 1024, 2, 2])\n",
      "inflated conn shape: torch.Size([5, 1024, 2, 2, 2])\n",
      "dencoder 2: torch.Size([5, 512, 4, 4, 4])\n",
      "res conn shape: torch.Size([5, 512, 4, 4])\n",
      "inflated conn shape: torch.Size([5, 512, 4, 4, 4])\n",
      "dencoder 3: torch.Size([5, 256, 8, 8, 8])\n",
      "res conn shape: torch.Size([5, 256, 8, 8])\n",
      "inflated conn shape: torch.Size([5, 256, 8, 8, 8])\n",
      "dencoder 4: torch.Size([5, 128, 16, 16, 16])\n",
      "res conn shape: torch.Size([5, 128, 16, 16])\n",
      "inflated conn shape: torch.Size([5, 128, 16, 16, 16])\n",
      "dencoder 5: torch.Size([5, 64, 48, 48, 48])\n",
      "before final conv1 torch.Size([5, 64, 48, 48, 48])\n",
      "before final conv2 torch.Size([5, 32, 48, 48, 48])\n",
      "before final conv3 torch.Size([5, 16, 48, 48, 48])\n",
      "before final conv4 torch.Size([5, 4, 48, 48, 48])\n",
      "[misclassification_rate - validation] 5850.0\n",
      "Adding in dict for wandb: 'validation_misclassification_rate': 5850.0\n",
      "\n",
      "Val loss: 0.08355690538883209,  val batches: 1\n",
      "Logging to wandb: {'train_misclassification_rate': 51159.0, 'validation_misclassification_rate': 5850.0, 'train_loss': 0.04575878009200096, 'val_loss': 0.04575878009200096, 'lr': 0.006}\n",
      "\n",
      "\n",
      "   Epoch 21/1224, Loss: 0.04575878009200096, lr: 0.006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                     | 0/1 [00:00<?, ?minibatches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 6, 256, 256])\n",
      "encoder 1: torch.Size([25, 16, 128, 128])\n",
      "encoder 2: torch.Size([25, 32, 64, 64])\n",
      "encoder 3: torch.Size([25, 64, 32, 32])\n",
      "encoder 4: torch.Size([25, 128, 16, 16])\n",
      "encoder 5: torch.Size([25, 256, 8, 8])\n",
      "encoder 6: torch.Size([25, 512, 4, 4])\n",
      "encoder 7: torch.Size([25, 1024, 2, 2])\n",
      "encoder 8: torch.Size([25, 2048, 1, 1])\n",
      "LATENTS HERE\n",
      "torch.Size([25, 2048, 1, 1, 1])\n",
      "res conn shape: torch.Size([25, 2048, 1, 1])\n",
      "inflated conn shape: torch.Size([25, 2048, 1, 1, 1])\n",
      "dencoder 1: torch.Size([25, 1024, 2, 2, 2])\n",
      "res conn shape: torch.Size([25, 1024, 2, 2])\n",
      "inflated conn shape: torch.Size([25, 1024, 2, 2, 2])\n",
      "dencoder 2: torch.Size([25, 512, 4, 4, 4])\n",
      "res conn shape: torch.Size([25, 512, 4, 4])\n",
      "inflated conn shape: torch.Size([25, 512, 4, 4, 4])\n",
      "dencoder 3: torch.Size([25, 256, 8, 8, 8])\n",
      "res conn shape: torch.Size([25, 256, 8, 8])\n",
      "inflated conn shape: torch.Size([25, 256, 8, 8, 8])\n",
      "dencoder 4: torch.Size([25, 128, 16, 16, 16])\n",
      "res conn shape: torch.Size([25, 128, 16, 16])\n",
      "inflated conn shape: torch.Size([25, 128, 16, 16, 16])\n",
      "dencoder 5: torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv1 torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv2 torch.Size([25, 32, 48, 48, 48])\n",
      "before final conv3 torch.Size([25, 16, 48, 48, 48])\n",
      "before final conv4 torch.Size([25, 4, 48, 48, 48])\n",
      "tensor(0.0467, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|█████████████████████████████| 1/1 [00:43<00:00, 43.06s/minibatches]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[misclassification_rate - train] 50355.0\n",
      "Adding in dict for wandb: 'train_misclassification_rate': 50355.0\n",
      "torch.Size([5, 6, 256, 256])\n",
      "encoder 1: torch.Size([5, 16, 128, 128])\n",
      "encoder 2: torch.Size([5, 32, 64, 64])\n",
      "encoder 3: torch.Size([5, 64, 32, 32])\n",
      "encoder 4: torch.Size([5, 128, 16, 16])\n",
      "encoder 5: torch.Size([5, 256, 8, 8])\n",
      "encoder 6: torch.Size([5, 512, 4, 4])\n",
      "encoder 7: torch.Size([5, 1024, 2, 2])\n",
      "encoder 8: torch.Size([5, 2048, 1, 1])\n",
      "LATENTS HERE\n",
      "torch.Size([5, 2048, 1, 1, 1])\n",
      "res conn shape: torch.Size([5, 2048, 1, 1])\n",
      "inflated conn shape: torch.Size([5, 2048, 1, 1, 1])\n",
      "dencoder 1: torch.Size([5, 1024, 2, 2, 2])\n",
      "res conn shape: torch.Size([5, 1024, 2, 2])\n",
      "inflated conn shape: torch.Size([5, 1024, 2, 2, 2])\n",
      "dencoder 2: torch.Size([5, 512, 4, 4, 4])\n",
      "res conn shape: torch.Size([5, 512, 4, 4])\n",
      "inflated conn shape: torch.Size([5, 512, 4, 4, 4])\n",
      "dencoder 3: torch.Size([5, 256, 8, 8, 8])\n",
      "res conn shape: torch.Size([5, 256, 8, 8])\n",
      "inflated conn shape: torch.Size([5, 256, 8, 8, 8])\n",
      "dencoder 4: torch.Size([5, 128, 16, 16, 16])\n",
      "res conn shape: torch.Size([5, 128, 16, 16])\n",
      "inflated conn shape: torch.Size([5, 128, 16, 16, 16])\n",
      "dencoder 5: torch.Size([5, 64, 48, 48, 48])\n",
      "before final conv1 torch.Size([5, 64, 48, 48, 48])\n",
      "before final conv2 torch.Size([5, 32, 48, 48, 48])\n",
      "before final conv3 torch.Size([5, 16, 48, 48, 48])\n",
      "before final conv4 torch.Size([5, 4, 48, 48, 48])\n",
      "[misclassification_rate - validation] 5368.0\n",
      "Adding in dict for wandb: 'validation_misclassification_rate': 5368.0\n",
      "\n",
      "Val loss: 0.0786297470331192,  val batches: 1\n",
      "Logging to wandb: {'train_misclassification_rate': 50355.0, 'validation_misclassification_rate': 5368.0, 'train_loss': 0.046747930347919464, 'val_loss': 0.046747930347919464, 'lr': 0.006}\n",
      "\n",
      "\n",
      "   Epoch 22/1224, Loss: 0.046747930347919464, lr: 0.006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                     | 0/1 [00:00<?, ?minibatches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 6, 256, 256])\n",
      "encoder 1: torch.Size([25, 16, 128, 128])\n",
      "encoder 2: torch.Size([25, 32, 64, 64])\n",
      "encoder 3: torch.Size([25, 64, 32, 32])\n",
      "encoder 4: torch.Size([25, 128, 16, 16])\n",
      "encoder 5: torch.Size([25, 256, 8, 8])\n",
      "encoder 6: torch.Size([25, 512, 4, 4])\n",
      "encoder 7: torch.Size([25, 1024, 2, 2])\n",
      "encoder 8: torch.Size([25, 2048, 1, 1])\n",
      "LATENTS HERE\n",
      "torch.Size([25, 2048, 1, 1, 1])\n",
      "res conn shape: torch.Size([25, 2048, 1, 1])\n",
      "inflated conn shape: torch.Size([25, 2048, 1, 1, 1])\n",
      "dencoder 1: torch.Size([25, 1024, 2, 2, 2])\n",
      "res conn shape: torch.Size([25, 1024, 2, 2])\n",
      "inflated conn shape: torch.Size([25, 1024, 2, 2, 2])\n",
      "dencoder 2: torch.Size([25, 512, 4, 4, 4])\n",
      "res conn shape: torch.Size([25, 512, 4, 4])\n",
      "inflated conn shape: torch.Size([25, 512, 4, 4, 4])\n",
      "dencoder 3: torch.Size([25, 256, 8, 8, 8])\n",
      "res conn shape: torch.Size([25, 256, 8, 8])\n",
      "inflated conn shape: torch.Size([25, 256, 8, 8, 8])\n",
      "dencoder 4: torch.Size([25, 128, 16, 16, 16])\n",
      "res conn shape: torch.Size([25, 128, 16, 16])\n",
      "inflated conn shape: torch.Size([25, 128, 16, 16, 16])\n",
      "dencoder 5: torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv1 torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv2 torch.Size([25, 32, 48, 48, 48])\n",
      "before final conv3 torch.Size([25, 16, 48, 48, 48])\n",
      "before final conv4 torch.Size([25, 4, 48, 48, 48])\n",
      "tensor(0.0466, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|█████████████████████████████| 1/1 [00:43<00:00, 43.10s/minibatches]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[misclassification_rate - train] 102553.0\n",
      "Adding in dict for wandb: 'train_misclassification_rate': 102553.0\n",
      "torch.Size([5, 6, 256, 256])\n",
      "encoder 1: torch.Size([5, 16, 128, 128])\n",
      "encoder 2: torch.Size([5, 32, 64, 64])\n",
      "encoder 3: torch.Size([5, 64, 32, 32])\n",
      "encoder 4: torch.Size([5, 128, 16, 16])\n",
      "encoder 5: torch.Size([5, 256, 8, 8])\n",
      "encoder 6: torch.Size([5, 512, 4, 4])\n",
      "encoder 7: torch.Size([5, 1024, 2, 2])\n",
      "encoder 8: torch.Size([5, 2048, 1, 1])\n",
      "LATENTS HERE\n",
      "torch.Size([5, 2048, 1, 1, 1])\n",
      "res conn shape: torch.Size([5, 2048, 1, 1])\n",
      "inflated conn shape: torch.Size([5, 2048, 1, 1, 1])\n",
      "dencoder 1: torch.Size([5, 1024, 2, 2, 2])\n",
      "res conn shape: torch.Size([5, 1024, 2, 2])\n",
      "inflated conn shape: torch.Size([5, 1024, 2, 2, 2])\n",
      "dencoder 2: torch.Size([5, 512, 4, 4, 4])\n",
      "res conn shape: torch.Size([5, 512, 4, 4])\n",
      "inflated conn shape: torch.Size([5, 512, 4, 4, 4])\n",
      "dencoder 3: torch.Size([5, 256, 8, 8, 8])\n",
      "res conn shape: torch.Size([5, 256, 8, 8])\n",
      "inflated conn shape: torch.Size([5, 256, 8, 8, 8])\n",
      "dencoder 4: torch.Size([5, 128, 16, 16, 16])\n",
      "res conn shape: torch.Size([5, 128, 16, 16])\n",
      "inflated conn shape: torch.Size([5, 128, 16, 16, 16])\n",
      "dencoder 5: torch.Size([5, 64, 48, 48, 48])\n",
      "before final conv1 torch.Size([5, 64, 48, 48, 48])\n",
      "before final conv2 torch.Size([5, 32, 48, 48, 48])\n",
      "before final conv3 torch.Size([5, 16, 48, 48, 48])\n",
      "before final conv4 torch.Size([5, 4, 48, 48, 48])\n",
      "[misclassification_rate - validation] 5706.0\n",
      "Adding in dict for wandb: 'validation_misclassification_rate': 5706.0\n",
      "\n",
      "Val loss: 0.07634139060974121,  val batches: 1\n",
      "Logging to wandb: {'train_misclassification_rate': 102553.0, 'validation_misclassification_rate': 5706.0, 'train_loss': 0.04659189283847809, 'val_loss': 0.04659189283847809, 'lr': 0.006}\n",
      "\n",
      "\n",
      "   Epoch 23/1224, Loss: 0.04659189283847809, lr: 0.006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                     | 0/1 [00:00<?, ?minibatches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 6, 256, 256])\n",
      "encoder 1: torch.Size([25, 16, 128, 128])\n",
      "encoder 2: torch.Size([25, 32, 64, 64])\n",
      "encoder 3: torch.Size([25, 64, 32, 32])\n",
      "encoder 4: torch.Size([25, 128, 16, 16])\n",
      "encoder 5: torch.Size([25, 256, 8, 8])\n",
      "encoder 6: torch.Size([25, 512, 4, 4])\n",
      "encoder 7: torch.Size([25, 1024, 2, 2])\n",
      "encoder 8: torch.Size([25, 2048, 1, 1])\n",
      "LATENTS HERE\n",
      "torch.Size([25, 2048, 1, 1, 1])\n",
      "res conn shape: torch.Size([25, 2048, 1, 1])\n",
      "inflated conn shape: torch.Size([25, 2048, 1, 1, 1])\n",
      "dencoder 1: torch.Size([25, 1024, 2, 2, 2])\n",
      "res conn shape: torch.Size([25, 1024, 2, 2])\n",
      "inflated conn shape: torch.Size([25, 1024, 2, 2, 2])\n",
      "dencoder 2: torch.Size([25, 512, 4, 4, 4])\n",
      "res conn shape: torch.Size([25, 512, 4, 4])\n",
      "inflated conn shape: torch.Size([25, 512, 4, 4, 4])\n",
      "dencoder 3: torch.Size([25, 256, 8, 8, 8])\n",
      "res conn shape: torch.Size([25, 256, 8, 8])\n",
      "inflated conn shape: torch.Size([25, 256, 8, 8, 8])\n",
      "dencoder 4: torch.Size([25, 128, 16, 16, 16])\n",
      "res conn shape: torch.Size([25, 128, 16, 16])\n",
      "inflated conn shape: torch.Size([25, 128, 16, 16, 16])\n",
      "dencoder 5: torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv1 torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv2 torch.Size([25, 32, 48, 48, 48])\n",
      "before final conv3 torch.Size([25, 16, 48, 48, 48])\n",
      "before final conv4 torch.Size([25, 4, 48, 48, 48])\n",
      "tensor(0.0448, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|█████████████████████████████| 1/1 [00:43<00:00, 43.67s/minibatches]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[misclassification_rate - train] 117356.0\n",
      "Adding in dict for wandb: 'train_misclassification_rate': 117356.0\n",
      "torch.Size([5, 6, 256, 256])\n",
      "encoder 1: torch.Size([5, 16, 128, 128])\n",
      "encoder 2: torch.Size([5, 32, 64, 64])\n",
      "encoder 3: torch.Size([5, 64, 32, 32])\n",
      "encoder 4: torch.Size([5, 128, 16, 16])\n",
      "encoder 5: torch.Size([5, 256, 8, 8])\n",
      "encoder 6: torch.Size([5, 512, 4, 4])\n",
      "encoder 7: torch.Size([5, 1024, 2, 2])\n",
      "encoder 8: torch.Size([5, 2048, 1, 1])\n",
      "LATENTS HERE\n",
      "torch.Size([5, 2048, 1, 1, 1])\n",
      "res conn shape: torch.Size([5, 2048, 1, 1])\n",
      "inflated conn shape: torch.Size([5, 2048, 1, 1, 1])\n",
      "dencoder 1: torch.Size([5, 1024, 2, 2, 2])\n",
      "res conn shape: torch.Size([5, 1024, 2, 2])\n",
      "inflated conn shape: torch.Size([5, 1024, 2, 2, 2])\n",
      "dencoder 2: torch.Size([5, 512, 4, 4, 4])\n",
      "res conn shape: torch.Size([5, 512, 4, 4])\n",
      "inflated conn shape: torch.Size([5, 512, 4, 4, 4])\n",
      "dencoder 3: torch.Size([5, 256, 8, 8, 8])\n",
      "res conn shape: torch.Size([5, 256, 8, 8])\n",
      "inflated conn shape: torch.Size([5, 256, 8, 8, 8])\n",
      "dencoder 4: torch.Size([5, 128, 16, 16, 16])\n",
      "res conn shape: torch.Size([5, 128, 16, 16])\n",
      "inflated conn shape: torch.Size([5, 128, 16, 16, 16])\n",
      "dencoder 5: torch.Size([5, 64, 48, 48, 48])\n",
      "before final conv1 torch.Size([5, 64, 48, 48, 48])\n",
      "before final conv2 torch.Size([5, 32, 48, 48, 48])\n",
      "before final conv3 torch.Size([5, 16, 48, 48, 48])\n",
      "before final conv4 torch.Size([5, 4, 48, 48, 48])\n",
      "[misclassification_rate - validation] 5804.0\n",
      "Adding in dict for wandb: 'validation_misclassification_rate': 5804.0\n",
      "\n",
      "Val loss: 0.0754268690943718,  val batches: 1\n",
      "Logging to wandb: {'train_misclassification_rate': 117356.0, 'validation_misclassification_rate': 5804.0, 'train_loss': 0.044811610132455826, 'val_loss': 0.044811610132455826, 'lr': 0.006}\n",
      "\n",
      "\n",
      "   Epoch 24/1224, Loss: 0.044811610132455826, lr: 0.006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                     | 0/1 [00:00<?, ?minibatches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 6, 256, 256])\n",
      "encoder 1: torch.Size([25, 16, 128, 128])\n",
      "encoder 2: torch.Size([25, 32, 64, 64])\n",
      "encoder 3: torch.Size([25, 64, 32, 32])\n",
      "encoder 4: torch.Size([25, 128, 16, 16])\n",
      "encoder 5: torch.Size([25, 256, 8, 8])\n",
      "encoder 6: torch.Size([25, 512, 4, 4])\n",
      "encoder 7: torch.Size([25, 1024, 2, 2])\n",
      "encoder 8: torch.Size([25, 2048, 1, 1])\n",
      "LATENTS HERE\n",
      "torch.Size([25, 2048, 1, 1, 1])\n",
      "res conn shape: torch.Size([25, 2048, 1, 1])\n",
      "inflated conn shape: torch.Size([25, 2048, 1, 1, 1])\n",
      "dencoder 1: torch.Size([25, 1024, 2, 2, 2])\n",
      "res conn shape: torch.Size([25, 1024, 2, 2])\n",
      "inflated conn shape: torch.Size([25, 1024, 2, 2, 2])\n",
      "dencoder 2: torch.Size([25, 512, 4, 4, 4])\n",
      "res conn shape: torch.Size([25, 512, 4, 4])\n",
      "inflated conn shape: torch.Size([25, 512, 4, 4, 4])\n",
      "dencoder 3: torch.Size([25, 256, 8, 8, 8])\n",
      "res conn shape: torch.Size([25, 256, 8, 8])\n",
      "inflated conn shape: torch.Size([25, 256, 8, 8, 8])\n",
      "dencoder 4: torch.Size([25, 128, 16, 16, 16])\n",
      "res conn shape: torch.Size([25, 128, 16, 16])\n",
      "inflated conn shape: torch.Size([25, 128, 16, 16, 16])\n",
      "dencoder 5: torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv1 torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv2 torch.Size([25, 32, 48, 48, 48])\n",
      "before final conv3 torch.Size([25, 16, 48, 48, 48])\n",
      "before final conv4 torch.Size([25, 4, 48, 48, 48])\n",
      "tensor(0.0398, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|█████████████████████████████| 1/1 [00:43<00:00, 43.34s/minibatches]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[misclassification_rate - train] 88765.0\n",
      "Adding in dict for wandb: 'train_misclassification_rate': 88765.0\n",
      "torch.Size([5, 6, 256, 256])\n",
      "encoder 1: torch.Size([5, 16, 128, 128])\n",
      "encoder 2: torch.Size([5, 32, 64, 64])\n",
      "encoder 3: torch.Size([5, 64, 32, 32])\n",
      "encoder 4: torch.Size([5, 128, 16, 16])\n",
      "encoder 5: torch.Size([5, 256, 8, 8])\n",
      "encoder 6: torch.Size([5, 512, 4, 4])\n",
      "encoder 7: torch.Size([5, 1024, 2, 2])\n",
      "encoder 8: torch.Size([5, 2048, 1, 1])\n",
      "LATENTS HERE\n",
      "torch.Size([5, 2048, 1, 1, 1])\n",
      "res conn shape: torch.Size([5, 2048, 1, 1])\n",
      "inflated conn shape: torch.Size([5, 2048, 1, 1, 1])\n",
      "dencoder 1: torch.Size([5, 1024, 2, 2, 2])\n",
      "res conn shape: torch.Size([5, 1024, 2, 2])\n",
      "inflated conn shape: torch.Size([5, 1024, 2, 2, 2])\n",
      "dencoder 2: torch.Size([5, 512, 4, 4, 4])\n",
      "res conn shape: torch.Size([5, 512, 4, 4])\n",
      "inflated conn shape: torch.Size([5, 512, 4, 4, 4])\n",
      "dencoder 3: torch.Size([5, 256, 8, 8, 8])\n",
      "res conn shape: torch.Size([5, 256, 8, 8])\n",
      "inflated conn shape: torch.Size([5, 256, 8, 8, 8])\n",
      "dencoder 4: torch.Size([5, 128, 16, 16, 16])\n",
      "res conn shape: torch.Size([5, 128, 16, 16])\n",
      "inflated conn shape: torch.Size([5, 128, 16, 16, 16])\n",
      "dencoder 5: torch.Size([5, 64, 48, 48, 48])\n",
      "before final conv1 torch.Size([5, 64, 48, 48, 48])\n",
      "before final conv2 torch.Size([5, 32, 48, 48, 48])\n",
      "before final conv3 torch.Size([5, 16, 48, 48, 48])\n",
      "before final conv4 torch.Size([5, 4, 48, 48, 48])\n",
      "[misclassification_rate - validation] 5418.0\n",
      "Adding in dict for wandb: 'validation_misclassification_rate': 5418.0\n",
      "\n",
      "Val loss: 0.10025943070650101,  val batches: 1\n",
      "Logging to wandb: {'train_misclassification_rate': 88765.0, 'validation_misclassification_rate': 5418.0, 'train_loss': 0.03984636068344116, 'val_loss': 0.03984636068344116, 'lr': 0.006}\n",
      "\n",
      "\n",
      "   Epoch 25/1224, Loss: 0.03984636068344116, lr: 0.006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                     | 0/1 [00:00<?, ?minibatches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 6, 256, 256])\n",
      "encoder 1: torch.Size([25, 16, 128, 128])\n",
      "encoder 2: torch.Size([25, 32, 64, 64])\n",
      "encoder 3: torch.Size([25, 64, 32, 32])\n",
      "encoder 4: torch.Size([25, 128, 16, 16])\n",
      "encoder 5: torch.Size([25, 256, 8, 8])\n",
      "encoder 6: torch.Size([25, 512, 4, 4])\n",
      "encoder 7: torch.Size([25, 1024, 2, 2])\n",
      "encoder 8: torch.Size([25, 2048, 1, 1])\n",
      "LATENTS HERE\n",
      "torch.Size([25, 2048, 1, 1, 1])\n",
      "res conn shape: torch.Size([25, 2048, 1, 1])\n",
      "inflated conn shape: torch.Size([25, 2048, 1, 1, 1])\n",
      "dencoder 1: torch.Size([25, 1024, 2, 2, 2])\n",
      "res conn shape: torch.Size([25, 1024, 2, 2])\n",
      "inflated conn shape: torch.Size([25, 1024, 2, 2, 2])\n",
      "dencoder 2: torch.Size([25, 512, 4, 4, 4])\n",
      "res conn shape: torch.Size([25, 512, 4, 4])\n",
      "inflated conn shape: torch.Size([25, 512, 4, 4, 4])\n",
      "dencoder 3: torch.Size([25, 256, 8, 8, 8])\n",
      "res conn shape: torch.Size([25, 256, 8, 8])\n",
      "inflated conn shape: torch.Size([25, 256, 8, 8, 8])\n",
      "dencoder 4: torch.Size([25, 128, 16, 16, 16])\n",
      "res conn shape: torch.Size([25, 128, 16, 16])\n",
      "inflated conn shape: torch.Size([25, 128, 16, 16, 16])\n",
      "dencoder 5: torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv1 torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv2 torch.Size([25, 32, 48, 48, 48])\n",
      "before final conv3 torch.Size([25, 16, 48, 48, 48])\n",
      "before final conv4 torch.Size([25, 4, 48, 48, 48])\n",
      "tensor(0.0411, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|█████████████████████████████| 1/1 [00:43<00:00, 43.27s/minibatches]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[misclassification_rate - train] 35941.0\n",
      "Adding in dict for wandb: 'train_misclassification_rate': 35941.0\n",
      "torch.Size([5, 6, 256, 256])\n",
      "encoder 1: torch.Size([5, 16, 128, 128])\n",
      "encoder 2: torch.Size([5, 32, 64, 64])\n",
      "encoder 3: torch.Size([5, 64, 32, 32])\n",
      "encoder 4: torch.Size([5, 128, 16, 16])\n",
      "encoder 5: torch.Size([5, 256, 8, 8])\n",
      "encoder 6: torch.Size([5, 512, 4, 4])\n",
      "encoder 7: torch.Size([5, 1024, 2, 2])\n",
      "encoder 8: torch.Size([5, 2048, 1, 1])\n",
      "LATENTS HERE\n",
      "torch.Size([5, 2048, 1, 1, 1])\n",
      "res conn shape: torch.Size([5, 2048, 1, 1])\n",
      "inflated conn shape: torch.Size([5, 2048, 1, 1, 1])\n",
      "dencoder 1: torch.Size([5, 1024, 2, 2, 2])\n",
      "res conn shape: torch.Size([5, 1024, 2, 2])\n",
      "inflated conn shape: torch.Size([5, 1024, 2, 2, 2])\n",
      "dencoder 2: torch.Size([5, 512, 4, 4, 4])\n",
      "res conn shape: torch.Size([5, 512, 4, 4])\n",
      "inflated conn shape: torch.Size([5, 512, 4, 4, 4])\n",
      "dencoder 3: torch.Size([5, 256, 8, 8, 8])\n",
      "res conn shape: torch.Size([5, 256, 8, 8])\n",
      "inflated conn shape: torch.Size([5, 256, 8, 8, 8])\n",
      "dencoder 4: torch.Size([5, 128, 16, 16, 16])\n",
      "res conn shape: torch.Size([5, 128, 16, 16])\n",
      "inflated conn shape: torch.Size([5, 128, 16, 16, 16])\n",
      "dencoder 5: torch.Size([5, 64, 48, 48, 48])\n",
      "before final conv1 torch.Size([5, 64, 48, 48, 48])\n",
      "before final conv2 torch.Size([5, 32, 48, 48, 48])\n",
      "before final conv3 torch.Size([5, 16, 48, 48, 48])\n",
      "before final conv4 torch.Size([5, 4, 48, 48, 48])\n",
      "[misclassification_rate - validation] 6651.0\n",
      "Adding in dict for wandb: 'validation_misclassification_rate': 6651.0\n",
      "\n",
      "Val loss: 0.06631400436162949,  val batches: 1\n",
      "Logging to wandb: {'train_misclassification_rate': 35941.0, 'validation_misclassification_rate': 6651.0, 'train_loss': 0.04107680171728134, 'val_loss': 0.04107680171728134, 'lr': 0.006}\n",
      "\n",
      "\n",
      "   Epoch 26/1224, Loss: 0.04107680171728134, lr: 0.006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                     | 0/1 [00:00<?, ?minibatches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 6, 256, 256])\n",
      "encoder 1: torch.Size([25, 16, 128, 128])\n",
      "encoder 2: torch.Size([25, 32, 64, 64])\n",
      "encoder 3: torch.Size([25, 64, 32, 32])\n",
      "encoder 4: torch.Size([25, 128, 16, 16])\n",
      "encoder 5: torch.Size([25, 256, 8, 8])\n",
      "encoder 6: torch.Size([25, 512, 4, 4])\n",
      "encoder 7: torch.Size([25, 1024, 2, 2])\n",
      "encoder 8: torch.Size([25, 2048, 1, 1])\n",
      "LATENTS HERE\n",
      "torch.Size([25, 2048, 1, 1, 1])\n",
      "res conn shape: torch.Size([25, 2048, 1, 1])\n",
      "inflated conn shape: torch.Size([25, 2048, 1, 1, 1])\n",
      "dencoder 1: torch.Size([25, 1024, 2, 2, 2])\n",
      "res conn shape: torch.Size([25, 1024, 2, 2])\n",
      "inflated conn shape: torch.Size([25, 1024, 2, 2, 2])\n",
      "dencoder 2: torch.Size([25, 512, 4, 4, 4])\n",
      "res conn shape: torch.Size([25, 512, 4, 4])\n",
      "inflated conn shape: torch.Size([25, 512, 4, 4, 4])\n",
      "dencoder 3: torch.Size([25, 256, 8, 8, 8])\n",
      "res conn shape: torch.Size([25, 256, 8, 8])\n",
      "inflated conn shape: torch.Size([25, 256, 8, 8, 8])\n",
      "dencoder 4: torch.Size([25, 128, 16, 16, 16])\n",
      "res conn shape: torch.Size([25, 128, 16, 16])\n",
      "inflated conn shape: torch.Size([25, 128, 16, 16, 16])\n",
      "dencoder 5: torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv1 torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv2 torch.Size([25, 32, 48, 48, 48])\n",
      "before final conv3 torch.Size([25, 16, 48, 48, 48])\n",
      "before final conv4 torch.Size([25, 4, 48, 48, 48])\n",
      "tensor(0.0396, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|█████████████████████████████| 1/1 [00:43<00:00, 43.39s/minibatches]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[misclassification_rate - train] 95152.0\n",
      "Adding in dict for wandb: 'train_misclassification_rate': 95152.0\n",
      "torch.Size([5, 6, 256, 256])\n",
      "encoder 1: torch.Size([5, 16, 128, 128])\n",
      "encoder 2: torch.Size([5, 32, 64, 64])\n",
      "encoder 3: torch.Size([5, 64, 32, 32])\n",
      "encoder 4: torch.Size([5, 128, 16, 16])\n",
      "encoder 5: torch.Size([5, 256, 8, 8])\n",
      "encoder 6: torch.Size([5, 512, 4, 4])\n",
      "encoder 7: torch.Size([5, 1024, 2, 2])\n",
      "encoder 8: torch.Size([5, 2048, 1, 1])\n",
      "LATENTS HERE\n",
      "torch.Size([5, 2048, 1, 1, 1])\n",
      "res conn shape: torch.Size([5, 2048, 1, 1])\n",
      "inflated conn shape: torch.Size([5, 2048, 1, 1, 1])\n",
      "dencoder 1: torch.Size([5, 1024, 2, 2, 2])\n",
      "res conn shape: torch.Size([5, 1024, 2, 2])\n",
      "inflated conn shape: torch.Size([5, 1024, 2, 2, 2])\n",
      "dencoder 2: torch.Size([5, 512, 4, 4, 4])\n",
      "res conn shape: torch.Size([5, 512, 4, 4])\n",
      "inflated conn shape: torch.Size([5, 512, 4, 4, 4])\n",
      "dencoder 3: torch.Size([5, 256, 8, 8, 8])\n",
      "res conn shape: torch.Size([5, 256, 8, 8])\n",
      "inflated conn shape: torch.Size([5, 256, 8, 8, 8])\n",
      "dencoder 4: torch.Size([5, 128, 16, 16, 16])\n",
      "res conn shape: torch.Size([5, 128, 16, 16])\n",
      "inflated conn shape: torch.Size([5, 128, 16, 16, 16])\n",
      "dencoder 5: torch.Size([5, 64, 48, 48, 48])\n",
      "before final conv1 torch.Size([5, 64, 48, 48, 48])\n",
      "before final conv2 torch.Size([5, 32, 48, 48, 48])\n",
      "before final conv3 torch.Size([5, 16, 48, 48, 48])\n",
      "before final conv4 torch.Size([5, 4, 48, 48, 48])\n",
      "[misclassification_rate - validation] 7701.0\n",
      "Adding in dict for wandb: 'validation_misclassification_rate': 7701.0\n",
      "\n",
      "Val loss: 0.06012431159615517,  val batches: 1\n",
      "Logging to wandb: {'train_misclassification_rate': 95152.0, 'validation_misclassification_rate': 7701.0, 'train_loss': 0.03958672285079956, 'val_loss': 0.03958672285079956, 'lr': 0.006}\n",
      "\n",
      "\n",
      "   Epoch 27/1224, Loss: 0.03958672285079956, lr: 0.006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                     | 0/1 [00:00<?, ?minibatches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 6, 256, 256])\n",
      "encoder 1: torch.Size([25, 16, 128, 128])\n",
      "encoder 2: torch.Size([25, 32, 64, 64])\n",
      "encoder 3: torch.Size([25, 64, 32, 32])\n",
      "encoder 4: torch.Size([25, 128, 16, 16])\n",
      "encoder 5: torch.Size([25, 256, 8, 8])\n",
      "encoder 6: torch.Size([25, 512, 4, 4])\n",
      "encoder 7: torch.Size([25, 1024, 2, 2])\n",
      "encoder 8: torch.Size([25, 2048, 1, 1])\n",
      "LATENTS HERE\n",
      "torch.Size([25, 2048, 1, 1, 1])\n",
      "res conn shape: torch.Size([25, 2048, 1, 1])\n",
      "inflated conn shape: torch.Size([25, 2048, 1, 1, 1])\n",
      "dencoder 1: torch.Size([25, 1024, 2, 2, 2])\n",
      "res conn shape: torch.Size([25, 1024, 2, 2])\n",
      "inflated conn shape: torch.Size([25, 1024, 2, 2, 2])\n",
      "dencoder 2: torch.Size([25, 512, 4, 4, 4])\n",
      "res conn shape: torch.Size([25, 512, 4, 4])\n",
      "inflated conn shape: torch.Size([25, 512, 4, 4, 4])\n",
      "dencoder 3: torch.Size([25, 256, 8, 8, 8])\n",
      "res conn shape: torch.Size([25, 256, 8, 8])\n",
      "inflated conn shape: torch.Size([25, 256, 8, 8, 8])\n",
      "dencoder 4: torch.Size([25, 128, 16, 16, 16])\n",
      "res conn shape: torch.Size([25, 128, 16, 16])\n",
      "inflated conn shape: torch.Size([25, 128, 16, 16, 16])\n",
      "dencoder 5: torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv1 torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv2 torch.Size([25, 32, 48, 48, 48])\n",
      "before final conv3 torch.Size([25, 16, 48, 48, 48])\n",
      "before final conv4 torch.Size([25, 4, 48, 48, 48])\n",
      "tensor(0.0380, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|█████████████████████████████| 1/1 [00:43<00:00, 43.38s/minibatches]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[misclassification_rate - train] 102266.0\n",
      "Adding in dict for wandb: 'train_misclassification_rate': 102266.0\n",
      "torch.Size([5, 6, 256, 256])\n",
      "encoder 1: torch.Size([5, 16, 128, 128])\n",
      "encoder 2: torch.Size([5, 32, 64, 64])\n",
      "encoder 3: torch.Size([5, 64, 32, 32])\n",
      "encoder 4: torch.Size([5, 128, 16, 16])\n",
      "encoder 5: torch.Size([5, 256, 8, 8])\n",
      "encoder 6: torch.Size([5, 512, 4, 4])\n",
      "encoder 7: torch.Size([5, 1024, 2, 2])\n",
      "encoder 8: torch.Size([5, 2048, 1, 1])\n",
      "LATENTS HERE\n",
      "torch.Size([5, 2048, 1, 1, 1])\n",
      "res conn shape: torch.Size([5, 2048, 1, 1])\n",
      "inflated conn shape: torch.Size([5, 2048, 1, 1, 1])\n",
      "dencoder 1: torch.Size([5, 1024, 2, 2, 2])\n",
      "res conn shape: torch.Size([5, 1024, 2, 2])\n",
      "inflated conn shape: torch.Size([5, 1024, 2, 2, 2])\n",
      "dencoder 2: torch.Size([5, 512, 4, 4, 4])\n",
      "res conn shape: torch.Size([5, 512, 4, 4])\n",
      "inflated conn shape: torch.Size([5, 512, 4, 4, 4])\n",
      "dencoder 3: torch.Size([5, 256, 8, 8, 8])\n",
      "res conn shape: torch.Size([5, 256, 8, 8])\n",
      "inflated conn shape: torch.Size([5, 256, 8, 8, 8])\n",
      "dencoder 4: torch.Size([5, 128, 16, 16, 16])\n",
      "res conn shape: torch.Size([5, 128, 16, 16])\n",
      "inflated conn shape: torch.Size([5, 128, 16, 16, 16])\n",
      "dencoder 5: torch.Size([5, 64, 48, 48, 48])\n",
      "before final conv1 torch.Size([5, 64, 48, 48, 48])\n",
      "before final conv2 torch.Size([5, 32, 48, 48, 48])\n",
      "before final conv3 torch.Size([5, 16, 48, 48, 48])\n",
      "before final conv4 torch.Size([5, 4, 48, 48, 48])\n",
      "[misclassification_rate - validation] 5756.0\n",
      "Adding in dict for wandb: 'validation_misclassification_rate': 5756.0\n",
      "\n",
      "Val loss: 0.05844767019152641,  val batches: 1\n",
      "Logging to wandb: {'train_misclassification_rate': 102266.0, 'validation_misclassification_rate': 5756.0, 'train_loss': 0.03802657872438431, 'val_loss': 0.03802657872438431, 'lr': 0.006}\n",
      "\n",
      "\n",
      "   Epoch 28/1224, Loss: 0.03802657872438431, lr: 0.006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                     | 0/1 [00:00<?, ?minibatches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 6, 256, 256])\n",
      "encoder 1: torch.Size([25, 16, 128, 128])\n",
      "encoder 2: torch.Size([25, 32, 64, 64])\n",
      "encoder 3: torch.Size([25, 64, 32, 32])\n",
      "encoder 4: torch.Size([25, 128, 16, 16])\n",
      "encoder 5: torch.Size([25, 256, 8, 8])\n",
      "encoder 6: torch.Size([25, 512, 4, 4])\n",
      "encoder 7: torch.Size([25, 1024, 2, 2])\n",
      "encoder 8: torch.Size([25, 2048, 1, 1])\n",
      "LATENTS HERE\n",
      "torch.Size([25, 2048, 1, 1, 1])\n",
      "res conn shape: torch.Size([25, 2048, 1, 1])\n",
      "inflated conn shape: torch.Size([25, 2048, 1, 1, 1])\n",
      "dencoder 1: torch.Size([25, 1024, 2, 2, 2])\n",
      "res conn shape: torch.Size([25, 1024, 2, 2])\n",
      "inflated conn shape: torch.Size([25, 1024, 2, 2, 2])\n",
      "dencoder 2: torch.Size([25, 512, 4, 4, 4])\n",
      "res conn shape: torch.Size([25, 512, 4, 4])\n",
      "inflated conn shape: torch.Size([25, 512, 4, 4, 4])\n",
      "dencoder 3: torch.Size([25, 256, 8, 8, 8])\n",
      "res conn shape: torch.Size([25, 256, 8, 8])\n",
      "inflated conn shape: torch.Size([25, 256, 8, 8, 8])\n",
      "dencoder 4: torch.Size([25, 128, 16, 16, 16])\n",
      "res conn shape: torch.Size([25, 128, 16, 16])\n",
      "inflated conn shape: torch.Size([25, 128, 16, 16, 16])\n",
      "dencoder 5: torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv1 torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv2 torch.Size([25, 32, 48, 48, 48])\n",
      "before final conv3 torch.Size([25, 16, 48, 48, 48])\n",
      "before final conv4 torch.Size([25, 4, 48, 48, 48])\n",
      "tensor(0.0381, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|█████████████████████████████| 1/1 [00:43<00:00, 43.24s/minibatches]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[misclassification_rate - train] 65197.0\n",
      "Adding in dict for wandb: 'train_misclassification_rate': 65197.0\n",
      "torch.Size([5, 6, 256, 256])\n",
      "encoder 1: torch.Size([5, 16, 128, 128])\n",
      "encoder 2: torch.Size([5, 32, 64, 64])\n",
      "encoder 3: torch.Size([5, 64, 32, 32])\n",
      "encoder 4: torch.Size([5, 128, 16, 16])\n",
      "encoder 5: torch.Size([5, 256, 8, 8])\n",
      "encoder 6: torch.Size([5, 512, 4, 4])\n",
      "encoder 7: torch.Size([5, 1024, 2, 2])\n",
      "encoder 8: torch.Size([5, 2048, 1, 1])\n",
      "LATENTS HERE\n",
      "torch.Size([5, 2048, 1, 1, 1])\n",
      "res conn shape: torch.Size([5, 2048, 1, 1])\n",
      "inflated conn shape: torch.Size([5, 2048, 1, 1, 1])\n",
      "dencoder 1: torch.Size([5, 1024, 2, 2, 2])\n",
      "res conn shape: torch.Size([5, 1024, 2, 2])\n",
      "inflated conn shape: torch.Size([5, 1024, 2, 2, 2])\n",
      "dencoder 2: torch.Size([5, 512, 4, 4, 4])\n",
      "res conn shape: torch.Size([5, 512, 4, 4])\n",
      "inflated conn shape: torch.Size([5, 512, 4, 4, 4])\n",
      "dencoder 3: torch.Size([5, 256, 8, 8, 8])\n",
      "res conn shape: torch.Size([5, 256, 8, 8])\n",
      "inflated conn shape: torch.Size([5, 256, 8, 8, 8])\n",
      "dencoder 4: torch.Size([5, 128, 16, 16, 16])\n",
      "res conn shape: torch.Size([5, 128, 16, 16])\n",
      "inflated conn shape: torch.Size([5, 128, 16, 16, 16])\n",
      "dencoder 5: torch.Size([5, 64, 48, 48, 48])\n",
      "before final conv1 torch.Size([5, 64, 48, 48, 48])\n",
      "before final conv2 torch.Size([5, 32, 48, 48, 48])\n",
      "before final conv3 torch.Size([5, 16, 48, 48, 48])\n",
      "before final conv4 torch.Size([5, 4, 48, 48, 48])\n",
      "[misclassification_rate - validation] 8245.0\n",
      "Adding in dict for wandb: 'validation_misclassification_rate': 8245.0\n",
      "\n",
      "Val loss: 0.04584543779492378,  val batches: 1\n",
      "Logging to wandb: {'train_misclassification_rate': 65197.0, 'validation_misclassification_rate': 8245.0, 'train_loss': 0.03810575604438782, 'val_loss': 0.03810575604438782, 'lr': 0.006}\n",
      "\n",
      "\n",
      "   Epoch 29/1224, Loss: 0.03810575604438782, lr: 0.006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                     | 0/1 [00:00<?, ?minibatches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 6, 256, 256])\n",
      "encoder 1: torch.Size([25, 16, 128, 128])\n",
      "encoder 2: torch.Size([25, 32, 64, 64])\n",
      "encoder 3: torch.Size([25, 64, 32, 32])\n",
      "encoder 4: torch.Size([25, 128, 16, 16])\n",
      "encoder 5: torch.Size([25, 256, 8, 8])\n",
      "encoder 6: torch.Size([25, 512, 4, 4])\n",
      "encoder 7: torch.Size([25, 1024, 2, 2])\n",
      "encoder 8: torch.Size([25, 2048, 1, 1])\n",
      "LATENTS HERE\n",
      "torch.Size([25, 2048, 1, 1, 1])\n",
      "res conn shape: torch.Size([25, 2048, 1, 1])\n",
      "inflated conn shape: torch.Size([25, 2048, 1, 1, 1])\n",
      "dencoder 1: torch.Size([25, 1024, 2, 2, 2])\n",
      "res conn shape: torch.Size([25, 1024, 2, 2])\n",
      "inflated conn shape: torch.Size([25, 1024, 2, 2, 2])\n",
      "dencoder 2: torch.Size([25, 512, 4, 4, 4])\n",
      "res conn shape: torch.Size([25, 512, 4, 4])\n",
      "inflated conn shape: torch.Size([25, 512, 4, 4, 4])\n",
      "dencoder 3: torch.Size([25, 256, 8, 8, 8])\n",
      "res conn shape: torch.Size([25, 256, 8, 8])\n",
      "inflated conn shape: torch.Size([25, 256, 8, 8, 8])\n",
      "dencoder 4: torch.Size([25, 128, 16, 16, 16])\n",
      "res conn shape: torch.Size([25, 128, 16, 16])\n",
      "inflated conn shape: torch.Size([25, 128, 16, 16, 16])\n",
      "dencoder 5: torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv1 torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv2 torch.Size([25, 32, 48, 48, 48])\n",
      "before final conv3 torch.Size([25, 16, 48, 48, 48])\n",
      "before final conv4 torch.Size([25, 4, 48, 48, 48])\n",
      "tensor(0.0365, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|█████████████████████████████| 1/1 [00:43<00:00, 43.04s/minibatches]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[misclassification_rate - train] 81455.0\n",
      "Adding in dict for wandb: 'train_misclassification_rate': 81455.0\n",
      "torch.Size([5, 6, 256, 256])\n",
      "encoder 1: torch.Size([5, 16, 128, 128])\n",
      "encoder 2: torch.Size([5, 32, 64, 64])\n",
      "encoder 3: torch.Size([5, 64, 32, 32])\n",
      "encoder 4: torch.Size([5, 128, 16, 16])\n",
      "encoder 5: torch.Size([5, 256, 8, 8])\n",
      "encoder 6: torch.Size([5, 512, 4, 4])\n",
      "encoder 7: torch.Size([5, 1024, 2, 2])\n",
      "encoder 8: torch.Size([5, 2048, 1, 1])\n",
      "LATENTS HERE\n",
      "torch.Size([5, 2048, 1, 1, 1])\n",
      "res conn shape: torch.Size([5, 2048, 1, 1])\n",
      "inflated conn shape: torch.Size([5, 2048, 1, 1, 1])\n",
      "dencoder 1: torch.Size([5, 1024, 2, 2, 2])\n",
      "res conn shape: torch.Size([5, 1024, 2, 2])\n",
      "inflated conn shape: torch.Size([5, 1024, 2, 2, 2])\n",
      "dencoder 2: torch.Size([5, 512, 4, 4, 4])\n",
      "res conn shape: torch.Size([5, 512, 4, 4])\n",
      "inflated conn shape: torch.Size([5, 512, 4, 4, 4])\n",
      "dencoder 3: torch.Size([5, 256, 8, 8, 8])\n",
      "res conn shape: torch.Size([5, 256, 8, 8])\n",
      "inflated conn shape: torch.Size([5, 256, 8, 8, 8])\n",
      "dencoder 4: torch.Size([5, 128, 16, 16, 16])\n",
      "res conn shape: torch.Size([5, 128, 16, 16])\n",
      "inflated conn shape: torch.Size([5, 128, 16, 16, 16])\n",
      "dencoder 5: torch.Size([5, 64, 48, 48, 48])\n",
      "before final conv1 torch.Size([5, 64, 48, 48, 48])\n",
      "before final conv2 torch.Size([5, 32, 48, 48, 48])\n",
      "before final conv3 torch.Size([5, 16, 48, 48, 48])\n",
      "before final conv4 torch.Size([5, 4, 48, 48, 48])\n",
      "[misclassification_rate - validation] 9175.0\n",
      "Adding in dict for wandb: 'validation_misclassification_rate': 9175.0\n",
      "\n",
      "Val loss: 0.04730287566781044,  val batches: 1\n",
      "Logging to wandb: {'train_misclassification_rate': 81455.0, 'validation_misclassification_rate': 9175.0, 'train_loss': 0.036495644599199295, 'val_loss': 0.036495644599199295, 'lr': 0.006}\n",
      "\n",
      "\n",
      "   Epoch 30/1224, Loss: 0.036495644599199295, lr: 0.006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                     | 0/1 [00:00<?, ?minibatches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 6, 256, 256])\n",
      "encoder 1: torch.Size([25, 16, 128, 128])\n",
      "encoder 2: torch.Size([25, 32, 64, 64])\n",
      "encoder 3: torch.Size([25, 64, 32, 32])\n",
      "encoder 4: torch.Size([25, 128, 16, 16])\n",
      "encoder 5: torch.Size([25, 256, 8, 8])\n",
      "encoder 6: torch.Size([25, 512, 4, 4])\n",
      "encoder 7: torch.Size([25, 1024, 2, 2])\n",
      "encoder 8: torch.Size([25, 2048, 1, 1])\n",
      "LATENTS HERE\n",
      "torch.Size([25, 2048, 1, 1, 1])\n",
      "res conn shape: torch.Size([25, 2048, 1, 1])\n",
      "inflated conn shape: torch.Size([25, 2048, 1, 1, 1])\n",
      "dencoder 1: torch.Size([25, 1024, 2, 2, 2])\n",
      "res conn shape: torch.Size([25, 1024, 2, 2])\n",
      "inflated conn shape: torch.Size([25, 1024, 2, 2, 2])\n",
      "dencoder 2: torch.Size([25, 512, 4, 4, 4])\n",
      "res conn shape: torch.Size([25, 512, 4, 4])\n",
      "inflated conn shape: torch.Size([25, 512, 4, 4, 4])\n",
      "dencoder 3: torch.Size([25, 256, 8, 8, 8])\n",
      "res conn shape: torch.Size([25, 256, 8, 8])\n",
      "inflated conn shape: torch.Size([25, 256, 8, 8, 8])\n",
      "dencoder 4: torch.Size([25, 128, 16, 16, 16])\n",
      "res conn shape: torch.Size([25, 128, 16, 16])\n",
      "inflated conn shape: torch.Size([25, 128, 16, 16, 16])\n",
      "dencoder 5: torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv1 torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv2 torch.Size([25, 32, 48, 48, 48])\n",
      "before final conv3 torch.Size([25, 16, 48, 48, 48])\n",
      "before final conv4 torch.Size([25, 4, 48, 48, 48])\n",
      "tensor(0.0360, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|█████████████████████████████| 1/1 [00:41<00:00, 41.91s/minibatches]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[misclassification_rate - train] 49083.0\n",
      "Adding in dict for wandb: 'train_misclassification_rate': 49083.0\n",
      "torch.Size([5, 6, 256, 256])\n",
      "encoder 1: torch.Size([5, 16, 128, 128])\n",
      "encoder 2: torch.Size([5, 32, 64, 64])\n",
      "encoder 3: torch.Size([5, 64, 32, 32])\n",
      "encoder 4: torch.Size([5, 128, 16, 16])\n",
      "encoder 5: torch.Size([5, 256, 8, 8])\n",
      "encoder 6: torch.Size([5, 512, 4, 4])\n",
      "encoder 7: torch.Size([5, 1024, 2, 2])\n",
      "encoder 8: torch.Size([5, 2048, 1, 1])\n",
      "LATENTS HERE\n",
      "torch.Size([5, 2048, 1, 1, 1])\n",
      "res conn shape: torch.Size([5, 2048, 1, 1])\n",
      "inflated conn shape: torch.Size([5, 2048, 1, 1, 1])\n",
      "dencoder 1: torch.Size([5, 1024, 2, 2, 2])\n",
      "res conn shape: torch.Size([5, 1024, 2, 2])\n",
      "inflated conn shape: torch.Size([5, 1024, 2, 2, 2])\n",
      "dencoder 2: torch.Size([5, 512, 4, 4, 4])\n",
      "res conn shape: torch.Size([5, 512, 4, 4])\n",
      "inflated conn shape: torch.Size([5, 512, 4, 4, 4])\n",
      "dencoder 3: torch.Size([5, 256, 8, 8, 8])\n",
      "res conn shape: torch.Size([5, 256, 8, 8])\n",
      "inflated conn shape: torch.Size([5, 256, 8, 8, 8])\n",
      "dencoder 4: torch.Size([5, 128, 16, 16, 16])\n",
      "res conn shape: torch.Size([5, 128, 16, 16])\n",
      "inflated conn shape: torch.Size([5, 128, 16, 16, 16])\n",
      "dencoder 5: torch.Size([5, 64, 48, 48, 48])\n",
      "before final conv1 torch.Size([5, 64, 48, 48, 48])\n",
      "before final conv2 torch.Size([5, 32, 48, 48, 48])\n",
      "before final conv3 torch.Size([5, 16, 48, 48, 48])\n",
      "before final conv4 torch.Size([5, 4, 48, 48, 48])\n",
      "[misclassification_rate - validation] 5980.0\n",
      "Adding in dict for wandb: 'validation_misclassification_rate': 5980.0\n",
      "\n",
      "Val loss: 0.04355190321803093,  val batches: 1\n",
      "Logging to wandb: {'train_misclassification_rate': 49083.0, 'validation_misclassification_rate': 5980.0, 'train_loss': 0.03604799509048462, 'val_loss': 0.03604799509048462, 'lr': 0.006}\n",
      "\n",
      "\n",
      "   Epoch 31/1224, Loss: 0.03604799509048462, lr: 0.006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                     | 0/1 [00:00<?, ?minibatches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 6, 256, 256])\n",
      "encoder 1: torch.Size([25, 16, 128, 128])\n",
      "encoder 2: torch.Size([25, 32, 64, 64])\n",
      "encoder 3: torch.Size([25, 64, 32, 32])\n",
      "encoder 4: torch.Size([25, 128, 16, 16])\n",
      "encoder 5: torch.Size([25, 256, 8, 8])\n",
      "encoder 6: torch.Size([25, 512, 4, 4])\n",
      "encoder 7: torch.Size([25, 1024, 2, 2])\n",
      "encoder 8: torch.Size([25, 2048, 1, 1])\n",
      "LATENTS HERE\n",
      "torch.Size([25, 2048, 1, 1, 1])\n",
      "res conn shape: torch.Size([25, 2048, 1, 1])\n",
      "inflated conn shape: torch.Size([25, 2048, 1, 1, 1])\n",
      "dencoder 1: torch.Size([25, 1024, 2, 2, 2])\n",
      "res conn shape: torch.Size([25, 1024, 2, 2])\n",
      "inflated conn shape: torch.Size([25, 1024, 2, 2, 2])\n",
      "dencoder 2: torch.Size([25, 512, 4, 4, 4])\n",
      "res conn shape: torch.Size([25, 512, 4, 4])\n",
      "inflated conn shape: torch.Size([25, 512, 4, 4, 4])\n",
      "dencoder 3: torch.Size([25, 256, 8, 8, 8])\n",
      "res conn shape: torch.Size([25, 256, 8, 8])\n",
      "inflated conn shape: torch.Size([25, 256, 8, 8, 8])\n",
      "dencoder 4: torch.Size([25, 128, 16, 16, 16])\n",
      "res conn shape: torch.Size([25, 128, 16, 16])\n",
      "inflated conn shape: torch.Size([25, 128, 16, 16, 16])\n",
      "dencoder 5: torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv1 torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv2 torch.Size([25, 32, 48, 48, 48])\n",
      "before final conv3 torch.Size([25, 16, 48, 48, 48])\n",
      "before final conv4 torch.Size([25, 4, 48, 48, 48])\n",
      "tensor(0.0336, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|█████████████████████████████| 1/1 [00:41<00:00, 41.81s/minibatches]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[misclassification_rate - train] 57043.0\n",
      "Adding in dict for wandb: 'train_misclassification_rate': 57043.0\n",
      "torch.Size([5, 6, 256, 256])\n",
      "encoder 1: torch.Size([5, 16, 128, 128])\n",
      "encoder 2: torch.Size([5, 32, 64, 64])\n",
      "encoder 3: torch.Size([5, 64, 32, 32])\n",
      "encoder 4: torch.Size([5, 128, 16, 16])\n",
      "encoder 5: torch.Size([5, 256, 8, 8])\n",
      "encoder 6: torch.Size([5, 512, 4, 4])\n",
      "encoder 7: torch.Size([5, 1024, 2, 2])\n",
      "encoder 8: torch.Size([5, 2048, 1, 1])\n",
      "LATENTS HERE\n",
      "torch.Size([5, 2048, 1, 1, 1])\n",
      "res conn shape: torch.Size([5, 2048, 1, 1])\n",
      "inflated conn shape: torch.Size([5, 2048, 1, 1, 1])\n",
      "dencoder 1: torch.Size([5, 1024, 2, 2, 2])\n",
      "res conn shape: torch.Size([5, 1024, 2, 2])\n",
      "inflated conn shape: torch.Size([5, 1024, 2, 2, 2])\n",
      "dencoder 2: torch.Size([5, 512, 4, 4, 4])\n",
      "res conn shape: torch.Size([5, 512, 4, 4])\n",
      "inflated conn shape: torch.Size([5, 512, 4, 4, 4])\n",
      "dencoder 3: torch.Size([5, 256, 8, 8, 8])\n",
      "res conn shape: torch.Size([5, 256, 8, 8])\n",
      "inflated conn shape: torch.Size([5, 256, 8, 8, 8])\n",
      "dencoder 4: torch.Size([5, 128, 16, 16, 16])\n",
      "res conn shape: torch.Size([5, 128, 16, 16])\n",
      "inflated conn shape: torch.Size([5, 128, 16, 16, 16])\n",
      "dencoder 5: torch.Size([5, 64, 48, 48, 48])\n",
      "before final conv1 torch.Size([5, 64, 48, 48, 48])\n",
      "before final conv2 torch.Size([5, 32, 48, 48, 48])\n",
      "before final conv3 torch.Size([5, 16, 48, 48, 48])\n",
      "before final conv4 torch.Size([5, 4, 48, 48, 48])\n",
      "[misclassification_rate - validation] 6156.0\n",
      "Adding in dict for wandb: 'validation_misclassification_rate': 6156.0\n",
      "\n",
      "Val loss: 0.04022696241736412,  val batches: 1\n",
      "Logging to wandb: {'train_misclassification_rate': 57043.0, 'validation_misclassification_rate': 6156.0, 'train_loss': 0.03361339867115021, 'val_loss': 0.03361339867115021, 'lr': 0.006}\n",
      "\n",
      "\n",
      "   Epoch 32/1224, Loss: 0.03361339867115021, lr: 0.006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                     | 0/1 [00:00<?, ?minibatches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 6, 256, 256])\n",
      "encoder 1: torch.Size([25, 16, 128, 128])\n",
      "encoder 2: torch.Size([25, 32, 64, 64])\n",
      "encoder 3: torch.Size([25, 64, 32, 32])\n",
      "encoder 4: torch.Size([25, 128, 16, 16])\n",
      "encoder 5: torch.Size([25, 256, 8, 8])\n",
      "encoder 6: torch.Size([25, 512, 4, 4])\n",
      "encoder 7: torch.Size([25, 1024, 2, 2])\n",
      "encoder 8: torch.Size([25, 2048, 1, 1])\n",
      "LATENTS HERE\n",
      "torch.Size([25, 2048, 1, 1, 1])\n",
      "res conn shape: torch.Size([25, 2048, 1, 1])\n",
      "inflated conn shape: torch.Size([25, 2048, 1, 1, 1])\n",
      "dencoder 1: torch.Size([25, 1024, 2, 2, 2])\n",
      "res conn shape: torch.Size([25, 1024, 2, 2])\n",
      "inflated conn shape: torch.Size([25, 1024, 2, 2, 2])\n",
      "dencoder 2: torch.Size([25, 512, 4, 4, 4])\n",
      "res conn shape: torch.Size([25, 512, 4, 4])\n",
      "inflated conn shape: torch.Size([25, 512, 4, 4, 4])\n",
      "dencoder 3: torch.Size([25, 256, 8, 8, 8])\n",
      "res conn shape: torch.Size([25, 256, 8, 8])\n",
      "inflated conn shape: torch.Size([25, 256, 8, 8, 8])\n",
      "dencoder 4: torch.Size([25, 128, 16, 16, 16])\n",
      "res conn shape: torch.Size([25, 128, 16, 16])\n",
      "inflated conn shape: torch.Size([25, 128, 16, 16, 16])\n",
      "dencoder 5: torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv1 torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv2 torch.Size([25, 32, 48, 48, 48])\n",
      "before final conv3 torch.Size([25, 16, 48, 48, 48])\n",
      "before final conv4 torch.Size([25, 4, 48, 48, 48])\n",
      "tensor(0.0332, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|█████████████████████████████| 1/1 [00:41<00:00, 41.87s/minibatches]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[misclassification_rate - train] 53761.0\n",
      "Adding in dict for wandb: 'train_misclassification_rate': 53761.0\n",
      "torch.Size([5, 6, 256, 256])\n",
      "encoder 1: torch.Size([5, 16, 128, 128])\n",
      "encoder 2: torch.Size([5, 32, 64, 64])\n",
      "encoder 3: torch.Size([5, 64, 32, 32])\n",
      "encoder 4: torch.Size([5, 128, 16, 16])\n",
      "encoder 5: torch.Size([5, 256, 8, 8])\n",
      "encoder 6: torch.Size([5, 512, 4, 4])\n",
      "encoder 7: torch.Size([5, 1024, 2, 2])\n",
      "encoder 8: torch.Size([5, 2048, 1, 1])\n",
      "LATENTS HERE\n",
      "torch.Size([5, 2048, 1, 1, 1])\n",
      "res conn shape: torch.Size([5, 2048, 1, 1])\n",
      "inflated conn shape: torch.Size([5, 2048, 1, 1, 1])\n",
      "dencoder 1: torch.Size([5, 1024, 2, 2, 2])\n",
      "res conn shape: torch.Size([5, 1024, 2, 2])\n",
      "inflated conn shape: torch.Size([5, 1024, 2, 2, 2])\n",
      "dencoder 2: torch.Size([5, 512, 4, 4, 4])\n",
      "res conn shape: torch.Size([5, 512, 4, 4])\n",
      "inflated conn shape: torch.Size([5, 512, 4, 4, 4])\n",
      "dencoder 3: torch.Size([5, 256, 8, 8, 8])\n",
      "res conn shape: torch.Size([5, 256, 8, 8])\n",
      "inflated conn shape: torch.Size([5, 256, 8, 8, 8])\n",
      "dencoder 4: torch.Size([5, 128, 16, 16, 16])\n",
      "res conn shape: torch.Size([5, 128, 16, 16])\n",
      "inflated conn shape: torch.Size([5, 128, 16, 16, 16])\n",
      "dencoder 5: torch.Size([5, 64, 48, 48, 48])\n",
      "before final conv1 torch.Size([5, 64, 48, 48, 48])\n",
      "before final conv2 torch.Size([5, 32, 48, 48, 48])\n",
      "before final conv3 torch.Size([5, 16, 48, 48, 48])\n",
      "before final conv4 torch.Size([5, 4, 48, 48, 48])\n",
      "[misclassification_rate - validation] 5534.0\n",
      "Adding in dict for wandb: 'validation_misclassification_rate': 5534.0\n",
      "\n",
      "Val loss: 0.041212182492017746,  val batches: 1\n",
      "Logging to wandb: {'train_misclassification_rate': 53761.0, 'validation_misclassification_rate': 5534.0, 'train_loss': 0.03315044194459915, 'val_loss': 0.03315044194459915, 'lr': 0.006}\n",
      "\n",
      "\n",
      "   Epoch 33/1224, Loss: 0.03315044194459915, lr: 0.006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                     | 0/1 [00:00<?, ?minibatches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 6, 256, 256])\n",
      "encoder 1: torch.Size([25, 16, 128, 128])\n",
      "encoder 2: torch.Size([25, 32, 64, 64])\n",
      "encoder 3: torch.Size([25, 64, 32, 32])\n",
      "encoder 4: torch.Size([25, 128, 16, 16])\n",
      "encoder 5: torch.Size([25, 256, 8, 8])\n",
      "encoder 6: torch.Size([25, 512, 4, 4])\n",
      "encoder 7: torch.Size([25, 1024, 2, 2])\n",
      "encoder 8: torch.Size([25, 2048, 1, 1])\n",
      "LATENTS HERE\n",
      "torch.Size([25, 2048, 1, 1, 1])\n",
      "res conn shape: torch.Size([25, 2048, 1, 1])\n",
      "inflated conn shape: torch.Size([25, 2048, 1, 1, 1])\n",
      "dencoder 1: torch.Size([25, 1024, 2, 2, 2])\n",
      "res conn shape: torch.Size([25, 1024, 2, 2])\n",
      "inflated conn shape: torch.Size([25, 1024, 2, 2, 2])\n",
      "dencoder 2: torch.Size([25, 512, 4, 4, 4])\n",
      "res conn shape: torch.Size([25, 512, 4, 4])\n",
      "inflated conn shape: torch.Size([25, 512, 4, 4, 4])\n",
      "dencoder 3: torch.Size([25, 256, 8, 8, 8])\n",
      "res conn shape: torch.Size([25, 256, 8, 8])\n",
      "inflated conn shape: torch.Size([25, 256, 8, 8, 8])\n",
      "dencoder 4: torch.Size([25, 128, 16, 16, 16])\n",
      "res conn shape: torch.Size([25, 128, 16, 16])\n",
      "inflated conn shape: torch.Size([25, 128, 16, 16, 16])\n",
      "dencoder 5: torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv1 torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv2 torch.Size([25, 32, 48, 48, 48])\n",
      "before final conv3 torch.Size([25, 16, 48, 48, 48])\n",
      "before final conv4 torch.Size([25, 4, 48, 48, 48])\n",
      "tensor(0.0316, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|█████████████████████████████| 1/1 [00:42<00:00, 42.92s/minibatches]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[misclassification_rate - train] 44631.0\n",
      "Adding in dict for wandb: 'train_misclassification_rate': 44631.0\n",
      "torch.Size([5, 6, 256, 256])\n",
      "encoder 1: torch.Size([5, 16, 128, 128])\n",
      "encoder 2: torch.Size([5, 32, 64, 64])\n",
      "encoder 3: torch.Size([5, 64, 32, 32])\n",
      "encoder 4: torch.Size([5, 128, 16, 16])\n",
      "encoder 5: torch.Size([5, 256, 8, 8])\n",
      "encoder 6: torch.Size([5, 512, 4, 4])\n",
      "encoder 7: torch.Size([5, 1024, 2, 2])\n",
      "encoder 8: torch.Size([5, 2048, 1, 1])\n",
      "LATENTS HERE\n",
      "torch.Size([5, 2048, 1, 1, 1])\n",
      "res conn shape: torch.Size([5, 2048, 1, 1])\n",
      "inflated conn shape: torch.Size([5, 2048, 1, 1, 1])\n",
      "dencoder 1: torch.Size([5, 1024, 2, 2, 2])\n",
      "res conn shape: torch.Size([5, 1024, 2, 2])\n",
      "inflated conn shape: torch.Size([5, 1024, 2, 2, 2])\n",
      "dencoder 2: torch.Size([5, 512, 4, 4, 4])\n",
      "res conn shape: torch.Size([5, 512, 4, 4])\n",
      "inflated conn shape: torch.Size([5, 512, 4, 4, 4])\n",
      "dencoder 3: torch.Size([5, 256, 8, 8, 8])\n",
      "res conn shape: torch.Size([5, 256, 8, 8])\n",
      "inflated conn shape: torch.Size([5, 256, 8, 8, 8])\n",
      "dencoder 4: torch.Size([5, 128, 16, 16, 16])\n",
      "res conn shape: torch.Size([5, 128, 16, 16])\n",
      "inflated conn shape: torch.Size([5, 128, 16, 16, 16])\n",
      "dencoder 5: torch.Size([5, 64, 48, 48, 48])\n",
      "before final conv1 torch.Size([5, 64, 48, 48, 48])\n",
      "before final conv2 torch.Size([5, 32, 48, 48, 48])\n",
      "before final conv3 torch.Size([5, 16, 48, 48, 48])\n",
      "before final conv4 torch.Size([5, 4, 48, 48, 48])\n",
      "[misclassification_rate - validation] 5380.0\n",
      "Adding in dict for wandb: 'validation_misclassification_rate': 5380.0\n",
      "\n",
      "Val loss: 0.0397816076874733,  val batches: 1\n",
      "Logging to wandb: {'train_misclassification_rate': 44631.0, 'validation_misclassification_rate': 5380.0, 'train_loss': 0.03160783275961876, 'val_loss': 0.03160783275961876, 'lr': 0.006}\n",
      "\n",
      "\n",
      "   Epoch 34/1224, Loss: 0.03160783275961876, lr: 0.006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                     | 0/1 [00:00<?, ?minibatches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 6, 256, 256])\n",
      "encoder 1: torch.Size([25, 16, 128, 128])\n",
      "encoder 2: torch.Size([25, 32, 64, 64])\n",
      "encoder 3: torch.Size([25, 64, 32, 32])\n",
      "encoder 4: torch.Size([25, 128, 16, 16])\n",
      "encoder 5: torch.Size([25, 256, 8, 8])\n",
      "encoder 6: torch.Size([25, 512, 4, 4])\n",
      "encoder 7: torch.Size([25, 1024, 2, 2])\n",
      "encoder 8: torch.Size([25, 2048, 1, 1])\n",
      "LATENTS HERE\n",
      "torch.Size([25, 2048, 1, 1, 1])\n",
      "res conn shape: torch.Size([25, 2048, 1, 1])\n",
      "inflated conn shape: torch.Size([25, 2048, 1, 1, 1])\n",
      "dencoder 1: torch.Size([25, 1024, 2, 2, 2])\n",
      "res conn shape: torch.Size([25, 1024, 2, 2])\n",
      "inflated conn shape: torch.Size([25, 1024, 2, 2, 2])\n",
      "dencoder 2: torch.Size([25, 512, 4, 4, 4])\n",
      "res conn shape: torch.Size([25, 512, 4, 4])\n",
      "inflated conn shape: torch.Size([25, 512, 4, 4, 4])\n",
      "dencoder 3: torch.Size([25, 256, 8, 8, 8])\n",
      "res conn shape: torch.Size([25, 256, 8, 8])\n",
      "inflated conn shape: torch.Size([25, 256, 8, 8, 8])\n",
      "dencoder 4: torch.Size([25, 128, 16, 16, 16])\n",
      "res conn shape: torch.Size([25, 128, 16, 16])\n",
      "inflated conn shape: torch.Size([25, 128, 16, 16, 16])\n",
      "dencoder 5: torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv1 torch.Size([25, 64, 48, 48, 48])\n",
      "before final conv2 torch.Size([25, 32, 48, 48, 48])\n",
      "before final conv3 torch.Size([25, 16, 48, 48, 48])\n",
      "before final conv4 torch.Size([25, 4, 48, 48, 48])\n"
     ]
    }
   ],
   "source": [
    "train_occupancy_model = True\n",
    "if train_occupancy_model:\n",
    "    train_model(model,\n",
    "                train_loader,\n",
    "                optimizer,\n",
    "                config,\n",
    "                metrics=[mscr],\n",
    "                start_at=0,\n",
    "                initial_epoch=initial_epoch,\n",
    "                autosave_every=1800,\n",
    "                num_epochs=1224,\n",
    "                device=device,\n",
    "                criterion=nn.BCEWithLogitsLoss(pos_weight=pos_weights),\n",
    "                debug=False,\n",
    "                name=run.name,\n",
    "                validation=test_loader,\n",
    "                log_to_wandb=True,\n",
    "                show_grad_norm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4e3f20-c29f-458e-b479-f5b7a5404508",
   "metadata": {},
   "outputs": [],
   "source": [
    "def misclassification_rate(predictions, ground_truth):\n",
    "    \"\"\"\n",
    "    Calculate the misclassification rate between predictions and ground truth.\n",
    "    \n",
    "    Parameters:\n",
    "    predictions (torch.Tensor): Tensor containing predicted binary labels (shape: [batch_dim, W, H, D])\n",
    "    ground_truth (torch.Tensor): Tensor containing ground truth binary labels (shape: [batch_dim, W, H, D])\n",
    "    \n",
    "    Returns:\n",
    "    float: Misclassification rate (incorrect predictions / total elements)\n",
    "    \"\"\"\n",
    "    # Ensure the two tensors have the same shape\n",
    "    assert predictions.shape == ground_truth.shape, \"Shape of predictions and ground_truth must be the same\"\n",
    "    \n",
    "    # Compare the predictions to the ground truth\n",
    "    incorrect = torch.ne(predictions, ground_truth)  # Tensor with True where predictions and ground truth differ\n",
    "    \n",
    "    # Calculate the number of incorrect predictions\n",
    "    num_incorrect = incorrect.sum().item()  # Convert to integer\n",
    "    \n",
    "    # Calculate total number of elements\n",
    "    total_elements = ground_truth.numel()  # Total number of elements in the tensor\n",
    "    \n",
    "    # Misclassification rate is the number of incorrect predictions divided by total number of elements\n",
    "    misclassification_rate = num_incorrect / total_elements\n",
    "    \n",
    "    return misclassification_rate\n",
    "\n",
    "def misclassification_rate_with_tolerance(predictions, ground_truth, tol=1e-6):\n",
    "    \"\"\"\n",
    "    Calculate the misclassification rate between predictions and ground truth\n",
    "    using a tolerance for floating point comparisons.\n",
    "    \n",
    "    Parameters:\n",
    "    predictions (torch.Tensor): Tensor containing predicted binary labels (shape: [batch_dim, W, H, D])\n",
    "    ground_truth (torch.Tensor): Tensor containing ground truth binary labels (shape: [batch_dim, W, H, D])\n",
    "    tol (float): Tolerance for floating point comparisons\n",
    "    \n",
    "    Returns:\n",
    "    float: Misclassification rate (incorrect predictions / total elements)\n",
    "    \"\"\"\n",
    "    # Ensure the two tensors have the same shape\n",
    "    assert predictions.shape == ground_truth.shape, \"Shape of predictions and ground_truth must be the same\"\n",
    "    \n",
    "    # Compare the predictions to the ground truth using a tolerance\n",
    "    incorrect = ~torch.isclose(predictions, ground_truth, atol=tol)\n",
    "    \n",
    "    # Calculate the number of incorrect predictions\n",
    "    num_incorrect = incorrect.sum().item()\n",
    "    \n",
    "    # Calculate total number of elements\n",
    "    total_elements = ground_truth.numel()\n",
    "    \n",
    "    # Misclassification rate is the number of incorrect predictions divided by total number of elements\n",
    "    misclassification_rate = num_incorrect / total_elements\n",
    "    \n",
    "    return misclassification_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b78b4b-afa6-456e-bbf7-085ef0e6d034",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "0c91c437-6e2d-48bb-89b6-56eaffe75818",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_f1(predictions, ground_truth, tol=1e-6):\n",
    "    \"\"\"\n",
    "    Calculate precision, recall, and F1 score for binary classification.\n",
    "    \n",
    "    Parameters:\n",
    "    predictions (torch.Tensor): Tensor containing predicted binary labels (shape: [batch_dim, W, H, D])\n",
    "    ground_truth (torch.Tensor): Tensor containing ground truth binary labels (shape: [batch_dim, W, H, D])\n",
    "    tol (float): Tolerance for floating point comparisons\n",
    "    \n",
    "    Returns:\n",
    "    tuple: (precision, recall, f1_score)\n",
    "    \"\"\"\n",
    "    # Ensure the two tensors have the same shape\n",
    "    assert predictions.shape == ground_truth.shape, \"Shape of predictions and ground_truth must be the same\"\n",
    "    \n",
    "    # Use torch.isclose to handle floating-point precision issues\n",
    "    pred_positives = torch.isclose(predictions, torch.tensor(1.0), atol=tol)\n",
    "    print(f\"pred pos: {pred_positives.sum()}\")\n",
    "    gt_positives = torch.isclose(ground_truth, torch.tensor(1.0), atol=tol)\n",
    "    print(f\"gt posirites: {gt_positives.sum()}\")\n",
    "    \n",
    "    # Calculate True Positives (TP), False Positives (FP), and False Negatives (FN)\n",
    "    TP = (pred_positives & gt_positives).sum().item()  # Both predicted and actual are 1\n",
    "    print(f\"TP: {TP}\")\n",
    "    FP = (pred_positives & ~gt_positives).sum().item()  # Predicted 1, but actual is 0\n",
    "    print(f\"FP: {FP}\")\n",
    "    FN = (~pred_positives & gt_positives).sum().item()  # Predicted 0, but actual is 1\n",
    "    print(f\"FN: {FN}\")\n",
    "    \n",
    "    # Calculate Precision, Recall, and F1 Score\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0.0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0.0\n",
    "    f1_score = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "    \n",
    "    return precision, recall, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "291950bd-906c-4ab0-83c4-552159ecd61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.035315315315315315\n",
      "Misclassification rate in test set: 0.035315315315315315\n"
     ]
    }
   ],
   "source": [
    "loader = test_natural_loader\n",
    "# Evaluation\n",
    "total_misc = 0\n",
    "total_batches = 0\n",
    "max_batch = 2\n",
    "for batch in loader:\n",
    "    pred = crop_output_batch(model(batch[0].to(device)))\n",
    "    occ = torch.sigmoid(pred)\n",
    "    occ = (occ-torch.min(occ)) / (torch.max(occ)-torch.min(occ))\n",
    "    occ = (occ > 0.25) * 1.0 # occ # th\n",
    "    gt = crop_output_batch(batch[1])\n",
    "    print(misclassification_rate(occ, gt))\n",
    "    total_misc += misclassification_rate(occ, gt)\n",
    "    total_batches += 1\n",
    "    max_batch -= 1\n",
    "    if max_batch == 0:\n",
    "        break\n",
    "print(f\"Misclassification rate in test set: {total_misc/total_batches}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "dbf968be-543a-480d-b60c-94d46e84afa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03567567567567568\n",
      "Misclassification rate in test set: 0.03567567567567568\n"
     ]
    }
   ],
   "source": [
    "loader = test_natural_loader\n",
    "# Evaluation\n",
    "total_misc = 0\n",
    "total_batches = 0\n",
    "max_batch = 30\n",
    "for batch in loader:\n",
    "    pred = crop_output_batch(model(batch[0].to(device)))\n",
    "    occ = torch.sigmoid(pred)\n",
    "    occ = (occ-torch.min(occ)) / (torch.max(occ)-torch.min(occ))\n",
    "    occ = (occ > 0.25) * 1.0# * occ # th\n",
    "    gt = crop_output_batch(batch[1])\n",
    "    print(misclassification_rate(occ, gt))\n",
    "    total_misc += misclassification_rate(occ, gt)\n",
    "    total_batches += 1\n",
    "    max_batch -= 1\n",
    "    if max_batch == 0:\n",
    "        break\n",
    "print(f\"Misclassification rate in test set: {total_misc/total_batches}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "ccf1a227-f523-41b1-9cac-7096772ca49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1592.)\n",
      "tensor(1128.)\n",
      "pred pos: 1592\n",
      "gt posirites: 1128\n",
      "TP: 863\n",
      "FP: 729\n",
      "FN: 265\n",
      "0.5420854271356784, 0.7650709219858156, 0.6345588235294118\n",
      "Precision, recall, F1 in test set: 0.5420854271356784, 0.7650709219858156, 0.6345588235294118\n"
     ]
    }
   ],
   "source": [
    "loader = test_natural_loader\n",
    "# Evaluation\n",
    "total_p = 0\n",
    "total_r = 0\n",
    "total_f1 = 0\n",
    "total_batches = 0\n",
    "max_batch = 30\n",
    "for batch in loader:\n",
    "    with torch.no_grad():\n",
    "        pred = crop_output_batch(model(batch[0].to(device)))\n",
    "        occ = torch.sigmoid(pred)\n",
    "        occ = (occ-torch.min(occ)) / (torch.max(occ)-torch.min(occ))\n",
    "        occ = (occ > 0.5) * 1.0# * occ # th\n",
    "        gt = crop_output_batch(batch[1])\n",
    "        print(occ.sum())\n",
    "        print(gt.sum())\n",
    "        p, r, f1 = precision_recall_f1(occ, gt)\n",
    "        print(f\"{p}, {r}, {f1}\")\n",
    "        total_p += p\n",
    "        total_r += r\n",
    "        total_f1 += f1\n",
    "        total_batches += 1\n",
    "        max_batch -= 1\n",
    "        if max_batch == 0:\n",
    "            break\n",
    "print(f\"Precision, recall, F1 in test set: {total_p/total_batches}, {total_r/total_batches}, {total_f1/total_batches}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
